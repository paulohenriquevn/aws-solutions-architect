### Questão [101]
Um arquiteto de soluções está projetando uma VPC com sub-redes públicas e privadas. A VPC e as sub-redes utilizam blocos CIDR IPv4. Há uma sub-rede pública e uma sub-rede privada em cada uma das três zonas de disponibilidade (AZs) para alta disponibilidade. Um gateway da Internet é usado para fornecer acesso à Internet para as sub-redes públicas. As sub-redes privadas precisam de acesso à Internet para permitir que instâncias Amazon EC2 façam download de atualizações de software.  
O que o arquiteto de soluções deve fazer para habilitar o acesso à Internet para as sub-redes privadas?  

A. Crie três NAT gateways, um para cada sub-rede pública em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para o NAT gateway em sua AZ.  

B. Crie três instâncias NAT, uma para cada sub-rede privada em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para a instância NAT em sua AZ.  

C. Crie um segundo gateway da Internet em uma das sub-redes privadas. Atualize a tabela de rotas para as sub-redes privadas que encaminhem o tráfego fora da VPC para o gateway da Internet privado.  

D. Crie um gateway da Internet somente de saída em uma das sub-redes públicas. Atualize a tabela de rotas para as sub-redes privadas que encaminhem o tráfego fora da VPC para o gateway da Internet somente de saída.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Crie três NAT gateways, um para cada sub-rede pública em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para o NAT gateway em sua AZ.

**Justificativa:**  
- **Por que essa opção?**  
  O NAT gateway é a solução recomendada e gerenciada pela AWS para permitir que instâncias em sub-redes privadas acessem a Internet de forma segura, sem expô-las diretamente. Criar um NAT gateway em cada AZ melhora a alta disponibilidade, garantindo que, mesmo que uma AZ fique indisponível, as instâncias em outras AZs ainda possam acessar a Internet. Atualizar as tabelas de rotas privadas para redirecionar o tráfego fora da VPC para o NAT gateway da AZ correspondente garante a eficiência da rede e alta disponibilidade.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora as instâncias NAT possam cumprir a mesma função que os NAT gateways, elas exigem manutenção manual, como atualizações, escalabilidade e substituições em caso de falha. Isso aumenta o esforço operacional em comparação com o NAT gateway, que é gerenciado pela AWS.  
  - **C:** Não é possível criar múltiplos gateways da Internet em uma única VPC. O gateway da Internet é usado apenas para tráfego de sub-redes públicas e não pode ser diretamente anexado a sub-redes privadas.  
  - **D:** O gateway da Internet somente de saída é usado para tráfego IPv6. Como o problema descrito na questão envolve tráfego IPv4, essa opção não é aplicável.  

</details>

---

### Questão [102]
**Tradução:**  
Uma empresa deseja migrar um data center local para a AWS. O data center hospeda um servidor SFTP que armazena seus dados em um sistema de arquivos baseado em NFS. O servidor contém 200 GB de dados que precisam ser transferidos. O servidor deve ser hospedado em uma instância Amazon EC2 que utiliza um sistema de arquivos Amazon Elastic File System (Amazon EFS).  

Quais combinações de etapas um arquiteto de soluções deve realizar para automatizar essa tarefa? (Escolha duas.)  

A. Inicie a instância EC2 na mesma zona de disponibilidade que o sistema de arquivos EFS.  
B. Instale um agente do AWS DataSync no data center local.  
C. Crie um volume secundário do Amazon Elastic Block Store (Amazon EBS) na instância EC2 para os dados.  
D. Use manualmente um comando de cópia do sistema operacional para enviar os dados para a instância EC2.  
E. Use o AWS DataSync para criar uma configuração de localização apropriada para o servidor SFTP local.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**B.** Instale um agente do AWS DataSync no data center local.  
**E.** Use o AWS DataSync para criar uma configuração de localização apropriada para o servidor SFTP local.

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O AWS DataSync é projetado para transferir dados de sistemas de arquivos locais para a AWS. Para usar o DataSync, é necessário instalar um agente no data center local que possa acessar os dados no sistema de arquivos NFS.  
  - **E:** Uma vez que o agente do DataSync está configurado, criar uma configuração de localização para o servidor SFTP local permite que o serviço saiba de onde transferir os dados. Essa abordagem automatiza o processo de transferência de dados e reduz a complexidade operacional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora seja uma boa prática posicionar a instância EC2 na mesma zona de disponibilidade que o EFS para minimizar a latência, essa etapa não é necessária para a migração automatizada dos dados.  
  - **C:** Criar um volume EBS adicional não é relevante, pois os dados serão armazenados diretamente no sistema de arquivos EFS, que é o objetivo final da configuração.  
  - **D:** Realizar a transferência manualmente com um comando do sistema operacional não é uma solução automatizada e, portanto, não atende ao requisito da questão.  

</details>
---

### Questão [103]
Uma empresa tem um trabalho de extração, transformação e carga (ETL) do AWS Glue que é executado todos os dias no mesmo horário. O trabalho processa dados XML que estão em um bucket do Amazon S3. Novos dados são adicionados ao bucket do S3 diariamente. Um arquiteto de soluções percebe que o AWS Glue está processando todos os dados em cada execução.  
O que o arquiteto de soluções deve fazer para evitar que o AWS Glue reprocesse dados antigos?  

A. Edite o trabalho para usar **job bookmarks**.  

B. Edite o trabalho para excluir os dados após serem processados.  

C. Edite o trabalho definindo o campo **NumberOfWorkers** como 1.  

D. Use uma transformação de aprendizado de máquina (ML) **FindMatches**.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Edite o trabalho para usar **job bookmarks**.

**Justificativa:**  
- **Por que essa opção?**  
  Os **job bookmarks** do AWS Glue permitem que o serviço acompanhe os dados que já foram processados em execuções anteriores. Quando ativados, os **bookmarks** garantem que somente os novos dados adicionados ao bucket S3 sejam processados, evitando o reprocesamento desnecessário de dados antigos. Essa é a solução ideal para cenários de processamento incremental de dados.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Excluir os dados após o processamento pode ser problemático, especialmente se os dados precisarem ser armazenados para referência futura ou outros processos. Isso também não é uma prática recomendada para controle de dados.  
  - **C:** Alterar o número de trabalhadores não resolve o problema de reprocesamento, pois o número de trabalhadores afeta apenas o desempenho do trabalho, e não a lógica de processamento.  
  - **D:** A transformação **FindMatches** é usada para encontrar registros semelhantes ou correspondentes, mas não é relevante para evitar o reprocesamento de dados no contexto descrito.  

</details>
---
### Questão [104]
Um arquiteto de soluções deve projetar uma infraestrutura altamente disponível para um site. O site é alimentado por servidores web Windows que rodam em instâncias Amazon EC2. O arquiteto de soluções deve implementar uma solução que possa mitigar um ataque DDoS em larga escala que se origina de milhares de endereços IP. O tempo de inatividade não é aceitável para o site.  
Quais ações o arquiteto de soluções deve tomar para proteger o site contra esse tipo de ataque? (Escolha duas.)  

A. Use o AWS Shield Advanced para interromper o ataque DDoS.  

B. Configure o Amazon GuardDuty para bloquear automaticamente os atacantes.  

C. Configure o site para usar o Amazon CloudFront para conteúdo estático e dinâmico.

D. Use uma função AWS Lambda para adicionar automaticamente os endereços IP dos atacantes às ACLs de rede da VPC.  

E. Use instâncias Spot do EC2 em um Auto Scaling group com uma política de escalabilidade baseada em rastreamento de destino definida para 80% de utilização da CPU.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**A.** Use o AWS Shield Advanced para interromper o ataque DDoS.  
**C.** Configure o site para usar o Amazon CloudFront para conteúdo estático e dinâmico.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** O **AWS Shield Advanced** oferece proteção avançada contra ataques DDoS, incluindo proteção para grandes ataques que utilizam milhares de IPs. Ele fornece detecção e mitigação automatizadas, reduzindo significativamente o impacto de ataques DDoS em larga escala.  
  - **C:** O **Amazon CloudFront** é uma rede de distribuição de conteúdo (CDN) que fornece proteção integrada contra ataques DDoS. Ele pode absorver grandes volumes de tráfego malicioso e filtrar solicitações antes que elas cheguem à infraestrutura do backend, reduzindo a carga sobre as instâncias EC2 e protegendo contra ataques volumétricos.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **Amazon GuardDuty** é uma ferramenta de detecção de ameaças e não bloqueia automaticamente os atacantes. Ele pode detectar atividades suspeitas, mas não oferece proteção ativa contra ataques DDoS.  
  - **D:** Usar uma função **AWS Lambda** para atualizar as ACLs de rede com IPs bloqueados não é escalável para ataques em larga escala com milhares de IPs. Além disso, ACLs têm limites para o número de regras, tornando essa abordagem inadequada.  
  - **E:** Usar instâncias Spot em um **Auto Scaling group** não é uma solução eficaz contra ataques DDoS. Embora a escalabilidade possa ajudar a lidar com tráfego legítimo elevado, as instâncias Spot podem ser interrompidas pela AWS a qualquer momento, o que comprometeria a disponibilidade do site durante um ataque.  

</details>

### Questão [105]
Uma empresa está se preparando para implantar uma nova carga de trabalho sem servidor. Um arquiteto de soluções deve usar o princípio de menor privilégio para configurar permissões que serão usadas para executar uma função AWS Lambda. Uma regra do Amazon EventBridge (Amazon CloudWatch Events) irá invocar a função.  
Qual solução atende a esses requisitos?  

A. Adicione uma função de execução à função Lambda com **lambda:InvokeFunction** como a ação e **\*** como o principal.  

B. Adicione uma função de execução à função Lambda com **lambda:InvokeFunction** como a ação e **Service: lambda.amazonaws.com** como o principal.  

C. Adicione uma política baseada em recursos à função Lambda com **lambda:\*** como a ação e **Service: events.amazonaws.com** como o principal.  

D. Adicione uma política baseada em recursos à função Lambda com **lambda:InvokeFunction** como a ação e **Service: events.amazonaws.com** como o principal.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Adicione uma política baseada em recursos à função Lambda com **lambda:InvokeFunction** como a ação e **Service: events.amazonaws.com** como o principal.

**Justificativa:**  
- **Por que essa opção?**  
  Para permitir que o Amazon EventBridge (anteriormente Amazon CloudWatch Events) invoque a função Lambda, você precisa adicionar uma **política baseada em recursos** à função Lambda. A política deve conceder a permissão **lambda:InvokeFunction** e definir **events.amazonaws.com** como o principal autorizado a invocar a função. Isso segue o princípio de menor privilégio, pois só permite a ação necessária (invocar a função) para o serviço específico (EventBridge).  

- **Por que as outras opções não são adequadas?**  
  - **A:** Permitir **\*** como o principal concede acesso a qualquer entidade para invocar a função Lambda, violando o princípio de menor privilégio.  
  - **B:** A configuração da função de execução da Lambda com **lambda:InvokeFunction** e o principal **lambda.amazonaws.com** não é relevante para permitir que o EventBridge invoque a função. Isso trata do contexto de execução da própria Lambda, não de quem pode invocá-la.  
  - **C:** Conceder **lambda:\*** como ação na política baseada em recursos concede permissões excessivas, permitindo qualquer ação Lambda, o que viola o princípio de menor privilégio.  

</details>

---
### Questão [106]
**Tradução:**  
Uma empresa está se preparando para armazenar dados confidenciais no Amazon S3. Por razões de conformidade, os dados devem ser criptografados em repouso. O uso das chaves de criptografia deve ser registrado para auditoria. As chaves devem ser rotacionadas a cada ano.  
Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?  

A. Criptografia no lado do servidor com chaves fornecidas pelo cliente (SSE-C).  

B. Criptografia no lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3).  

C. Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação manual.  

D. Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação automática.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação automática.

**Justificativa:**  
- **Por que essa opção?**  
  O **AWS KMS (Key Management Service)** oferece suporte a criptografia com chaves gerenciadas pelo serviço, incluindo a funcionalidade de rotação automática anual. Ele também registra o uso das chaves no AWS CloudTrail, atendendo ao requisito de auditoria. Como a rotação é automática, essa abordagem minimiza o esforço operacional e é altamente eficiente, enquanto mantém conformidade e segurança.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **SSE-C** exige que o cliente forneça as chaves de criptografia e gerencie manualmente a rotação, aumentando significativamente o esforço operacional. Além disso, o Amazon S3 não registra automaticamente o uso dessas chaves para auditoria.  
  - **B:** O **SSE-S3** gerencia as chaves automaticamente, mas não registra o uso das chaves em logs detalhados como o AWS KMS, o que pode não atender aos requisitos de auditoria.  
  - **C:** O **SSE-KMS** com rotação manual atende aos requisitos de conformidade e auditoria, mas exige intervenção manual para rotacionar as chaves, tornando-o menos eficiente operacionalmente em comparação com a rotação automática.  

</details>
---

### Questão [107]
Uma empresa de compartilhamento de bicicletas está desenvolvendo uma arquitetura em várias camadas para rastrear a localização de suas bicicletas durante as horas de operação de pico. A empresa deseja usar esses pontos de dados em sua plataforma de análise existente. Um arquiteto de soluções deve determinar a opção de várias camadas mais viável para dar suporte a essa arquitetura. Os pontos de dados devem ser acessíveis a partir da API REST.  
Qual ação atende a esses requisitos para armazenar e recuperar os dados de localização?  

A. Use o Amazon Athena com o Amazon S3.  

B. Use o Amazon API Gateway com o AWS Lambda.  

C. Use o Amazon QuickSight com o Amazon Redshift.  

D. Use o Amazon API Gateway com o Amazon Kinesis Data Analytics.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Use o Amazon API Gateway com o Amazon Kinesis Data Analytics.

**Justificativa:**  
- **Por que essa opção?**  
  O **Amazon API Gateway** permite expor uma API REST para os dados de localização. O **Amazon Kinesis Data Analytics** é ideal para processar dados em tempo real, como fluxos de localização de bicicletas, garantindo que os dados estejam disponíveis de maneira eficiente para integração com a plataforma analítica da empresa. Essa solução atende ao requisito de disponibilizar os dados de localização em tempo real via API REST, enquanto também suporta a integração com plataformas analíticas existentes.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **Amazon Athena** com o **Amazon S3** é uma boa solução para consultas interativas em dados armazenados, mas não é otimizado para dados em tempo real. Ele não atende aos requisitos de fornecer acesso em tempo real aos pontos de dados por meio de uma API REST.  
  - **B:** Embora o **Amazon API Gateway** com o **AWS Lambda** possa expor uma API REST, ele não é ideal para processar grandes volumes de dados em tempo real, como fluxos contínuos de localização de bicicletas.  
  - **C:** O **Amazon QuickSight** com o **Amazon Redshift** é uma solução para visualização de dados e análise em lote. Ele não oferece suporte a fluxos de dados em tempo real nem fornece uma API REST para acessar os dados diretamente.  

</details>

---

### Questão [108]
Uma empresa possui um site de vendas de automóveis que armazena seus anúncios em um banco de dados no Amazon RDS. Quando um automóvel é vendido, o anúncio precisa ser removido do site e os dados devem ser enviados para vários sistemas de destino.  
Qual design um arquiteto de soluções deve recomendar?  

A. Crie uma função AWS Lambda acionada quando o banco de dados no Amazon RDS for atualizado para enviar as informações para uma fila do Amazon Simple Queue Service (Amazon SQS) para os destinos consumirem.  

B. Crie uma função AWS Lambda acionada quando o banco de dados no Amazon RDS for atualizado para enviar as informações para uma fila FIFO do Amazon Simple Queue Service (Amazon SQS) para os destinos consumirem. 

C. Inscreva-se em uma notificação de eventos do RDS e envie uma fila do Amazon Simple Queue Service (Amazon SQS) distribuída para vários tópicos do Amazon Simple Notification Service (Amazon SNS). Use funções AWS Lambda para atualizar os destinos. 

D. Inscreva-se em uma notificação de eventos do RDS e envie um tópico do Amazon Simple Notification Service (Amazon SNS) distribuído para várias filas do Amazon Simple Queue Service (Amazon SQS). Use funções AWS Lambda para atualizar os destinos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Inscreva-se em uma notificação de eventos do RDS e envie um tópico do Amazon Simple Notification Service (Amazon SNS) distribuído para várias filas do Amazon Simple Queue Service (Amazon SQS). Use funções AWS Lambda para atualizar os destinos.

**Justificativa:**  
- **Por que essa opção?**  
  O design utiliza notificações de eventos do Amazon RDS, que podem detectar alterações no banco de dados. O evento aciona um tópico do Amazon SNS que, por sua vez, pode ser "distribuído" (fanned out) para várias filas do Amazon SQS. Cada fila pode ser processada independentemente por funções AWS Lambda, que enviam os dados para os sistemas de destino. Essa arquitetura é escalável e desacoplada, permitindo que novos sistemas de destino sejam facilmente adicionados no futuro.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora uma função Lambda acionada diretamente pelo RDS possa enviar os dados para uma única fila SQS, essa abordagem não suporta a necessidade de "fan-out" para múltiplos sistemas de destino.  
  - **B:** Usar uma fila FIFO do SQS não é necessário neste caso, pois a ordem exata dos eventos não foi mencionada como um requisito. Fila padrão do SQS e SNS oferecem mais flexibilidade para lidar com múltiplos destinos.  
  - **C:** O design que utiliza uma fila SQS como ponto inicial para "fan-out" para múltiplos tópicos SNS não é eficiente, pois SNS é mais adequado para distribuição inicial (fan-out). Reverter o papel de SNS e SQS adiciona complexidade desnecessária.  

</details>

---

### Questão [109]
Uma empresa precisa armazenar dados no Amazon S3 e deve impedir que os dados sejam alterados. A empresa deseja que novos objetos enviados ao Amazon S3 permaneçam inalteráveis por um período de tempo não especificado, até que a empresa decida modificá-los. Apenas usuários específicos na conta da AWS da empresa podem ter permissão para excluir os objetos.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Crie um cofre S3 Glacier. Aplique uma política de bloqueio de cofre "escreve-uma-vez, lê-muitas" (WORM) aos objetos.  

B. Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Defina um período de retenção de 100 anos. Use o modo de governança como o modo de retenção padrão do bucket S3 para novos objetos.  

C. Crie um bucket S3. Use o AWS CloudTrail para rastrear quaisquer eventos da API S3 que modifiquem os objetos. Quando notificado, restaure os objetos modificados de qualquer versão de backup que a empresa possua.  

D. Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Adicione uma retenção legal (legal hold) aos objetos. Adicione a permissão **s3:PutObjectLegalHold** às políticas IAM dos usuários que precisam excluir os objetos.  


<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Adicione uma retenção legal (legal hold) aos objetos. Adicione a permissão **s3:PutObjectLegalHold** às políticas IAM dos usuários que precisam excluir os objetos.

**Justificativa:**  
- **Por que essa opção?**  
  O **S3 Object Lock** permite que os objetos no S3 sejam configurados para serem imutáveis, impedindo que sejam alterados ou excluídos durante um período de retenção ou enquanto uma retenção legal estiver aplicada. A retenção legal (legal hold) pode ser usada quando o período de retenção não é especificado e permite que usuários autorizados apliquem ou removam a retenção conforme necessário. Isso satisfaz os requisitos da empresa de evitar alterações até que uma decisão seja tomada.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O S3 Glacier Vault Lock é para arquivos armazenados em **S3 Glacier**, o que não é indicado para armazenamento regular de objetos que podem precisar ser acessados ou modificados eventualmente.  
  - **B:** Embora o S3 Object Lock com um período de retenção longo (100 anos) e modo de governança impeça alterações, ele não permite flexibilidade para modificar objetos antes que o período de retenção termine, a menos que uma alteração seja explicitamente autorizada por usuários com permissões especiais. Isso não atende ao requisito de modificar os objetos em um momento incerto.  
  - **C:** Usar o **AWS CloudTrail** para rastrear eventos e restaurar objetos manualmente adiciona complexidade e não impede proativamente alterações nos objetos.  

</details>
---

### Questão [110]
Uma empresa de mídia social permite que os usuários enviem imagens para o seu site. O site é executado em instâncias Amazon EC2. Durante as solicitações de upload, o site redimensiona as imagens para um tamanho padrão e armazena as imagens redimensionadas no Amazon S3. Os usuários estão experimentando lentidão nas solicitações de upload para o site.  
A empresa precisa reduzir o acoplamento dentro do aplicativo e melhorar o desempenho do site. Um arquiteto de soluções deve projetar o processo de upload de imagens mais eficiente operacionalmente.  
Quais combinações de ações o arquiteto de soluções deve tomar para atender a esses requisitos? (Escolha duas.)  

A. Configure o aplicativo para enviar imagens para o S3 Glacier.  

B. Configure o servidor web para enviar as imagens originais para o Amazon S3.  

C. Configure o aplicativo para enviar imagens diretamente do navegador de cada usuário para o Amazon S3 por meio do uso de uma URL pré-assinada (presigned URL).  

D. Configure notificações de evento do S3 para invocar uma função AWS Lambda quando uma imagem for enviada. Use a função para redimensionar a imagem.  

E. Crie uma regra do Amazon EventBridge (Amazon CloudWatch Events) que invoque uma função AWS Lambda em uma programação para redimensionar as imagens enviadas.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**C.** Configure o aplicativo para enviar imagens diretamente do navegador de cada usuário para o Amazon S3 por meio do uso de uma URL pré-assinada (presigned URL).  
**D.** Configure notificações de evento do S3 para invocar uma função AWS Lambda quando uma imagem for enviada. Use a função para redimensionar a imagem.

**Justificativa:**  
- **Por que essas opções?**  
  - **C:** Usar URLs pré-assinadas permite que os usuários enviem imagens diretamente para o Amazon S3, eliminando a necessidade de o servidor web EC2 processar os uploads. Isso reduz significativamente o acoplamento e melhora o desempenho do site, pois reduz a carga no servidor.  
  - **D:** Configurar notificações de evento do S3 para invocar uma função Lambda automatiza o redimensionamento de imagens. A função Lambda processa as imagens enviadas para o S3, eliminando a necessidade de o servidor web realizar esse processamento, o que melhora o desempenho geral e mantém um design desacoplado.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O S3 Glacier é projetado para arquivamento de longo prazo, não para armazenamento de objetos frequentemente acessados como imagens. Ele não suporta redimensionamento eficiente ou rápido.  
  - **B:** Enviar as imagens originais para o Amazon S3 usando o servidor web não resolve o problema de desempenho, pois o servidor ainda gerencia a carga do upload.  
  - **E:** Usar o Amazon EventBridge para redimensionar imagens em uma programação não processa as imagens em tempo real, resultando em atrasos significativos que impactariam negativamente a experiência do usuário.  

</details>
---

### Questão [111]
Uma empresa recentemente migrou um sistema de processamento de mensagens para a AWS. O sistema recebe mensagens em uma fila ActiveMQ executando em uma instância Amazon EC2. As mensagens são processadas por um aplicativo consumidor que também é executado em uma instância Amazon EC2. O aplicativo consumidor processa as mensagens e grava os resultados em um banco de dados MySQL executando em uma instância Amazon EC2. A empresa deseja que este aplicativo seja altamente disponível, com baixa complexidade operacional.  
Qual arquitetura oferece a MAIOR disponibilidade?  

A. Adicione um segundo servidor ActiveMQ em outra zona de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Replique o banco de dados MySQL para outra zona de disponibilidade.  

B. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Replique o banco de dados MySQL para outra zona de disponibilidade.
  
C. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.  

D. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione um grupo de Auto Scaling para as instâncias EC2 consumidoras em duas zonas de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione um grupo de Auto Scaling para as instâncias EC2 consumidoras em duas zonas de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon MQ com brokers ativo/standby:** O Amazon MQ é uma solução gerenciada que oferece alta disponibilidade ao configurar brokers em modo ativo/standby em múltiplas zonas de disponibilidade. Isso elimina a complexidade operacional de gerenciar servidores ActiveMQ manualmente.  
  - **Auto Scaling para consumidores:** Um grupo de Auto Scaling distribuído por várias zonas de disponibilidade garante alta disponibilidade e escalabilidade automática para o aplicativo consumidor, lidando com falhas ou variações na carga de trabalho.  
  - **Amazon RDS for MySQL com Multi-AZ:** O RDS oferece replicação síncrona para uma instância standby em uma zona de disponibilidade diferente, garantindo alta disponibilidade para o banco de dados com gerenciamento simplificado.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Configurar servidores ActiveMQ manualmente aumenta a complexidade operacional. Além disso, gerenciar a replicação do banco de dados EC2 manualmente adiciona mais riscos e esforço operacional.  
  - **B:** Usar Amazon MQ melhora a disponibilidade da fila de mensagens, mas a replicação manual do MySQL não é tão confiável quanto o Multi-AZ do Amazon RDS.  
  - **C:** Embora o Amazon MQ e o RDS Multi-AZ ofereçam alta disponibilidade para as filas de mensagens e o banco de dados, adicionar apenas uma instância EC2 adicional para consumidores não garante alta disponibilidade nem escalabilidade.  

</details>

---

### Questão [112]
Uma empresa hospeda um aplicativo web conteinerizado em uma frota de servidores locais que processam solicitações de entrada. O número de solicitações está crescendo rapidamente, e os servidores locais não conseguem lidar com o aumento. A empresa deseja mover o aplicativo para a AWS com o mínimo de alterações no código e esforço de desenvolvimento.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?  

A. Use o AWS Fargate no Amazon Elastic Container Service (Amazon ECS) para executar o aplicativo web conteinerizado com Service Auto Scaling. Use um Application Load Balancer para distribuir as solicitações de entrada.  

B. Use duas instâncias Amazon EC2 para hospedar o aplicativo web conteinerizado. Use um Application Load Balancer para distribuir as solicitações de entrada. 

C. Use o AWS Lambda com um novo código que utilize uma das linguagens suportadas. Crie várias funções Lambda para suportar a carga. Use o Amazon API Gateway como ponto de entrada para as funções Lambda.  

D. Use uma solução de computação de alto desempenho (HPC), como o AWS ParallelCluster, para estabelecer um cluster que possa processar as solicitações de entrada na escala apropriada.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Use o AWS Fargate no Amazon Elastic Container Service (Amazon ECS) para executar o aplicativo web conteinerizado com Service Auto Scaling. Use um Application Load Balancer para distribuir as solicitações de entrada.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Fargate** permite executar contêineres sem a necessidade de gerenciar servidores subjacentes, reduzindo significativamente o esforço operacional.  
  - O **Service Auto Scaling** no Amazon ECS ajusta automaticamente o número de tarefas do contêiner com base na carga, garantindo alta disponibilidade e escalabilidade.  
  - O **Application Load Balancer (ALB)** distribui as solicitações de entrada de maneira eficiente entre os contêineres em execução, garantindo melhor desempenho.  
  - Essa abordagem requer o mínimo de alterações no código existente, pois o aplicativo já está conteinerizado.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Usar instâncias Amazon EC2 para hospedar os contêineres aumenta a carga operacional, pois a empresa precisará gerenciar o provisionamento, escalabilidade e manutenção dos servidores manualmente.  
  - **C:** Embora o AWS Lambda ofereça uma solução sem servidor, essa opção exigiria alterações significativas no código para adaptar o aplicativo ao modelo de execução baseado em eventos. Isso contradiz o requisito de "mínimo de alterações no código".  
  - **D:** O AWS ParallelCluster é projetado para cargas de trabalho de computação de alto desempenho (HPC) e não é adequado para hospedar aplicativos web com contêineres. Ele adiciona complexidade desnecessária para este caso de uso.  

</details>
---

### Questão [113]
Uma empresa utiliza 50 TB de dados para relatórios. A empresa deseja mover esses dados do local para a AWS. Um aplicativo personalizado no data center da empresa executa um trabalho semanal de transformação de dados. A empresa planeja pausar o aplicativo até que a transferência de dados seja concluída e precisa iniciar o processo de transferência o mais rápido possível.  
O data center não tem largura de banda de rede disponível para cargas de trabalho adicionais. Um arquiteto de soluções deve transferir os dados e configurar o trabalho de transformação para continuar a ser executado na nuvem AWS.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?  

A. Use o AWS DataSync para mover os dados. Crie um trabalho de transformação personalizado usando o AWS Glue.  

B. Solicite um dispositivo AWS Snowcone para mover os dados. Implante o aplicativo de transformação no dispositivo.  

C. Solicite um dispositivo AWS Snowball Edge Storage Optimized. Copie os dados para o dispositivo. Crie um trabalho de transformação personalizado usando o AWS Glue.  

D. Solicite um dispositivo AWS Snowball Edge Storage Optimized que inclua computação Amazon EC2. Copie os dados para o dispositivo. Crie uma nova instância EC2 na AWS para executar o aplicativo de transformação.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**C.** Solicite um dispositivo AWS Snowball Edge Storage Optimized. Copie os dados para o dispositivo. Crie um trabalho de transformação personalizado usando o AWS Glue.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Snowball Edge Storage Optimized** é ideal para transferir grandes volumes de dados (50 TB) do local para a AWS sem depender da largura de banda de rede disponível.  
  - Após a transferência, os dados podem ser carregados no S3, onde o **AWS Glue** pode ser usado para criar e gerenciar o trabalho de transformação de dados com esforço operacional mínimo.  
  - Essa solução oferece escalabilidade e integra o processo de transformação diretamente com o ecossistema AWS, minimizando a necessidade de gerenciar infraestrutura adicional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O AWS DataSync depende de conectividade de rede para transferir dados. Como o data center não possui largura de banda de rede disponível, esta opção não é viável.  
  - **B:** O AWS Snowcone é projetado para volumes menores de dados e não é adequado para transferir 50 TB de forma eficiente.  
  - **D:** Embora o AWS Snowball Edge com computação EC2 seja uma opção viável, o uso de uma instância EC2 adicional para executar o trabalho de transformação aumenta a complexidade operacional em comparação com o uso do AWS Glue, que é gerenciado pela AWS.  

</details>

---

### Questão [114]
Uma empresa criou um aplicativo de análise de imagens no qual os usuários podem fazer upload de fotos e adicionar molduras às suas imagens. Os usuários enviam imagens e metadados para indicar quais molduras de fotos desejam adicionar às suas imagens. O aplicativo usa uma única instância Amazon EC2 e o Amazon DynamoDB para armazenar os metadados.  
O aplicativo está se tornando mais popular, e o número de usuários está aumentando. A empresa espera que o número de usuários simultâneos varie significativamente dependendo do horário do dia e do dia da semana. A empresa deve garantir que o aplicativo possa escalar para atender às necessidades da crescente base de usuários.  
Qual solução atende a esses requisitos?  

A. Use o AWS Lambda para processar as fotos. Armazene as fotos e os metadados no DynamoDB.  

B. Use o Amazon Kinesis Data Firehose para processar as fotos e armazenar as fotos e os metadados.  

C. Use o AWS Lambda para processar as fotos. Armazene as fotos no Amazon S3. Retenha o DynamoDB para armazenar os metadados.

D. Aumente o número de instâncias EC2 para três. Use volumes Provisioned IOPS SSD (io2) do Amazon Elastic Block Store (Amazon EBS) para armazenar as fotos e os metadados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**C.** Use o AWS Lambda para processar as fotos. Armazene as fotos no Amazon S3. Retenha o DynamoDB para armazenar os metadados.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS Lambda:** Usar o AWS Lambda elimina a necessidade de gerenciar servidores, permitindo que o processamento de fotos seja escalado automaticamente com base no volume de solicitações.  
  - **Amazon S3:** O S3 é um serviço altamente escalável, durável e econômico para armazenar fotos, especialmente em cenários com variação significativa no número de usuários.  
  - **Amazon DynamoDB:** O DynamoDB é uma solução altamente escalável e gerenciada para armazenar metadados. Ele pode lidar facilmente com variações no número de usuários e cargas de trabalho.  
  - Essa combinação oferece escalabilidade automática e baixa complexidade operacional para lidar com o aumento do número de usuários e suas variações.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora o AWS Lambda seja uma boa escolha para o processamento, armazenar fotos no DynamoDB não é eficiente nem econômico. O DynamoDB é otimizado para metadados e não para grandes objetos como imagens.  
  - **B:** O Amazon Kinesis Data Firehose é usado para ingestão e entrega de dados de streaming, mas não é ideal para processamento de imagens individuais ou armazenamento de fotos.  
  - **D:** Escalar instâncias EC2 manualmente e usar volumes io2 do Amazon EBS aumenta a complexidade operacional e não oferece escalabilidade automática, o que contradiz o requisito de suportar variações significativas no número de usuários.  

</details>

---

### Questão [115]
Uma empresa de registros médicos está hospedando um aplicativo em instâncias Amazon EC2. O aplicativo processa arquivos de dados de clientes armazenados no Amazon S3. As instâncias EC2 estão hospedadas em sub-redes públicas. As instâncias EC2 acessam o Amazon S3 pela internet, mas não precisam de nenhum outro acesso à rede.  
Um novo requisito determina que o tráfego de rede para transferências de arquivos siga uma rota privada e não seja enviado pela internet.  
Qual alteração na arquitetura de rede um arquiteto de soluções deve recomendar para atender a esse requisito?  

A. Crie um gateway NAT. Configure a tabela de rotas para as sub-redes públicas para enviar o tráfego para o Amazon S3 por meio do gateway NAT.  

B. Configure o grupo de segurança das instâncias EC2 para restringir o tráfego de saída, permitindo apenas o tráfego para a lista de prefixos do S3.  

C. Mova as instâncias EC2 para sub-redes privadas. Crie um endpoint de VPC para o Amazon S3 e vincule o endpoint à tabela de rotas das sub-redes privadas.

D. Remova o gateway da internet da VPC. Configure uma conexão AWS Direct Connect e roteie o tráfego para o Amazon S3 por meio da conexão Direct Connect.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**C.** Mova as instâncias EC2 para sub-redes privadas. Crie um endpoint de VPC para o Amazon S3 e vincule o endpoint à tabela de rotas das sub-redes privadas.

**Justificativa:**  
- **Por que essa opção?**  
  - Um **endpoint de VPC para o Amazon S3** permite que o tráfego entre a VPC e o Amazon S3 seja roteado internamente pela rede da AWS, sem passar pela internet.  
  - Mover as instâncias EC2 para sub-redes privadas elimina a necessidade de um IP público ou de uma conexão direta à internet, atendendo ao requisito de manter o tráfego privado.  
  - Vincular o endpoint à tabela de rotas das sub-redes privadas garante que todo o tráfego destinado ao Amazon S3 use o endpoint privado, mantendo a conformidade com o requisito.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Usar um gateway NAT ainda resultaria em tráfego passando pela internet, mesmo que seja roteado de forma segura. Isso não atende ao requisito de manter o tráfego totalmente privado.  
  - **B:** Restringir o tráfego com um grupo de segurança não altera a rota do tráfego, que ainda passaria pela internet.  
  - **D:** Configurar uma conexão Direct Connect é uma solução mais complexa e cara, além de não ser necessária para transferências dentro da rede da AWS.  

</details>
---

### Questão [116]
Uma empresa utiliza um sistema de gerenciamento de conteúdo (CMS) popular para o site corporativo. No entanto, os patches e a manutenção necessários são onerosos. A empresa está redesenhando seu site e quer uma nova solução. O site será atualizado quatro vezes por ano e não precisa ter nenhum conteúdo dinâmico disponível. A solução deve oferecer alta escalabilidade e segurança aprimorada.  
Quais combinações de mudanças atenderão a esses requisitos com o MENOR esforço operacional? (Escolha duas.)  

A. Configure o Amazon CloudFront na frente do site para usar funcionalidade HTTPS.  

B. Implemente uma ACL da Web do AWS WAF na frente do site para fornecer funcionalidade HTTPS.  

C. Crie e implemente uma função AWS Lambda para gerenciar e servir o conteúdo do site.  

D. Crie o novo site e um bucket Amazon S3. Implemente o site no bucket S3 com o hosting de site estático ativado. 

E. Crie o novo site. Implemente o site usando um grupo de Auto Scaling de instâncias Amazon EC2 atrás de um Application Load Balancer.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**A.** Configure o Amazon CloudFront na frente do site para usar funcionalidade HTTPS.  
**D.** Crie o novo site e um bucket Amazon S3. Implemente o site no bucket S3 com o hosting de site estático ativado.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** O **Amazon CloudFront** é uma rede de distribuição de conteúdo (CDN) que melhora a segurança, fornecendo suporte para HTTPS, além de aumentar a escalabilidade ao armazenar em cache o conteúdo estático em locais de borda.  
  - **D:** Hospedar o site em um **bucket S3** com hosting de site estático ativado é uma solução altamente escalável e com baixa manutenção para conteúdo estático. O S3 oferece uma maneira econômica e simples de servir páginas web estáticas.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **AWS WAF** é usado para proteger aplicativos web contra ataques comuns, mas ele não fornece funcionalidade HTTPS por conta própria. O WAF pode ser usado em conjunto com o CloudFront, mas não substitui o uso do HTTPS do CloudFront para este caso.  
  - **C:** Usar uma função **AWS Lambda** para servir o conteúdo do site adicionaria complexidade desnecessária e não é ideal para um site com conteúdo estático que não exige processamento dinâmico.  
  - **E:** Implementar o site em instâncias EC2 com um Application Load Balancer aumenta significativamente o esforço operacional e os custos em comparação com o uso de S3 e CloudFront para conteúdo estático.  

</details>

---

### Questão [117]
Uma empresa armazena os logs de sua aplicação em um grupo de logs do Amazon CloudWatch Logs. Uma nova política exige que a empresa armazene todos os logs da aplicação no Amazon OpenSearch Service (anteriormente Amazon Elasticsearch Service) em tempo quase real.  
Qual solução atenderá a este requisito com o MENOR esforço operacional?  

A. Configure uma assinatura do CloudWatch Logs para transmitir os logs para o Amazon OpenSearch Service.  

B. Crie uma função AWS Lambda. Use o grupo de logs para invocar a função e gravar os logs no Amazon OpenSearch Service. 

C. Crie um fluxo de entrega do Amazon Kinesis Data Firehose. Configure o grupo de logs como a origem do fluxo de entrega. Configure o Amazon OpenSearch Service como o destino do fluxo de entrega.  

D. Instale e configure o Amazon Kinesis Agent em cada servidor da aplicação para enviar os logs para o Amazon Kinesis Data Streams. Configure o Kinesis Data Streams para enviar os logs ao Amazon OpenSearch Service.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Configure uma assinatura do CloudWatch Logs para transmitir os logs para o Amazon OpenSearch Service.

**Justificativa:**  
- **Por que essa opção?**  
  - Configurar uma assinatura do **CloudWatch Logs** é a solução mais simples e com menor esforço operacional. As assinaturas permitem que você transmita os logs diretamente de um grupo de logs do CloudWatch para o **Amazon OpenSearch Service**, fornecendo integração nativa e em tempo quase real.  
  - Isso elimina a necessidade de configurar ou gerenciar serviços intermediários, como Lambda ou Kinesis, tornando-o altamente eficiente.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Usar uma função AWS Lambda para processar e transmitir os logs aumenta a complexidade operacional, pois seria necessário gerenciar a função Lambda, incluindo a escalabilidade e a integração com o OpenSearch.  
  - **C:** O **Kinesis Data Firehose** pode ser usado para transmitir os logs ao OpenSearch Service, mas introduz um serviço intermediário desnecessário, aumentando o esforço operacional em comparação com a transmissão direta do CloudWatch Logs.  
  - **D:** Configurar o Kinesis Agent em cada servidor adiciona complexidade significativa, especialmente em ambientes com muitos servidores. Essa abordagem também não utiliza a integração nativa do CloudWatch Logs com o OpenSearch Service.  

</details>
---

### Questão [118]
Uma empresa está desenvolvendo um aplicativo web baseado em instâncias Amazon EC2 em várias zonas de disponibilidade. O aplicativo web fornecerá acesso a um repositório de documentos de texto totalizando cerca de 900 TB. A empresa prevê que o aplicativo enfrentará períodos de alta demanda. Um arquiteto de soluções deve garantir que o componente de armazenamento para os documentos de texto possa escalar para atender à demanda do aplicativo a qualquer momento. A empresa está preocupada com o custo total da solução.  
Qual solução de armazenamento atende a esses requisitos de forma MAIS econômica?  

A. Amazon Elastic Block Store (Amazon EBS)  

B. Amazon Elastic File System (Amazon EFS)  

C. Amazon OpenSearch Service (Amazon Elasticsearch Service)  

D. Amazon S3  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Amazon S3

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon S3** é uma solução altamente escalável, durável e econômica para armazenar grandes volumes de dados, como os 900 TB mencionados na questão.  
  - Ele suporta alta demanda sem necessidade de configuração manual de escalabilidade e é otimizado para acesso a objetos armazenados.  
  - Comparado a outras opções, o custo do S3 é significativamente menor, especialmente considerando o volume de armazenamento necessário.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **Amazon EBS** é projetado para armazenamento conectado a instâncias individuais e não é otimizado para compartilhamento entre múltiplas instâncias. Além disso, o gerenciamento de 900 TB em volumes EBS seria caro e operacionalmente complexo.  
  - **B:** O **Amazon EFS** é ideal para sistemas de arquivos compartilhados e dinâmicos, mas é mais caro que o S3 para armazenamento em larga escala, como 900 TB.  
  - **C:** O **Amazon OpenSearch Service** (anteriormente Elasticsearch) é projetado para análise e pesquisa, não para armazenamento de documentos em larga escala. Usá-lo apenas como solução de armazenamento seria ineficiente e caro.  

</details>

---

### Questão [119]
Uma empresa global está usando o Amazon API Gateway para projetar APIs REST para os usuários do seu clube de fidelidade nas regiões **us-east-1** e **ap-southeast-2**. Um arquiteto de soluções deve projetar uma solução para proteger essas APIs REST gerenciadas pelo API Gateway em várias contas contra ataques de **injeção de SQL** e **cross-site scripting** (XSS).  
Qual solução atenderá a esses requisitos com o MENOR esforço administrativo?  

A. Configure o AWS WAF em ambas as regiões. Associe web ACLs regionais a um estágio da API.  

B. Configure o AWS Firewall Manager em ambas as regiões. Configure centralmente as regras do AWS WAF.  

C. Configure o AWS Shield em ambas as regiões. Associe web ACLs regionais a um estágio da API.  

D. Configure o AWS Shield em uma das regiões. Associe web ACLs regionais a um estágio da API.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Configure o AWS WAF em ambas as regiões. Associe web ACLs regionais a um estágio da API.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS WAF** é projetado especificamente para proteger aplicativos web contra ataques comuns, como injeção de SQL e cross-site scripting (XSS).  
  - Associar web ACLs regionais diretamente aos estágios das APIs no API Gateway é simples e eficiente, garantindo proteção em ambas as regiões.  
  - Essa abordagem atende ao requisito com o menor esforço administrativo, pois o WAF é gerenciado pela AWS e pode ser configurado diretamente para o API Gateway.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **AWS Firewall Manager** é usado para gerenciar centralmente políticas de segurança em várias contas e regiões, mas ele adiciona complexidade desnecessária neste caso, já que o objetivo é proteger apenas APIs específicas em duas regiões.  
  - **C:** O **AWS Shield** é projetado para proteção contra ataques DDoS. Ele não oferece proteção contra injeção de SQL ou cross-site scripting, tornando-o inadequado para os requisitos da questão.  
  - **D:** Configurar o AWS Shield em apenas uma região não protegerá a API na outra região. Além disso, como mencionado anteriormente, o Shield não oferece proteção contra ataques de injeção de SQL ou XSS.  

</details>

---

### Questão [120]
Uma empresa implementou uma solução de DNS autogerenciada em três instâncias Amazon EC2 atrás de um Network Load Balancer (NLB) na região **us-west-2**. A maioria dos usuários da empresa está localizada nos Estados Unidos e na Europa. A empresa deseja melhorar o desempenho e a disponibilidade da solução. A empresa lança e configura três instâncias EC2 na região **eu-west-1** e as adiciona como alvos para um novo NLB.  
Qual solução a empresa pode usar para rotear o tráfego para todas as instâncias EC2?  

A. Crie uma política de roteamento de geolocalização no Amazon Route 53 para rotear as solicitações para um dos dois NLBs. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

B. Crie um acelerador padrão no AWS Global Accelerator. Crie grupos de endpoints em **us-west-2** e **eu-west-1**. Adicione os dois NLBs como endpoints para os grupos de endpoints.  

C. Anexe Elastic IPs às seis instâncias EC2. Crie uma política de roteamento de geolocalização no Amazon Route 53 para rotear as solicitações para uma das seis instâncias EC2. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

D. Substitua os dois NLBs por dois Application Load Balancers (ALBs). Crie uma política de roteamento de latência no Amazon Route 53 para rotear as solicitações para um dos dois ALBs. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**B.** Crie um acelerador padrão no AWS Global Accelerator. Crie grupos de endpoints em **us-west-2** e **eu-west-1**. Adicione os dois NLBs como endpoints para os grupos de endpoints.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Global Accelerator** fornece endereços IP fixos e roteia o tráfego de forma otimizada para os endpoints mais próximos, melhorando o desempenho e a disponibilidade para os usuários.  
  - A configuração de grupos de endpoints em ambas as regiões (**us-west-2** e **eu-west-1**) permite que o tráfego seja roteado automaticamente para o NLB mais próximo com base na proximidade do usuário.  
  - Global Accelerator é projetado para aplicativos globais e oferece alta resiliência e baixa latência, além de ser fácil de configurar e gerenciar.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Uma política de roteamento de geolocalização no Route 53 e o uso do CloudFront como origem adicionam complexidade desnecessária e não oferecem os benefícios de desempenho e latência reduzida que o Global Accelerator oferece.  
  - **C:** Usar Elastic IPs diretamente com instâncias EC2 aumenta a complexidade operacional, pois requer o gerenciamento individual de instâncias e não oferece balanceamento de carga ou failover eficiente.  
  - **D:** Substituir os NLBs por ALBs pode melhorar o suporte a aplicativos baseados em HTTP/HTTPS, mas essa solução depende apenas de uma política de latência no Route 53, que não fornece a otimização global e resiliência que o Global Accelerator oferece.  

</details>

---

### Questão [121]
Uma empresa está executando uma carga de trabalho de processamento de transações online (OLTP) na AWS. Essa carga de trabalho utiliza uma instância Amazon RDS DB não criptografada em uma implantação Multi-AZ. Snapshots diários do banco de dados são criados a partir dessa instância.  
O que um arquiteto de soluções deve fazer para garantir que o banco de dados e os snapshots estejam sempre criptografados daqui em diante?  

A. Criptografe uma cópia do snapshot mais recente do banco de dados. Substitua a instância de banco de dados existente restaurando o snapshot criptografado. 

B. Crie um novo volume Amazon Elastic Block Store (Amazon EBS) criptografado e copie os snapshots para ele. Habilite a criptografia na instância do banco de dados.  

C. Copie os snapshots e habilite a criptografia usando o AWS Key Management Service (AWS KMS). Restaure o snapshot criptografado para uma instância de banco de dados existente.  

D. Copie os snapshots para um bucket Amazon S3 que esteja criptografado usando criptografia no lado do servidor com chaves gerenciadas pelo AWS Key Management Service (SSE-KMS).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Criptografe uma cópia do snapshot mais recente do banco de dados. Substitua a instância de banco de dados existente restaurando o snapshot criptografado.

**Justificativa:**  
- **Por que essa opção?**  
  - O Amazon RDS não permite habilitar a criptografia diretamente em uma instância de banco de dados existente. No entanto, você pode criptografar um snapshot existente ao fazer uma cópia criptografada dele.  
  - Uma vez que o snapshot esteja criptografado, você pode restaurá-lo para criar uma nova instância do RDS com criptografia habilitada. A partir de então, todos os novos snapshots dessa instância também estarão criptografados.  
  - Este é o método recomendado pela AWS para adicionar criptografia a uma instância de banco de dados não criptografada.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Não é possível habilitar criptografia diretamente em uma instância RDS existente ou copiar snapshots para volumes EBS para criptografá-los.  
  - **C:** Embora seja possível copiar snapshots e criptografá-los, você não pode restaurar um snapshot criptografado para uma instância existente. Deve-se criar uma nova instância a partir do snapshot criptografado.  
  - **D:** Copiar os snapshots para um bucket S3 criptografado protege apenas os snapshots no S3, mas não criptografa a instância RDS subjacente nem os futuros snapshots criados diretamente do banco de dados.  

</details>

---

### Questão [122]
Uma empresa deseja construir uma infraestrutura escalável de gerenciamento de chaves para dar suporte a desenvolvedores que precisam criptografar dados em seus aplicativos.  
O que um arquiteto de soluções deve fazer para reduzir a carga operacional?  

A. Use autenticação multifator (MFA) para proteger as chaves de criptografia.  

B. Use o AWS Key Management Service (AWS KMS) para proteger as chaves de criptografia. 

C. Use o AWS Certificate Manager (ACM) para criar, armazenar e atribuir as chaves de criptografia.

D. Use uma política IAM para limitar o escopo de usuários que têm permissões de acesso para proteger as chaves de criptografia.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**B.** Use o AWS Key Management Service (AWS KMS) para proteger as chaves de criptografia.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Key Management Service (AWS KMS)** é um serviço gerenciado que permite criar, gerenciar e usar chaves de criptografia com esforço operacional mínimo. Ele oferece integração nativa com outros serviços da AWS e SDKs para desenvolvedores usarem criptografia facilmente em seus aplicativos.  
  - O KMS reduz a carga operacional ao lidar automaticamente com tarefas como rotação de chaves, gerenciamento de permissões granulares e auditoria do uso das chaves no AWS CloudTrail.  
  - Ele é altamente escalável e projetado para suportar aplicativos em grande escala.  

- **Por que as outras opções não são adequadas?**  
  - **A:** A autenticação multifator (MFA) melhora a segurança do acesso às chaves, mas não resolve o problema de gerenciamento de chaves em grande escala, nem reduz significativamente a carga operacional.  
  - **C:** O **AWS Certificate Manager (ACM)** é projetado para gerenciar certificados SSL/TLS, não chaves de criptografia gerais. Ele não atende à necessidade de suportar a criptografia de dados em aplicativos.  
  - **D:** Limitar o escopo de usuários com uma política IAM é uma prática recomendada para segurança, mas não aborda diretamente a questão de gerenciamento escalável de chaves. Essa abordagem seria complementar ao uso do AWS KMS.  

</details>

---

### Questão [123]
Uma empresa tem um aplicativo web dinâmico hospedado em duas instâncias Amazon EC2. A empresa possui seu próprio certificado SSL, que está instalado em cada instância para realizar a terminação SSL.  
Recentemente, houve um aumento no tráfego, e a equipe de operações determinou que a criptografia e descriptografia SSL está fazendo com que a capacidade de computação dos servidores web atinja o limite máximo.  
O que um arquiteto de soluções deve fazer para aumentar o desempenho do aplicativo?  

A. Crie um novo certificado SSL usando o AWS Certificate Manager (ACM). Instale o certificado ACM em cada instância.  

B. Crie um bucket Amazon S3. Migre o certificado SSL para o bucket S3. Configure as instâncias EC2 para referenciar o bucket para terminação SSL.  

C. Crie outra instância EC2 como um servidor proxy. Migre o certificado SSL para a nova instância e configure-a para direcionar conexões para as instâncias EC2 existentes.  

D. Importe o certificado SSL para o AWS Certificate Manager (ACM). Crie um Application Load Balancer com um listener HTTPS que use o certificado SSL do ACM.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Importe o certificado SSL para o AWS Certificate Manager (ACM). Crie um Application Load Balancer com um listener HTTPS que use o certificado SSL do ACM.

**Justificativa:**  
- **Por que essa opção?**  
  - Ao usar um **Application Load Balancer (ALB)** com terminação SSL, o tráfego HTTPS é processado pelo ALB, eliminando a carga de criptografia/descriptografia das instâncias EC2. Isso reduz a utilização da capacidade computacional dos servidores web, melhorando o desempenho.  
  - O **AWS Certificate Manager (ACM)** permite importar e gerenciar certificados SSL/TLS com facilidade, sem necessidade de gerenciar manualmente os certificados em cada instância EC2.  
  - Essa abordagem fornece uma solução escalável e gerenciada para lidar com o aumento no tráfego.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Criar um novo certificado ACM e instalá-lo em cada instância EC2 não resolverá o problema de carga computacional causada pela terminação SSL. O problema de desempenho persistirá.  
  - **B:** Usar um bucket S3 para armazenar certificados SSL e configurá-los para referência pelas instâncias EC2 não é uma abordagem suportada ou apropriada para terminação SSL.  
  - **C:** Adicionar uma instância proxy com terminação SSL desloca o problema de carga computacional para a nova instância proxy, o que não resolve o problema de forma eficiente e escalável.  

</details>
---

### Questão [124]
Uma empresa tem um trabalho de processamento em lote altamente dinâmico que utiliza muitas instâncias Amazon EC2 para completá-lo. O trabalho é **sem estado**, pode ser iniciado e interrompido a qualquer momento sem impacto negativo e geralmente leva mais de 60 minutos para ser concluído. A empresa pediu a um arquiteto de soluções para projetar uma solução escalável e econômica que atenda aos requisitos do trabalho.  
O que o arquiteto de soluções deve recomendar?  

A. Implementar instâncias Spot do EC2.  

B. Comprar instâncias reservadas do EC2.  

C. Implementar instâncias sob demanda do EC2.  

D. Implementar o processamento no AWS Lambda.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Implementar instâncias Spot do EC2.

**Justificativa:**  
- **Por que essa opção?**  
  - As **instâncias Spot do EC2** são altamente econômicas e ideais para cargas de trabalho **sem estado** que podem ser interrompidas e retomadas sem impacto significativo, como o processamento em lote descrito.  
  - As instâncias Spot permitem economias de custo de até 90% em comparação com instâncias sob demanda.  
  - Como o trabalho é dinâmico e sem estado, ele pode lidar com a interrupção de instâncias Spot, tornando essa opção escalável e econômica.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Instâncias reservadas são mais adequadas para cargas de trabalho previsíveis e de longo prazo. Elas não oferecem flexibilidade para lidar com a natureza dinâmica do trabalho descrito e são mais caras que instâncias Spot.  
  - **C:** Instâncias sob demanda fornecem flexibilidade, mas são significativamente mais caras que instâncias Spot para uma carga de trabalho como essa.  
  - **D:** O AWS Lambda é mais adequado para tarefas de curta duração e baseadas em eventos, não para trabalhos em lote que levam mais de 60 minutos para serem concluídos.  

</details>

---


### Questão [125]
Uma empresa opera seu site de comércio eletrônico de duas camadas na AWS. A camada web consiste em um balanceador de carga que envia tráfego para instâncias Amazon EC2. A camada de banco de dados usa uma instância Amazon RDS DB. As instâncias EC2 e a instância RDS DB não devem ser expostas à internet pública. As instâncias EC2 precisam de acesso à internet para concluir o processamento de pagamentos por meio de um serviço web de terceiros. A aplicação deve ser altamente disponível.  
Quais combinações de opções de configuração atenderão a esses requisitos? (Escolha duas.)  

A. Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes privadas. Implemente uma instância RDS Multi-AZ em sub-redes privadas. 

B. Configure uma VPC com duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes privadas.  

C. Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes públicas em duas zonas de disponibilidade. Implemente uma instância RDS Multi-AZ em sub-redes privadas.  

D. Configure uma VPC com uma sub-rede pública, uma sub-rede privada e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer na sub-rede pública.  

E. Configure uma VPC com duas sub-redes públicas, duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes públicas.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**A.** Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes privadas. Implemente uma instância RDS Multi-AZ em sub-redes privadas.  
**E.** Configure uma VPC com duas sub-redes públicas, duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes públicas.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** As instâncias EC2 na camada web e a instância RDS na camada de banco de dados devem ser colocadas em sub-redes privadas para garantir que não sejam expostas à internet pública. Isso melhora a segurança. A implementação de RDS em uma configuração Multi-AZ garante alta disponibilidade.  
  - **E:** Configurar sub-redes públicas para o Application Load Balancer permite que ele receba tráfego público da internet e o redirecione para as instâncias EC2 em sub-redes privadas. Os NAT gateways permitem que as instâncias EC2 em sub-redes privadas acessem a internet para comunicações de saída (como o processamento de pagamentos).  

- **Por que as outras opções não são adequadas?**  
  - **B:** Implementar um Application Load Balancer em sub-redes privadas o tornaria inacessível à internet pública, o que não atende aos requisitos de receber tráfego público.  
  - **C:** Lançar instâncias EC2 em sub-redes públicas exporia essas instâncias diretamente à internet, o que viola o requisito de segurança de não expor os servidores públicos.  
  - **D:** Usar apenas uma sub-rede pública e uma sub-rede privada em uma VPC não é suficiente para garantir alta disponibilidade, pois o design depende de múltiplas zonas de disponibilidade.  

</details>

---

### Questão [126]
Um arquiteto de soluções precisa implementar uma solução para reduzir os custos de armazenamento de uma empresa. Todos os dados da empresa estão atualmente na classe de armazenamento **Amazon S3 Standard**. A empresa deve manter todos os dados por pelo menos 25 anos. Os dados dos últimos 2 anos devem ser altamente disponíveis e imediatamente recuperáveis.  
Qual solução atenderá a esses requisitos?  

A. Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive imediatamente.  

B. Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive após 2 anos.  

C. Use o S3 Intelligent-Tiering. Ative a opção de arquivamento para garantir que os dados sejam arquivados no S3 Glacier Deep Archive.

D. Configure uma política do S3 Lifecycle para transferir objetos para o S3 One Zone-Infrequent Access (S3 One Zone-IA) imediatamente e para o S3 Glacier Deep Archive após 2 anos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**B.** Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive após 2 anos.

**Justificativa:**  
- **Por que essa opção?**  
  - A classe de armazenamento **S3 Glacier Deep Archive** é projetada para retenção de longo prazo de dados que são acessados raramente, sendo a opção mais econômica para armazenamento de 25 anos.  
  - A política do **S3 Lifecycle** permite que os dados permaneçam na classe **S3 Standard** (altamente disponível e imediatamente recuperável) pelos primeiros 2 anos, atendendo ao requisito de acesso imediato. Após esse período, os dados podem ser movidos para o **S3 Glacier Deep Archive** para reduzir os custos.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Mover objetos para o S3 Glacier Deep Archive imediatamente viola o requisito de que os dados dos últimos 2 anos devem ser altamente disponíveis e imediatamente recuperáveis.  
  - **C:** O **S3 Intelligent-Tiering** é útil para dados com padrões de acesso imprevisíveis. No entanto, ele não garante a retenção de dados em uma classe específica por 2 anos antes de movê-los para o **S3 Glacier Deep Archive**, tornando-o inadequado para este caso de uso.  
  - **D:** O **S3 One Zone-IA** oferece uma opção de menor custo para dados acessados raramente, mas não é apropriado para dados críticos, pois depende de uma única zona de disponibilidade. Além disso, o requisito de alta disponibilidade para os últimos 2 anos não é atendido com esta abordagem.  

</details>

---

### Questão [127]
Uma empresa de mídia está avaliando a possibilidade de mover seus sistemas para a AWS Cloud. A empresa precisa de pelo menos 10 TB de armazenamento com o máximo de desempenho de I/O para processamento de vídeo, 300 TB de armazenamento altamente durável para armazenar conteúdo de mídia, e 900 TB de armazenamento para arquivamento de mídia que não está mais em uso.  
Qual conjunto de serviços um arquiteto de soluções deve recomendar para atender a esses requisitos?  

A. Amazon EBS para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.

B. Amazon EBS para desempenho máximo, Amazon EFS para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.  

C. Amazon EC2 instance store para desempenho máximo, Amazon EFS para armazenamento durável de dados e Amazon S3 para armazenamento de arquivos.  

D. Amazon EC2 instance store para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A.** Amazon EBS para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon EBS (Elastic Block Store):** É a melhor escolha para o processamento de vídeo que requer desempenho máximo de I/O e armazenamento de bloco persistente. Ele suporta volumes otimizados para altas taxas de transferência de dados, sendo ideal para cargas de trabalho intensivas como processamento de vídeo.  
  - **Amazon S3:** É uma solução altamente durável e escalável para armazenamento de conteúdo de mídia, com integração nativa com outros serviços AWS e suporte a altas taxas de armazenamento de dados (300 TB neste caso).  
  - **Amazon S3 Glacier:** É ideal para arquivamento de longo prazo de dados raramente acessados, com custos muito baixos, atendendo ao requisito de armazenamento de 900 TB para mídias não utilizadas.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora o EFS seja adequado para sistemas de arquivos compartilhados, ele não é tão econômico quanto o S3 para armazenar grandes volumes de dados (300 TB).  
  - **C:** O **EC2 instance store** oferece desempenho alto, mas não é persistente, o que significa que os dados podem ser perdidos se a instância for interrompida. Isso o torna inadequado para cargas de trabalho que exigem armazenamento confiável. Além disso, o S3 não é otimizado para arquivamento em comparação com o S3 Glacier.  
  - **D:** Semelhante à opção anterior, o **EC2 instance store** não oferece persistência de dados e não é confiável para armazenamento de longo prazo.  

</details>

---

### Questão [128]
Uma empresa deseja executar aplicativos em contêineres na AWS Cloud. Esses aplicativos são sem estado e podem tolerar interrupções na infraestrutura subjacente. A empresa precisa de uma solução que minimize os custos e o esforço operacional.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Use instâncias Spot em um grupo de Auto Scaling do Amazon EC2 para executar os contêineres de aplicativos.  

B. Use instâncias Spot em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).  

C. Use instâncias sob demanda em um grupo de Auto Scaling do Amazon EC2 para executar os contêineres de aplicativos.  

D. Use instâncias sob demanda em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**B.** Use instâncias Spot em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon EKS com instâncias Spot:** O Amazon EKS é uma solução gerenciada para executar contêineres em Kubernetes, reduzindo significativamente o esforço operacional. Ele fornece uma infraestrutura escalável e de baixo custo.  
  - **Instâncias Spot:** Instâncias Spot são altamente econômicas e ideais para cargas de trabalho que podem tolerar interrupções, como aplicativos sem estado. Elas reduzem significativamente os custos em comparação com instâncias sob demanda.  
  - Combinar o Amazon EKS com instâncias Spot oferece uma solução que minimiza tanto os custos quanto o esforço operacional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora instâncias Spot em um Auto Scaling group do EC2 sejam econômicas, essa solução não aproveita a automação e os benefícios de gerenciamento que o EKS oferece, aumentando o esforço operacional.  
  - **C:** Usar instâncias sob demanda em um Auto Scaling group do EC2 é mais caro do que usar instâncias Spot, e não tira proveito da abstração e do gerenciamento que o EKS fornece.  
  - **D:** Instâncias sob demanda em um grupo de nós gerenciados do EKS fornecem automação e gerenciamento, mas a escolha de instâncias sob demanda aumenta significativamente os custos em comparação com instâncias Spot.  

</details>

---

### Questão [129]
**Tradução:**  
Uma empresa está executando um aplicativo web de várias camadas localmente. O aplicativo web é conteinerizado e executado em vários hosts Linux conectados a um banco de dados PostgreSQL que contém registros de usuários. O esforço operacional de manter a infraestrutura e planejar a capacidade está limitando o crescimento da empresa. Um arquiteto de soluções deve melhorar a infraestrutura do aplicativo.  
Quais combinações de ações o arquiteto de soluções deve realizar para alcançar isso? (Escolha duas.)  

A. Migre o banco de dados PostgreSQL para o Amazon Aurora.

B. Migre o aplicativo web para ser hospedado em instâncias Amazon EC2.  

C. Configure uma distribuição Amazon CloudFront para o conteúdo do aplicativo web.  

D. Configure o Amazon ElastiCache entre o aplicativo web e o banco de dados PostgreSQL. 

E. Migre o aplicativo web para ser hospedado no AWS Fargate com Amazon Elastic Container Service (Amazon ECS).  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
**A.** Migre o banco de dados PostgreSQL para o Amazon Aurora.  
**E.** Migre o aplicativo web para ser hospedado no AWS Fargate com Amazon Elastic Container Service (Amazon ECS).

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** Migrar o banco de dados PostgreSQL para o **Amazon Aurora** reduz o esforço operacional, pois o Aurora é um serviço gerenciado, altamente escalável e otimizado para desempenho. Ele elimina a necessidade de manutenção de hardware e planejamento de capacidade para o banco de dados.  
  - **E:** Hospedar o aplicativo web no **AWS Fargate** com o **Amazon ECS** elimina a necessidade de gerenciar servidores subjacentes, reduzindo a sobrecarga operacional. O Fargate é ideal para aplicativos conteinerizados, permitindo escalabilidade automática e integração com outros serviços AWS.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Migrar o aplicativo web para instâncias Amazon EC2 ainda exigiria gerenciamento e manutenção de servidores, o que não resolve o problema de sobrecarga operacional.  
  - **C:** Configurar o **Amazon CloudFront** para distribuição de conteúdo pode melhorar o desempenho para usuários finais, mas não resolve os problemas principais de sobrecarga operacional e planejamento de capacidade.  
  - **D:** Usar o **Amazon ElastiCache** pode melhorar o desempenho ao reduzir a carga no banco de dados PostgreSQL, mas não aborda diretamente a sobrecarga operacional associada à infraestrutura subjacente.  

</details>

---

### Questão [130]
Um aplicativo é executado em instâncias Amazon EC2 distribuídas por várias zonas de disponibilidade. As instâncias estão em um grupo de Auto Scaling do Amazon EC2 atrás de um Application Load Balancer. O aplicativo funciona melhor quando a utilização de CPU das instâncias EC2 está em ou próximo de 40%.  
O que um arquiteto de soluções deve fazer para manter o desempenho desejado em todas as instâncias do grupo?  

A. Use uma política de escalabilidade simples para escalar dinamicamente o grupo de Auto Scaling.  

B. Use uma política de rastreamento de destino para escalar dinamicamente o grupo de Auto Scaling.  

C. Use uma função AWS Lambda para atualizar a capacidade desejada do grupo de Auto Scaling.  

D. Use ações de escalabilidade agendadas para aumentar e reduzir o grupo de Auto Scaling.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**B.** Use uma política de rastreamento de destino para escalar dinamicamente o grupo de Auto Scaling.

**Justificativa:**  
- **Por que essa opção?**  
  - Uma **política de rastreamento de destino** ajusta automaticamente o tamanho do grupo de Auto Scaling para atingir um valor de métrica-alvo específico, como a utilização da CPU. Nesse caso, configurar o rastreamento para manter a utilização de CPU em torno de 40% garante o desempenho ideal do aplicativo.  
  - Essa abordagem é eficiente e reduz o esforço operacional, pois o Auto Scaling ajusta automaticamente o número de instâncias com base na métrica-alvo configurada.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Uma política de escalabilidade simples baseia-se em alarmes que acionam ações específicas, mas não garante que a utilização da CPU será mantida em 40%.  
  - **C:** Usar uma função AWS Lambda para ajustar manualmente a capacidade desejada adiciona complexidade operacional desnecessária e não é uma solução automatizada como as políticas do Auto Scaling.  
  - **D:** Ações de escalabilidade agendadas funcionam bem para cargas de trabalho previsíveis, mas não são adequadas para ajustes dinâmicos e métricas variáveis, como a utilização da CPU.  

</details>

---

### Questão [131]
Uma empresa está desenvolvendo um aplicativo de compartilhamento de arquivos que usará um bucket do Amazon S3 para armazenamento. A empresa deseja servir todos os arquivos por meio de uma distribuição do Amazon CloudFront. A empresa não quer que os arquivos sejam acessíveis por navegação direta para o URL do S3.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Escreva políticas individuais para cada bucket S3 para conceder permissão de leitura apenas para o acesso do CloudFront.  

B. Crie um usuário IAM. Conceda permissão de leitura para objetos no bucket S3. Atribua o usuário ao CloudFront.  

C. Escreva uma política de bucket S3 que atribua o ID da distribuição do CloudFront como o Principal e atribua o bucket S3 como o Amazon Resource Name (ARN). 

D. Crie uma identidade de acesso de origem (OAI). Atribua a OAI à distribuição do CloudFront. Configure as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**D.** Crie uma identidade de acesso de origem (OAI). Atribua a OAI à distribuição do CloudFront. Configure as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura.

**Justificativa:**  
- **Por que essa opção?**  
  - Uma **Origin Access Identity (OAI)** é usada para garantir que o acesso aos objetos em um bucket S3 seja permitido apenas por meio de uma distribuição do **CloudFront**. Isso impede o acesso direto aos URLs do S3.  
  - Configurar as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura garante que os arquivos só possam ser acessados por meio do CloudFront.  
  - Essa abordagem é uma prática recomendada para proteger arquivos servidos pelo CloudFront.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Escrever políticas individuais para cada bucket S3 é desnecessário e não garante que o acesso direto ao S3 será bloqueado.  
  - **B:** Criar um usuário IAM para gerenciar o acesso do CloudFront não é o método correto, pois o IAM não controla diretamente o acesso entre o CloudFront e o S3.  
  - **C:** Especificar o ID da distribuição
**CloudFront** como principal na política do bucket S3 não é suportado. O CloudFront usa a OAI para gerenciar permissões de acesso ao S3 de forma segura.

</details>

---

### Questão #132
Uma empresa disponibiliza em seu site relatórios de desempenho histórico para download pelos usuários. O site precisa de uma solução que escale para atender às demandas globais da empresa. A solução deve ser econômica, limitar o provisionamento de recursos de infraestrutura e oferecer o menor tempo de resposta possível.  
Qual combinação um arquiteto de soluções deve recomendar para atender a esses requisitos?

**Alternativas:**
A. Amazon CloudFront e Amazon S3  

B. AWS Lambda e Amazon DynamoDB  

C. Application Load Balancer com Amazon EC2 Auto Scaling  

D. Amazon Route 53 com Application Load Balancers internos  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
**A:** Amazon CloudFront e Amazon S3

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon S3** é um serviço de armazenamento altamente escalável e econômico, ideal para hospedar arquivos estáticos, como relatórios para download. Ele reduz os custos e elimina a necessidade de provisionar e gerenciar servidores de infraestrutura.
  - O **Amazon CloudFront** é uma rede de entrega de conteúdo (CDN) que garante a distribuição global eficiente e com baixa latência dos arquivos armazenados no S3, atendendo ao requisito de menor tempo de resposta para usuários em diferentes partes do mundo.  
  - Essa combinação é econômica, escalável e não exige provisionamento manual de recursos de infraestrutura.

**Por que as outras opções não são adequadas?**  
- **B:** AWS Lambda e Amazon DynamoDB  
  - AWS Lambda é ideal para execução de código sem provisionamento de servidores, e DynamoDB é usado para armazenamento de dados em tabelas NoSQL. No entanto, essa combinação não é apropriada para distribuir arquivos grandes e estáticos, como relatórios para download, e não oferece a melhor latência para entrega global.  
- **C:** Application Load Balancer com Amazon EC2 Auto Scaling  
  - Essa abordagem requer o provisionamento e a manutenção de instâncias EC2. Embora escalável, não é a solução mais econômica nem oferece a melhor latência global quando comparada ao CloudFront.  
- **D:** Amazon Route 53 com Application Load Balancers internos  
  - O Route 53 pode ser usado para rotear tráfego globalmente, mas, ao utilizar apenas balanceadores de carga internos, a solução não é otimizada para entrega de conteúdo estático globalmente e não atende ao requisito de menor tempo de resposta.  

</details>

---

### Questão #133
Uma empresa executa um banco de dados Oracle localmente. Como parte da migração para a AWS, a empresa deseja atualizar o banco de dados para a versão mais recente disponível. A empresa também quer configurar recuperação de desastres (DR) para o banco de dados. É necessário minimizar a sobrecarga operacional para operações normais e configuração de DR. Além disso, a empresa precisa manter acesso ao sistema operacional subjacente do banco de dados.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Migrar o banco de dados Oracle para uma instância Amazon EC2. Configurar replicação do banco de dados para uma Região diferente da AWS.  

B. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Ativar backups automatizados entre Regiões para replicar os snapshots para outra Região AWS.  

C. Migrar o banco de dados Oracle para Amazon RDS Custom para Oracle. Criar uma réplica de leitura do banco de dados em outra Região AWS.  

D. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Criar um banco de dados standby em outra Zona de Disponibilidade (AZ).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
C. Migrar o banco de dados Oracle para Amazon RDS Custom para Oracle. Criar uma réplica de leitura do banco de dados em outra Região AWS.

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon RDS Custom para Oracle** permite que os usuários mantenham acesso ao sistema operacional subjacente, atendendo ao requisito de manter esse nível de controle.
  - A réplica de leitura em outra região fornece uma configuração eficiente de recuperação de desastres (DR) com replicação contínua e facilita a escalabilidade para leitura em múltiplas regiões.  
  - Além disso, o RDS Custom reduz a sobrecarga operacional, já que automatiza várias tarefas de gerenciamento de banco de dados enquanto mantém flexibilidade para personalizações.

**Por que as outras opções não são adequadas?**  
- A. Migrar o banco de dados Oracle para uma instância Amazon EC2. Configurar replicação do banco de dados para uma Região diferente da AWS.  
  - Embora permita acesso ao sistema operacional, essa solução exige alta sobrecarga operacional para gerenciar a infraestrutura e configurar manualmente a replicação, o que não atende ao requisito de minimizar a sobrecarga.  
- B. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Ativar backups automatizados entre Regiões para replicar os snapshots para outra Região AWS.  
  - Essa abordagem reduz a sobrecarga operacional, mas o RDS padrão não oferece acesso ao sistema operacional subjacente, o que não atende a um requisito importante.  
- D. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Criar um banco de dados standby em outra Zona de Disponibilidade (AZ).  
  - Essa configuração oferece alta disponibilidade (HA) em vez de recuperação de desastres (DR) entre Regiões. Além disso, o RDS padrão não permite acesso ao sistema operacional.  

</details>

---

### Questão #134
Uma empresa deseja migrar sua aplicação para uma solução serverless. A solução serverless precisa analisar dados existentes e novos usando SQL. A empresa armazena os dados em um bucket do Amazon S3. Os dados exigem criptografia e devem ser replicados para outra Região AWS.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?

**Alternativas:**
A. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon Athena para consultar os dados.  

B. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon RDS para consultar os dados.  

C. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon Athena para consultar os dados.  

D. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon RDS para consultar os dados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
A. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon Athena para consultar os dados.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon S3 Cross-Region Replication (CRR):** Configura a replicação automática de objetos para outro bucket em uma Região diferente, atendendo ao requisito de replicação.  
  - **Criptografia SSE-KMS com chaves multi-Região:** Garante que os dados sejam criptografados com um nível mais avançado de controle usando chaves gerenciadas pelo AWS KMS. Isso é mais seguro do que as chaves gerenciadas pelo S3 (SSE-S3).  
  - **Amazon Athena:** É uma solução serverless que permite consultas SQL diretamente nos dados armazenados no S3, eliminando a necessidade de provisionar e gerenciar um banco de dados relacional.  
  - Essa configuração minimiza o esforço operacional, utiliza uma arquitetura serverless e atende aos requisitos de criptografia e replicação.  

**Por que as outras opções não são adequadas?**  
- B. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon RDS para consultar os dados.  
  - Embora atenda aos requisitos de criptografia e replicação, o uso do Amazon RDS exige a configuração de uma instância de banco de dados, o que aumenta o esforço operacional e não é uma solução totalmente serverless.  
- C. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon Athena para consultar os dados.  
  - Apesar de ser uma solução serverless, a criptografia SSE-S3 oferece menos controle e segurança do que o SSE-KMS, tornando-a menos apropriada para dados sensíveis que exigem gerenciamento de chaves avançado.  
- D. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon RDS para consultar os dados.  
  - Assim como a opção C, a criptografia SSE-S3 não é a ideal. Além disso, o uso do Amazon RDS adiciona esforço operacional, contrariando o requisito de uma solução com baixo overhead.  

</details>

---

### Questão #135
Uma empresa executa cargas de trabalho na AWS. A empresa precisa se conectar a um serviço de um provedor externo. O serviço está hospedado na VPC do provedor. De acordo com a equipe de segurança da empresa, a conectividade deve ser privada e restrita ao serviço de destino. A conexão deve ser iniciada somente a partir da VPC da empresa.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Criar uma conexão de peering entre a VPC da empresa e a VPC do provedor. Atualizar a tabela de rotas para se conectar ao serviço de destino.  

B. Pedir ao provedor para criar um gateway privado virtual em sua VPC. Usar AWS PrivateLink para se conectar ao serviço de destino.  

C. Criar um gateway NAT em uma sub-rede pública da VPC da empresa. Atualizar a tabela de rotas para se conectar ao serviço de destino.  

D. Pedir ao provedor para criar um endpoint de VPC para o serviço de destino. Usar AWS PrivateLink para se conectar ao serviço de destino.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
D. Pedir ao provedor para criar um endpoint de VPC para o serviço de destino. Usar AWS PrivateLink para se conectar ao serviço de destino.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS PrivateLink** permite conexões privadas para serviços hospedados em outra VPC, garantindo que o tráfego nunca saia da rede da AWS. Essa abordagem atende aos requisitos de conectividade privada e restrita.  
  - O provedor cria um **endpoint de VPC**, que funciona como um ponto de entrada para o serviço. A VPC da empresa pode então usar o PrivateLink para acessar exclusivamente o serviço de destino.  
  - Essa solução também garante que a conexão seja iniciada somente da VPC da empresa, atendendo aos requisitos de segurança.

**Por que as outras opções não são adequadas?**  
- A. Criar uma conexão de peering entre a VPC da empresa e a VPC do provedor. Atualizar a tabela de rotas para se conectar ao serviço de destino.  
  - Uma conexão de peering permitiria conectividade entre as VPCs, mas não restringe o acesso apenas ao serviço de destino, o que não atende aos requisitos de segurança.  
- B. Pedir ao provedor para criar um gateway privado virtual em sua VPC. Usar AWS PrivateLink para se conectar ao serviço de destino.  
  - O gateway privado virtual (VPN) conecta VPCs ou redes locais, mas não é necessário neste caso, já que o PrivateLink é suficiente e mais direto para conectar ao serviço.  
- C. Criar um gateway NAT em uma sub-rede pública da VPC da empresa. Atualizar a tabela de rotas para se conectar ao serviço de destino.  
  - O gateway NAT permite conexões de saída para a internet, mas não oferece conectividade privada. Isso contraria o requisito de manter a conexão exclusivamente privada.  

</details>

---

### Questão #136
Uma empresa está migrando seu banco de dados PostgreSQL local para o Amazon Aurora PostgreSQL. O banco de dados local deve permanecer online e acessível durante a migração. O banco de dados Aurora deve permanecer sincronizado com o banco de dados local.  
Quais ações combinadas um arquiteto de soluções deve realizar para atender a esses requisitos? (Escolha duas.)

**Alternativas:**
A. Criar uma tarefa de replicação contínua.  

B. Criar um backup do banco de dados local.  

C. Criar um servidor de replicação do AWS Database Migration Service (AWS DMS).  

D. Converter o esquema do banco de dados usando o AWS Schema Conversion Tool (AWS SCT).  

E. Criar uma regra do Amazon EventBridge (Amazon CloudWatch Events) para monitorar a sincronização do banco de dados.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
A. Criar uma tarefa de replicação contínua.  
C. Criar um servidor de replicação do AWS Database Migration Service (AWS DMS).

**Justificativa:**  
- **Por que essas opções?**  
  - **A. Criar uma tarefa de replicação contínua:** Permite que o banco de dados Aurora seja continuamente sincronizado com o banco de dados local, atendendo ao requisito de manter os dados atualizados em tempo real durante a migração.  
  - **C. Criar um servidor de replicação do AWS DMS:** O AWS DMS é o serviço recomendado para migração de bancos de dados, permitindo configurar a replicação contínua entre o banco de dados local e o Aurora PostgreSQL. O servidor de replicação gerencia o processo de migração e sincronização.  

**Por que as outras opções não são adequadas?**  
- **B. Criar um backup do banco de dados local:** Embora útil para migração inicial de dados, essa abordagem não suporta sincronização contínua e não atende ao requisito de manter o banco de dados online durante a migração.  
- **D. Converter o esquema do banco de dados usando o AWS Schema Conversion Tool (AWS SCT):** Essa ferramenta é útil para converter esquemas ao migrar entre diferentes mecanismos de banco de dados, mas, neste caso, ambos os bancos de dados usam PostgreSQL. Não é necessário para essa migração.  
- **E. Criar uma regra do Amazon EventBridge (Amazon CloudWatch Events) para monitorar a sincronização do banco de dados:** Monitoramento não é um requisito explícito para manter a sincronização ou realizar a migração. Isso pode ser uma etapa complementar, mas não atende diretamente aos requisitos descritos.  

</details>

---

### Questão #137
Uma empresa usa o AWS Organizations para criar contas AWS dedicadas para cada unidade de negócios, permitindo que cada unidade gerencie sua conta de forma independente sob demanda. O destinatário do e-mail principal perdeu uma notificação enviada ao endereço de e-mail do usuário raiz de uma conta. A empresa deseja garantir que todas as notificações futuras não sejam perdidas. As notificações futuras devem ser limitadas aos administradores das contas.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Configurar o servidor de e-mail da empresa para encaminhar mensagens enviadas ao endereço de e-mail do usuário raiz da conta AWS para todos os usuários da organização.  

B. Configurar todos os endereços de e-mail do usuário raiz das contas AWS como listas de distribuição que enviem para alguns administradores capazes de responder aos alertas. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.  

C. Configurar todas as mensagens enviadas ao endereço de e-mail do usuário raiz das contas AWS para serem encaminhadas a um único administrador responsável por monitorar alertas e redirecionar esses alertas aos grupos apropriados.  

D. Configurar todas as contas AWS existentes e todas as novas contas criadas para usarem o mesmo endereço de e-mail do usuário raiz. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
B. Configurar todos os endereços de e-mail do usuário raiz das contas AWS como listas de distribuição que enviem para alguns administradores capazes de responder aos alertas. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.

**Justificativa:**  
- **Por que essa opção?**  
  - Configurar os endereços de e-mail do usuário raiz como listas de distribuição garante que múltiplos administradores recebam as notificações críticas enviadas para as contas raiz, reduzindo o risco de alertas serem ignorados.  
  - A configuração de contatos alternativos para as contas AWS permite que notificações importantes sejam enviadas diretamente aos administradores apropriados, eliminando a dependência exclusiva do usuário raiz para esse tipo de comunicação.  
  - Essa abordagem é escalável e evita o problema de notificações críticas serem perdidas.  

**Por que as outras opções não são adequadas?**  
- **A. Configurar o servidor de e-mail da empresa para encaminhar mensagens para todos os usuários da organização:**  
  - Encaminhar notificações para todos os usuários da organização pode inundar os destinatários com mensagens irrelevantes, não limitando as notificações apenas aos administradores.  
- **C. Configurar mensagens para serem enviadas a um único administrador:**  
  - Confiar em um único administrador não é uma prática recomendada, pois introduz um ponto único de falha. Isso também pode levar à perda de notificações se o administrador estiver indisponível.  
- **D. Configurar todas as contas para usarem o mesmo endereço de e-mail do usuário raiz:**  
  - Usar o mesmo endereço de e-mail para todas as contas não é recomendado, pois compromete a separação e a independência das contas, tornando mais difícil identificar de qual conta a notificação se originou.  

</details>

---

### Questão #138
Uma empresa executa sua aplicação de comércio eletrônico na AWS. Cada novo pedido é publicado como uma mensagem em uma fila RabbitMQ que roda em uma instância EC2 em uma única Zona de Disponibilidade. Essas mensagens são processadas por uma aplicação diferente que roda em outra instância EC2. Esta aplicação armazena os detalhes em um banco de dados PostgreSQL em outra instância EC2. Todas as instâncias EC2 estão na mesma Zona de Disponibilidade.  
A empresa precisa redesenhar sua arquitetura para proporcionar a maior disponibilidade com o menor esforço operacional.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam o banco de dados PostgreSQL. 

B. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.  

C. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a fila RabbitMQ. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.  

D. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a fila RabbitMQ. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Criar um terceiro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam o banco de dados PostgreSQL.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
B. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon MQ com RabbitMQ:** Substituir a instância EC2 que roda RabbitMQ pelo Amazon MQ reduz a sobrecarga operacional, pois o Amazon MQ é um serviço gerenciado que oferece alta disponibilidade com pares redundantes em configuração ativa/standby.  
  - **Auto Scaling Multi-AZ para a aplicação:** A criação de um grupo Multi-AZ com Auto Scaling para as instâncias que hospedam a aplicação garante maior disponibilidade e recuperação automática em caso de falha.  
  - **Amazon RDS para PostgreSQL:** Migrar o banco de dados para o Amazon RDS com implantação Multi-AZ elimina a necessidade de gerenciar manualmente a alta disponibilidade do PostgreSQL, ao mesmo tempo em que garante replicação automática e failover.  
  - Essa solução combina alta disponibilidade e baixo esforço operacional em todos os componentes da arquitetura.  

**Por que as outras opções não são adequadas?**  
- **A. Criar grupos de Auto Scaling para instâncias EC2 que hospedam o banco de dados:**  
  - Gerenciar manualmente um cluster PostgreSQL em EC2 com Auto Scaling exige maior esforço operacional comparado ao uso do Amazon RDS Multi-AZ, o que contraria o requisito de menor esforço operacional.  
- **C. Criar grupos de Auto Scaling Multi-AZ para o RabbitMQ em EC2:**  
  - Embora forneça escalabilidade, gerenciar RabbitMQ manualmente em EC2 requer mais esforço operacional. O Amazon MQ é uma solução gerenciada mais apropriada para o caso.  
- **D. Criar três grupos de Auto Scaling Multi-AZ em EC2 para todos os componentes:**  
  - Gerenciar RabbitMQ e PostgreSQL manualmente em EC2 aumenta significativamente a complexidade operacional. Essa abordagem não atende ao requisito de menor esforço operacional.  

</details>

---

### Questão #139
Uma equipe de relatórios recebe arquivos diariamente em um bucket Amazon S3. A equipe revisa e copia manualmente os arquivos desse bucket inicial para um bucket de análise no S3 todos os dias, no mesmo horário, para uso com o Amazon QuickSight. Outras equipes começaram a enviar mais arquivos e em tamanhos maiores para o bucket inicial do S3.  
A equipe de relatórios deseja mover os arquivos automaticamente para o bucket de análise assim que eles forem enviados ao bucket inicial. Além disso, deseja usar funções AWS Lambda para executar código de correspondência de padrões nos dados copiados. Por fim, a equipe deseja enviar os arquivos de dados para um pipeline no Amazon SageMaker Pipelines.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos com o MENOR esforço operacional?

**Alternativas:**
A. Criar uma função Lambda para copiar os arquivos para o bucket de análise. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.  

B. Criar uma função Lambda para copiar os arquivos para o bucket de análise. Configurar o bucket de análise para enviar notificações de eventos para o Amazon EventBridge (Amazon CloudWatch Events). Configurar uma regra ObjectCreated no EventBridge. Configurar Lambda e SageMaker Pipelines como destinos da regra.  

C. Configurar replicação no S3 entre os buckets. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.  

D. Configurar replicação no S3 entre os buckets. Configurar o bucket de análise para enviar notificações de eventos para o Amazon EventBridge (Amazon CloudWatch Events). Configurar uma regra ObjectCreated no EventBridge. Configurar Lambda e SageMaker Pipelines como destinos da regra.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
C. Configurar replicação no S3 entre os buckets. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.

**Justificativa:**  
- **Por que essa opção?**  
  - **Replicação no S3:** Configurar replicação automática entre os buckets do S3 garante que os arquivos sejam copiados para o bucket de análise assim que forem enviados para o bucket inicial, eliminando a necessidade de criar e gerenciar uma função Lambda para esta tarefa.  
  - **Notificação de evento S3:** Configurar uma notificação no bucket de análise permite invocar uma função Lambda e enviar dados para o Amazon SageMaker Pipelines automaticamente sempre que um novo objeto é criado no bucket de análise.  
  - **Menor esforço operacional:** A replicação S3 gerenciada reduz significativamente a carga operacional, e o uso de notificações do S3 elimina a necessidade de configurar EventBridge adicionalmente.  

**Por que as outras opções não são adequadas?**  
- **A. Criar uma função Lambda para copiar os arquivos para o bucket de análise:**  
  - Usar Lambda para copiar arquivos manualmente adiciona mais complexidade e aumenta o esforço operacional, uma vez que a replicação do S3 pode realizar essa tarefa automaticamente.  
- **B. Configurar notificações EventBridge no bucket de análise:**  
  - Usar EventBridge para notificar eventos no bucket de análise adiciona uma etapa extra que não é necessária, já que as notificações do S3 podem acionar diretamente a Lambda e o SageMaker Pipelines.  
- **D. Configurar replicação no S3 e notificações EventBridge no bucket de análise:**  
  - Embora a replicação seja correta, adicionar EventBridge como um intermediário aumenta a complexidade desnecessariamente, já que notificações do S3 são suficientes para atender aos requisitos.  

</details>

---

### Questão #140
Um arquiteto de soluções precisa ajudar uma empresa a otimizar os custos de execução de uma aplicação na AWS. A aplicação usará instâncias Amazon EC2, AWS Fargate e AWS Lambda para computação dentro da arquitetura.  
As instâncias EC2 executarão a camada de ingestão de dados da aplicação. O uso de EC2 será esporádico e imprevisível. As cargas de trabalho que rodam nas instâncias EC2 podem ser interrompidas a qualquer momento. A interface da aplicação será executada no Fargate, e o Lambda atenderá a camada de API. A utilização da interface e da camada de API será previsível ao longo do próximo ano.  
Qual combinação de opções de compra fornecerá a solução mais econômica para hospedar essa aplicação? (Escolha duas.)

**Alternativas:**
A. Usar Spot Instances para a camada de ingestão de dados. 

B. Usar instâncias On-Demand para a camada de ingestão de dados.  

C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API. 

D. Comprar instâncias reservadas All Upfront de 1 ano para a camada de ingestão de dados.  

E. Comprar um Savings Plan de instâncias EC2 de 1 ano para a interface e camada de API.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
A. Usar Spot Instances para a camada de ingestão de dados.  
C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API.

**Justificativa:**  
- **A. Usar Spot Instances para a camada de ingestão de dados:**  
  - Spot Instances são a opção mais econômica para cargas de trabalho esporádicas e tolerantes a interrupções, como a ingestão de dados. Elas oferecem descontos significativos em relação às instâncias On-Demand, reduzindo os custos para a camada de ingestão de dados.  
- **C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API:**  
  - Um Compute Savings Plan cobre qualquer tipo de computação na AWS (EC2, Fargate, Lambda) e fornece flexibilidade com descontos em contratos de longo prazo. Como o uso da interface e da camada de API será previsível ao longo de um ano, essa é a opção mais econômica.  

**Por que as outras opções não são adequadas?**  
- **B. Usar instâncias On-Demand para a camada de ingestão de dados:**  
  - Instâncias On-Demand são mais caras do que Spot Instances. Para uma carga de trabalho esporádica e tolerante a interrupções, Spot Instances são mais apropriadas.  
- **D. Comprar instâncias reservadas All Upfront de 1 ano para a camada de ingestão de dados:**  
  - As instâncias reservadas exigem um compromisso fixo, o que não é ideal para cargas de trabalho imprevisíveis e esporádicas como a ingestão de dados.  
- **E. Comprar um Savings Plan de instâncias EC2 de 1 ano para a interface e camada de API:**  
  - Um Savings Plan específico para instâncias EC2 limita-se a instâncias EC2 e não cobre Fargate e Lambda. O Compute Savings Plan é mais flexível e cobre todos os tipos de computação necessários.  

</details>

---


### Questão #141
Uma empresa opera um portal baseado na web que fornece aos usuários notícias globais de última hora, alertas locais e atualizações meteorológicas. O portal entrega uma visão personalizada para cada usuário, usando uma mistura de conteúdo estático e dinâmico. O conteúdo é servido por HTTPS através de um servidor de API que roda em uma instância Amazon EC2 atrás de um Application Load Balancer (ALB). A empresa quer que o portal forneça esse conteúdo aos usuários em todo o mundo o mais rápido possível.  
Como um arquiteto de soluções deve projetar a aplicação para garantir a MENOR latência para todos os usuários?

**Alternativas:**
A. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir todo o conteúdo estático e dinâmico, especificando o ALB como uma origem.  

B. Implantar o stack da aplicação em duas regiões AWS. Usar uma política de roteamento por latência do Amazon Route 53 para servir todo o conteúdo do ALB na região mais próxima.  

C. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir o conteúdo estático. Servir o conteúdo dinâmico diretamente do ALB.  

D. Implantar o stack da aplicação em duas regiões AWS. Usar uma política de roteamento por geolocalização do Amazon Route 53 para servir todo o conteúdo do ALB na região mais próxima.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
A. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir todo o conteúdo estático e dinâmico, especificando o ALB como uma origem.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon CloudFront:** É uma rede de entrega de conteúdo (CDN) global que reduz a latência ao armazenar conteúdo em caches próximos aos usuários. Ele suporta a entrega tanto de conteúdo estático quanto dinâmico.  
  - **ALB como origem:** O CloudFront pode ser configurado para usar o ALB como uma origem para conteúdo dinâmico, garantindo que todos os usuários recebam respostas com baixa latência.  
  - **Simples e eficaz:** Manter o stack em uma única região reduz a complexidade operacional, e o uso do CloudFront garante a menor latência para usuários globais.  

**Por que as outras opções não são adequadas?**  
- **B. Implantar em duas regiões com política de roteamento por latência no Route 53:**  
  - Ter duas regiões aumenta a complexidade e os custos operacionais. O Route 53 por si só não reduz significativamente a latência global, pois os dados ainda precisam ser servidos diretamente do ALB sem um cache distribuído.  
- **C. Usar o CloudFront para conteúdo estático e o ALB para conteúdo dinâmico:**  
  - Embora funcione, essa abordagem introduz latência adicional para conteúdo dinâmico, já que ele não se beneficia do cache distribuído do CloudFront.  
- **D. Implantar em duas regiões com política de roteamento por geolocalização no Route 53:**  
  - Similar à opção B, adicionar outra região aumenta a complexidade e os custos operacionais. Além disso, o roteamento por geolocalização não melhora a latência de forma tão eficaz quanto o uso de uma CDN como o CloudFront.  

</details>

---

### Questão #142
Uma empresa de jogos está projetando uma arquitetura altamente disponível. A aplicação roda em um kernel Linux modificado e suporta apenas tráfego baseado em UDP. A empresa precisa que a camada front-end forneça a melhor experiência possível para o usuário. Essa camada deve ter baixa latência, rotear o tráfego para a localização de borda mais próxima e fornecer endereços IP estáticos para entrada nos endpoints da aplicação.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Configurar o Amazon Route 53 para encaminhar solicitações para um Application Load Balancer. Usar AWS Lambda para a aplicação em um grupo de escalabilidade automática do AWS Application Auto Scaling.  

B. Configurar o Amazon CloudFront para encaminhar solicitações para um Network Load Balancer. Usar AWS Lambda para a aplicação em um grupo de escalabilidade automática do AWS Application Auto Scaling.  

C. Configurar o AWS Global Accelerator para encaminhar solicitações para um Network Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.  

D. Configurar o Amazon API Gateway para encaminhar solicitações para um Application Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
C. Configurar o AWS Global Accelerator para encaminhar solicitações para um Network Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS Global Accelerator:** Fornece endereços IP estáticos globais e roteia o tráfego para a localização de borda mais próxima, garantindo baixa latência e a melhor experiência do usuário.  
  - **Network Load Balancer (NLB):** Suporta tráfego baseado em UDP, atendendo ao requisito específico da aplicação.  
  - **Amazon EC2 com Auto Scaling:** Permite a execução do kernel Linux modificado com alta disponibilidade e escalabilidade automática para lidar com mudanças na demanda.  
  - Essa combinação atende a todos os requisitos de baixa latência, suporte a UDP, endereços IP estáticos e roteamento para a localização de borda mais próxima.  

**Por que as outras opções não são adequadas?**  
- **A. Route 53 com Application Load Balancer (ALB) e AWS Lambda:**  
  - O ALB não suporta tráfego UDP, apenas TCP e HTTP/HTTPS, tornando essa configuração incompatível. Além disso, o Lambda não permite kernels modificados.  
- **B. CloudFront com Network Load Balancer e AWS Lambda:**  
  - O Amazon CloudFront não suporta UDP, apenas HTTP/HTTPS. O uso de Lambda também não atende ao requisito de um kernel Linux modificado.  
- **D. API Gateway com Application Load Balancer e EC2:**  
  - O API Gateway é projetado para tráfego HTTP/HTTPS, não para UDP. Além disso, o ALB não suporta UDP, tornando essa configuração inviável.  

</details>

---
