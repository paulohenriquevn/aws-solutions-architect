### Questão 101
Um arquiteto de soluções está projetando uma VPC com sub-redes públicas e privadas. A VPC e as sub-redes utilizam blocos CIDR IPv4. Há uma sub-rede pública e uma sub-rede privada em cada uma das três zonas de disponibilidade (AZs) para alta disponibilidade. Um gateway da Internet é usado para fornecer acesso à Internet para as sub-redes públicas. As sub-redes privadas precisam de acesso à Internet para permitir que instâncias Amazon EC2 façam download de atualizações de software.  
O que o arquiteto de soluções deve fazer para habilitar o acesso à Internet para as sub-redes privadas?  

A. Crie três NAT gateways, um para cada sub-rede pública em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para o NAT gateway em sua AZ.  

B. Crie três instâncias NAT, uma para cada sub-rede privada em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para a instância NAT em sua AZ.  

C. Crie um segundo gateway da Internet em uma das sub-redes privadas. Atualize a tabela de rotas para as sub-redes privadas que encaminhem o tráfego fora da VPC para o gateway da Internet privado.  

D. Crie um gateway da Internet somente de saída em uma das sub-redes públicas. Atualize a tabela de rotas para as sub-redes privadas que encaminhem o tráfego fora da VPC para o gateway da Internet somente de saída.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Crie três NAT gateways, um para cada sub-rede pública em cada AZ. Crie uma tabela de rotas privada para cada AZ que encaminhe o tráfego fora da VPC para o NAT gateway em sua AZ.

**Justificativa:**  
- **Por que essa opção?**  
  O NAT gateway é a solução recomendada e gerenciada pela AWS para permitir que instâncias em sub-redes privadas acessem a Internet de forma segura, sem expô-las diretamente. Criar um NAT gateway em cada AZ melhora a alta disponibilidade, garantindo que, mesmo que uma AZ fique indisponível, as instâncias em outras AZs ainda possam acessar a Internet. Atualizar as tabelas de rotas privadas para redirecionar o tráfego fora da VPC para o NAT gateway da AZ correspondente garante a eficiência da rede e alta disponibilidade.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora as instâncias NAT possam cumprir a mesma função que os NAT gateways, elas exigem manutenção manual, como atualizações, escalabilidade e substituições em caso de falha. Isso aumenta o esforço operacional em comparação com o NAT gateway, que é gerenciado pela AWS.  
  - **C:** Não é possível criar múltiplos gateways da Internet em uma única VPC. O gateway da Internet é usado apenas para tráfego de sub-redes públicas e não pode ser diretamente anexado a sub-redes privadas.  
  - **D:** O gateway da Internet somente de saída é usado para tráfego IPv6. Como o problema descrito na questão envolve tráfego IPv4, essa opção não é aplicável.  

</details>

---

### Questão 102
**Tradução:**  
Uma empresa deseja migrar um data center local para a AWS. O data center hospeda um servidor SFTP que armazena seus dados em um sistema de arquivos baseado em NFS. O servidor contém 200 GB de dados que precisam ser transferidos. O servidor deve ser hospedado em uma instância Amazon EC2 que utiliza um sistema de arquivos Amazon Elastic File System (Amazon EFS).  

Quais combinações de etapas um arquiteto de soluções deve realizar para automatizar essa tarefa? (Escolha duas.)  

A. Inicie a instância EC2 na mesma zona de disponibilidade que o sistema de arquivos EFS.  
B. Instale um agente do AWS DataSync no data center local.  
C. Crie um volume secundário do Amazon Elastic Block Store (Amazon EBS) na instância EC2 para os dados.  
D. Use manualmente um comando de cópia do sistema operacional para enviar os dados para a instância EC2.  
E. Use o AWS DataSync para criar uma configuração de localização apropriada para o servidor SFTP local.  

<details>
<summary>Resposta</summary>
<resposta>B,E</resposta>

**Respostas corretas:**  
<resposta>B,E</resposta>

**B.** Instale um agente do AWS DataSync no data center local.  
**E.** Use o AWS DataSync para criar uma configuração de localização apropriada para o servidor SFTP local.

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O AWS DataSync é projetado para transferir dados de sistemas de arquivos locais para a AWS. Para usar o DataSync, é necessário instalar um agente no data center local que possa acessar os dados no sistema de arquivos NFS.  
  - **E:** Uma vez que o agente do DataSync está configurado, criar uma configuração de localização para o servidor SFTP local permite que o serviço saiba de onde transferir os dados. Essa abordagem automatiza o processo de transferência de dados e reduz a complexidade operacional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora seja uma boa prática posicionar a instância EC2 na mesma zona de disponibilidade que o EFS para minimizar a latência, essa etapa não é necessária para a migração automatizada dos dados.  
  - **C:** Criar um volume EBS adicional não é relevante, pois os dados serão armazenados diretamente no sistema de arquivos EFS, que é o objetivo final da configuração.  
  - **D:** Realizar a transferência manualmente com um comando do sistema operacional não é uma solução automatizada e, portanto, não atende ao requisito da questão.  

</details>
---

### Questão 103
Uma empresa tem um trabalho de extração, transformação e carga (ETL) do AWS Glue que é executado todos os dias no mesmo horário. O trabalho processa dados XML que estão em um bucket do Amazon S3. Novos dados são adicionados ao bucket do S3 diariamente. Um arquiteto de soluções percebe que o AWS Glue está processando todos os dados em cada execução.  
O que o arquiteto de soluções deve fazer para evitar que o AWS Glue reprocesse dados antigos?  

A. Edite o trabalho para usar **job bookmarks**.  

B. Edite o trabalho para excluir os dados após serem processados.  

C. Edite o trabalho definindo o campo **NumberOfWorkers** como 1.  

D. Use uma transformação de aprendizado de máquina (ML) **FindMatches**.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Edite o trabalho para usar **job bookmarks**.

**Justificativa:**  
- **Por que essa opção?**  
  Os **job bookmarks** do AWS Glue permitem que o serviço acompanhe os dados que já foram processados em execuções anteriores. Quando ativados, os **bookmarks** garantem que somente os novos dados adicionados ao bucket S3 sejam processados, evitando o reprocesamento desnecessário de dados antigos. Essa é a solução ideal para cenários de processamento incremental de dados.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Excluir os dados após o processamento pode ser problemático, especialmente se os dados precisarem ser armazenados para referência futura ou outros processos. Isso também não é uma prática recomendada para controle de dados.  
  - **C:** Alterar o número de trabalhadores não resolve o problema de reprocesamento, pois o número de trabalhadores afeta apenas o desempenho do trabalho, e não a lógica de processamento.  
  - **D:** A transformação **FindMatches** é usada para encontrar registros semelhantes ou correspondentes, mas não é relevante para evitar o reprocesamento de dados no contexto descrito.  

</details>
---
### Questão 104
Um arquiteto de soluções deve projetar uma infraestrutura altamente disponível para um site. O site é alimentado por servidores web Windows que rodam em instâncias Amazon EC2. O arquiteto de soluções deve implementar uma solução que possa mitigar um ataque DDoS em larga escala que se origina de milhares de endereços IP. O tempo de inatividade não é aceitável para o site.  
Quais ações o arquiteto de soluções deve tomar para proteger o site contra esse tipo de ataque? (Escolha duas.)  

A. Use o AWS Shield Advanced para interromper o ataque DDoS.  

B. Configure o Amazon GuardDuty para bloquear automaticamente os atacantes.  

C. Configure o site para usar o Amazon CloudFront para conteúdo estático e dinâmico.

D. Use uma função AWS Lambda para adicionar automaticamente os endereços IP dos atacantes às ACLs de rede da VPC.  

E. Use instâncias Spot do EC2 em um Auto Scaling group com uma política de escalabilidade baseada em rastreamento de destino definida para 80% de utilização da CPU.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**
<resposta>A,C</resposta>

**A.** Use o AWS Shield Advanced para interromper o ataque DDoS.  
**C.** Configure o site para usar o Amazon CloudFront para conteúdo estático e dinâmico.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** O **AWS Shield Advanced** oferece proteção avançada contra ataques DDoS, incluindo proteção para grandes ataques que utilizam milhares de IPs. Ele fornece detecção e mitigação automatizadas, reduzindo significativamente o impacto de ataques DDoS em larga escala.  
  - **C:** O **Amazon CloudFront** é uma rede de distribuição de conteúdo (CDN) que fornece proteção integrada contra ataques DDoS. Ele pode absorver grandes volumes de tráfego malicioso e filtrar solicitações antes que elas cheguem à infraestrutura do backend, reduzindo a carga sobre as instâncias EC2 e protegendo contra ataques volumétricos.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **Amazon GuardDuty** é uma ferramenta de detecção de ameaças e não bloqueia automaticamente os atacantes. Ele pode detectar atividades suspeitas, mas não oferece proteção ativa contra ataques DDoS.  
  - **D:** Usar uma função **AWS Lambda** para atualizar as ACLs de rede com IPs bloqueados não é escalável para ataques em larga escala com milhares de IPs. Além disso, ACLs têm limites para o número de regras, tornando essa abordagem inadequada.  
  - **E:** Usar instâncias Spot em um **Auto Scaling group** não é uma solução eficaz contra ataques DDoS. Embora a escalabilidade possa ajudar a lidar com tráfego legítimo elevado, as instâncias Spot podem ser interrompidas pela AWS a qualquer momento, o que comprometeria a disponibilidade do site durante um ataque.  

</details>

### Questão 105
Uma empresa está se preparando para implantar uma nova carga de trabalho sem servidor. Um arquiteto de soluções deve usar o princípio de menor privilégio para configurar permissões que serão usadas para executar uma função AWS Lambda. Uma regra do Amazon EventBridge (Amazon CloudWatch Events) irá invocar a função.  
Qual solução atende a esses requisitos?  

A. Adicione uma função de execução à função Lambda com **lambda:InvokeFunction** como a ação e **\*** como o principal.  

B. Adicione uma função de execução à função Lambda com **lambda:InvokeFunction** como a ação e **Service: lambda.amazonaws.com** como o principal.  

C. Adicione uma política baseada em recursos à função Lambda com **lambda:\*** como a ação e **Service: events.amazonaws.com** como o principal.  

D. Adicione uma política baseada em recursos à função Lambda com **lambda:InvokeFunction** como a ação e **Service: events.amazonaws.com** como o principal.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Adicione uma política baseada em recursos à função Lambda com **lambda:InvokeFunction** como a ação e **Service: events.amazonaws.com** como o principal.

**Justificativa:**  
- **Por que essa opção?**  
  Para permitir que o Amazon EventBridge (anteriormente Amazon CloudWatch Events) invoque a função Lambda, você precisa adicionar uma **política baseada em recursos** à função Lambda. A política deve conceder a permissão **lambda:InvokeFunction** e definir **events.amazonaws.com** como o principal autorizado a invocar a função. Isso segue o princípio de menor privilégio, pois só permite a ação necessária (invocar a função) para o serviço específico (EventBridge).  

- **Por que as outras opções não são adequadas?**  
  - **A:** Permitir **\*** como o principal concede acesso a qualquer entidade para invocar a função Lambda, violando o princípio de menor privilégio.  
  - **B:** A configuração da função de execução da Lambda com **lambda:InvokeFunction** e o principal **lambda.amazonaws.com** não é relevante para permitir que o EventBridge invoque a função. Isso trata do contexto de execução da própria Lambda, não de quem pode invocá-la.  
  - **C:** Conceder **lambda:\*** como ação na política baseada em recursos concede permissões excessivas, permitindo qualquer ação Lambda, o que viola o princípio de menor privilégio.  

</details>

---
### Questão 106
**Tradução:**  
Uma empresa está se preparando para armazenar dados confidenciais no Amazon S3. Por razões de conformidade, os dados devem ser criptografados em repouso. O uso das chaves de criptografia deve ser registrado para auditoria. As chaves devem ser rotacionadas a cada ano.  
Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?  

A. Criptografia no lado do servidor com chaves fornecidas pelo cliente (SSE-C).  

B. Criptografia no lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3).  

C. Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação manual.  

D. Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação automática.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Criptografia no lado do servidor com chaves do AWS KMS (SSE-KMS) com rotação automática.

**Justificativa:**  
- **Por que essa opção?**  
  O **AWS KMS (Key Management Service)** oferece suporte a criptografia com chaves gerenciadas pelo serviço, incluindo a funcionalidade de rotação automática anual. Ele também registra o uso das chaves no AWS CloudTrail, atendendo ao requisito de auditoria. Como a rotação é automática, essa abordagem minimiza o esforço operacional e é altamente eficiente, enquanto mantém conformidade e segurança.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **SSE-C** exige que o cliente forneça as chaves de criptografia e gerencie manualmente a rotação, aumentando significativamente o esforço operacional. Além disso, o Amazon S3 não registra automaticamente o uso dessas chaves para auditoria.  
  - **B:** O **SSE-S3** gerencia as chaves automaticamente, mas não registra o uso das chaves em logs detalhados como o AWS KMS, o que pode não atender aos requisitos de auditoria.  
  - **C:** O **SSE-KMS** com rotação manual atende aos requisitos de conformidade e auditoria, mas exige intervenção manual para rotacionar as chaves, tornando-o menos eficiente operacionalmente em comparação com a rotação automática.  

</details>
---

### Questão 107
Uma empresa de compartilhamento de bicicletas está desenvolvendo uma arquitetura em várias camadas para rastrear a localização de suas bicicletas durante as horas de operação de pico. A empresa deseja usar esses pontos de dados em sua plataforma de análise existente. Um arquiteto de soluções deve determinar a opção de várias camadas mais viável para dar suporte a essa arquitetura. Os pontos de dados devem ser acessíveis a partir da API REST.  
Qual ação atende a esses requisitos para armazenar e recuperar os dados de localização?  

A. Use o Amazon Athena com o Amazon S3.  

B. Use o Amazon API Gateway com o AWS Lambda.  

C. Use o Amazon QuickSight com o Amazon Redshift.  

D. Use o Amazon API Gateway com o Amazon Kinesis Data Analytics.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Use o Amazon API Gateway com o Amazon Kinesis Data Analytics.

**Justificativa:**  
- **Por que essa opção?**  
  O **Amazon API Gateway** permite expor uma API REST para os dados de localização. O **Amazon Kinesis Data Analytics** é ideal para processar dados em tempo real, como fluxos de localização de bicicletas, garantindo que os dados estejam disponíveis de maneira eficiente para integração com a plataforma analítica da empresa. Essa solução atende ao requisito de disponibilizar os dados de localização em tempo real via API REST, enquanto também suporta a integração com plataformas analíticas existentes.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **Amazon Athena** com o **Amazon S3** é uma boa solução para consultas interativas em dados armazenados, mas não é otimizado para dados em tempo real. Ele não atende aos requisitos de fornecer acesso em tempo real aos pontos de dados por meio de uma API REST.  
  - **B:** Embora o **Amazon API Gateway** com o **AWS Lambda** possa expor uma API REST, ele não é ideal para processar grandes volumes de dados em tempo real, como fluxos contínuos de localização de bicicletas.  
  - **C:** O **Amazon QuickSight** com o **Amazon Redshift** é uma solução para visualização de dados e análise em lote. Ele não oferece suporte a fluxos de dados em tempo real nem fornece uma API REST para acessar os dados diretamente.  

</details>

---

### Questão 108
Uma empresa possui um site de vendas de automóveis que armazena seus anúncios em um banco de dados no Amazon RDS. Quando um automóvel é vendido, o anúncio precisa ser removido do site e os dados devem ser enviados para vários sistemas de destino.  
Qual design um arquiteto de soluções deve recomendar?  

A. Crie uma função AWS Lambda acionada quando o banco de dados no Amazon RDS for atualizado para enviar as informações para uma fila do Amazon Simple Queue Service (Amazon SQS) para os destinos consumirem.  

B. Crie uma função AWS Lambda acionada quando o banco de dados no Amazon RDS for atualizado para enviar as informações para uma fila FIFO do Amazon Simple Queue Service (Amazon SQS) para os destinos consumirem. 

C. Inscreva-se em uma notificação de eventos do RDS e envie uma fila do Amazon Simple Queue Service (Amazon SQS) distribuída para vários tópicos do Amazon Simple Notification Service (Amazon SNS). Use funções AWS Lambda para atualizar os destinos. 

D. Inscreva-se em uma notificação de eventos do RDS e envie um tópico do Amazon Simple Notification Service (Amazon SNS) distribuído para várias filas do Amazon Simple Queue Service (Amazon SQS). Use funções AWS Lambda para atualizar os destinos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Inscreva-se em uma notificação de eventos do RDS e envie um tópico do Amazon Simple Notification Service (Amazon SNS) distribuído para várias filas do Amazon Simple Queue Service (Amazon SQS). Use funções AWS Lambda para atualizar os destinos.

**Justificativa:**  
- **Por que essa opção?**  
  O design utiliza notificações de eventos do Amazon RDS, que podem detectar alterações no banco de dados. O evento aciona um tópico do Amazon SNS que, por sua vez, pode ser "distribuído" (fanned out) para várias filas do Amazon SQS. Cada fila pode ser processada independentemente por funções AWS Lambda, que enviam os dados para os sistemas de destino. Essa arquitetura é escalável e desacoplada, permitindo que novos sistemas de destino sejam facilmente adicionados no futuro.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora uma função Lambda acionada diretamente pelo RDS possa enviar os dados para uma única fila SQS, essa abordagem não suporta a necessidade de "fan-out" para múltiplos sistemas de destino.  
  - **B:** Usar uma fila FIFO do SQS não é necessário neste caso, pois a ordem exata dos eventos não foi mencionada como um requisito. Fila padrão do SQS e SNS oferecem mais flexibilidade para lidar com múltiplos destinos.  
  - **C:** O design que utiliza uma fila SQS como ponto inicial para "fan-out" para múltiplos tópicos SNS não é eficiente, pois SNS é mais adequado para distribuição inicial (fan-out). Reverter o papel de SNS e SQS adiciona complexidade desnecessária.  

</details>

---

### Questão 109
Uma empresa precisa armazenar dados no Amazon S3 e deve impedir que os dados sejam alterados. A empresa deseja que novos objetos enviados ao Amazon S3 permaneçam inalteráveis por um período de tempo não especificado, até que a empresa decida modificá-los. Apenas usuários específicos na conta da AWS da empresa podem ter permissão para excluir os objetos.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Crie um cofre S3 Glacier. Aplique uma política de bloqueio de cofre "escreve-uma-vez, lê-muitas" (WORM) aos objetos.  

B. Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Defina um período de retenção de 100 anos. Use o modo de governança como o modo de retenção padrão do bucket S3 para novos objetos.  

C. Crie um bucket S3. Use o AWS CloudTrail para rastrear quaisquer eventos da API S3 que modifiquem os objetos. Quando notificado, restaure os objetos modificados de qualquer versão de backup que a empresa possua.  

D. Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Adicione uma retenção legal (legal hold) aos objetos. Adicione a permissão **s3:PutObjectLegalHold** às políticas IAM dos usuários que precisam excluir os objetos.  


<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Crie um bucket S3 com o S3 Object Lock habilitado. Habilite o versionamento. Adicione uma retenção legal (legal hold) aos objetos. Adicione a permissão **s3:PutObjectLegalHold** às políticas IAM dos usuários que precisam excluir os objetos.

**Justificativa:**  
- **Por que essa opção?**  
  O **S3 Object Lock** permite que os objetos no S3 sejam configurados para serem imutáveis, impedindo que sejam alterados ou excluídos durante um período de retenção ou enquanto uma retenção legal estiver aplicada. A retenção legal (legal hold) pode ser usada quando o período de retenção não é especificado e permite que usuários autorizados apliquem ou removam a retenção conforme necessário. Isso satisfaz os requisitos da empresa de evitar alterações até que uma decisão seja tomada.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O S3 Glacier Vault Lock é para arquivos armazenados em **S3 Glacier**, o que não é indicado para armazenamento regular de objetos que podem precisar ser acessados ou modificados eventualmente.  
  - **B:** Embora o S3 Object Lock com um período de retenção longo (100 anos) e modo de governança impeça alterações, ele não permite flexibilidade para modificar objetos antes que o período de retenção termine, a menos que uma alteração seja explicitamente autorizada por usuários com permissões especiais. Isso não atende ao requisito de modificar os objetos em um momento incerto.  
  - **C:** Usar o **AWS CloudTrail** para rastrear eventos e restaurar objetos manualmente adiciona complexidade e não impede proativamente alterações nos objetos.  

</details>
---

### Questão 110
Uma empresa de mídia social permite que os usuários enviem imagens para o seu site. O site é executado em instâncias Amazon EC2. Durante as solicitações de upload, o site redimensiona as imagens para um tamanho padrão e armazena as imagens redimensionadas no Amazon S3. Os usuários estão experimentando lentidão nas solicitações de upload para o site.  
A empresa precisa reduzir o acoplamento dentro do aplicativo e melhorar o desempenho do site. Um arquiteto de soluções deve projetar o processo de upload de imagens mais eficiente operacionalmente.  
Quais combinações de ações o arquiteto de soluções deve tomar para atender a esses requisitos? (Escolha duas.)  

A. Configure o aplicativo para enviar imagens para o S3 Glacier.  

B. Configure o servidor web para enviar as imagens originais para o Amazon S3.  

C. Configure o aplicativo para enviar imagens diretamente do navegador de cada usuário para o Amazon S3 por meio do uso de uma URL pré-assinada (presigned URL).  

D. Configure notificações de evento do S3 para invocar uma função AWS Lambda quando uma imagem for enviada. Use a função para redimensionar a imagem.  

E. Crie uma regra do Amazon EventBridge (Amazon CloudWatch Events) que invoque uma função AWS Lambda em uma programação para redimensionar as imagens enviadas.  

<details>
<summary>Resposta</summary>

**Respostas corretas:** 
<resposta>C,D</resposta>

**C.** Configure o aplicativo para enviar imagens diretamente do navegador de cada usuário para o Amazon S3 por meio do uso de uma URL pré-assinada (presigned URL).  
**D.** Configure notificações de evento do S3 para invocar uma função AWS Lambda quando uma imagem for enviada. Use a função para redimensionar a imagem.

**Justificativa:**  
- **Por que essas opções?**  
  - **C:** Usar URLs pré-assinadas permite que os usuários enviem imagens diretamente para o Amazon S3, eliminando a necessidade de o servidor web EC2 processar os uploads. Isso reduz significativamente o acoplamento e melhora o desempenho do site, pois reduz a carga no servidor.  
  - **D:** Configurar notificações de evento do S3 para invocar uma função Lambda automatiza o redimensionamento de imagens. A função Lambda processa as imagens enviadas para o S3, eliminando a necessidade de o servidor web realizar esse processamento, o que melhora o desempenho geral e mantém um design desacoplado.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O S3 Glacier é projetado para arquivamento de longo prazo, não para armazenamento de objetos frequentemente acessados como imagens. Ele não suporta redimensionamento eficiente ou rápido.  
  - **B:** Enviar as imagens originais para o Amazon S3 usando o servidor web não resolve o problema de desempenho, pois o servidor ainda gerencia a carga do upload.  
  - **E:** Usar o Amazon EventBridge para redimensionar imagens em uma programação não processa as imagens em tempo real, resultando em atrasos significativos que impactariam negativamente a experiência do usuário.  

</details>
---

### Questão 111
Uma empresa recentemente migrou um sistema de processamento de mensagens para a AWS. O sistema recebe mensagens em uma fila ActiveMQ executando em uma instância Amazon EC2. As mensagens são processadas por um aplicativo consumidor que também é executado em uma instância Amazon EC2. O aplicativo consumidor processa as mensagens e grava os resultados em um banco de dados MySQL executando em uma instância Amazon EC2. A empresa deseja que este aplicativo seja altamente disponível, com baixa complexidade operacional.  
Qual arquitetura oferece a MAIOR disponibilidade?  

A. Adicione um segundo servidor ActiveMQ em outra zona de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Replique o banco de dados MySQL para outra zona de disponibilidade.  

B. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Replique o banco de dados MySQL para outra zona de disponibilidade.
  
C. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione uma instância adicional do consumidor EC2 em outra zona de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.  

D. Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione um grupo de Auto Scaling para as instâncias EC2 consumidoras em duas zonas de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Use o Amazon MQ com brokers em modo ativo/standby configurados em duas zonas de disponibilidade. Adicione um grupo de Auto Scaling para as instâncias EC2 consumidoras em duas zonas de disponibilidade. Use o Amazon RDS for MySQL com Multi-AZ habilitado.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon MQ com brokers ativo/standby:** O Amazon MQ é uma solução gerenciada que oferece alta disponibilidade ao configurar brokers em modo ativo/standby em múltiplas zonas de disponibilidade. Isso elimina a complexidade operacional de gerenciar servidores ActiveMQ manualmente.  
  - **Auto Scaling para consumidores:** Um grupo de Auto Scaling distribuído por várias zonas de disponibilidade garante alta disponibilidade e escalabilidade automática para o aplicativo consumidor, lidando com falhas ou variações na carga de trabalho.  
  - **Amazon RDS for MySQL com Multi-AZ:** O RDS oferece replicação síncrona para uma instância standby em uma zona de disponibilidade diferente, garantindo alta disponibilidade para o banco de dados com gerenciamento simplificado.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Configurar servidores ActiveMQ manualmente aumenta a complexidade operacional. Além disso, gerenciar a replicação do banco de dados EC2 manualmente adiciona mais riscos e esforço operacional.  
  - **B:** Usar Amazon MQ melhora a disponibilidade da fila de mensagens, mas a replicação manual do MySQL não é tão confiável quanto o Multi-AZ do Amazon RDS.  
  - **C:** Embora o Amazon MQ e o RDS Multi-AZ ofereçam alta disponibilidade para as filas de mensagens e o banco de dados, adicionar apenas uma instância EC2 adicional para consumidores não garante alta disponibilidade nem escalabilidade.  

</details>

---

### Questão 112
Uma empresa hospeda um aplicativo web conteinerizado em uma frota de servidores locais que processam solicitações de entrada. O número de solicitações está crescendo rapidamente, e os servidores locais não conseguem lidar com o aumento. A empresa deseja mover o aplicativo para a AWS com o mínimo de alterações no código e esforço de desenvolvimento.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?  

A. Use o AWS Fargate no Amazon Elastic Container Service (Amazon ECS) para executar o aplicativo web conteinerizado com Service Auto Scaling. Use um Application Load Balancer para distribuir as solicitações de entrada.  

B. Use duas instâncias Amazon EC2 para hospedar o aplicativo web conteinerizado. Use um Application Load Balancer para distribuir as solicitações de entrada. 

C. Use o AWS Lambda com um novo código que utilize uma das linguagens suportadas. Crie várias funções Lambda para suportar a carga. Use o Amazon API Gateway como ponto de entrada para as funções Lambda.  

D. Use uma solução de computação de alto desempenho (HPC), como o AWS ParallelCluster, para estabelecer um cluster que possa processar as solicitações de entrada na escala apropriada.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Use o AWS Fargate no Amazon Elastic Container Service (Amazon ECS) para executar o aplicativo web conteinerizado com Service Auto Scaling. Use um Application Load Balancer para distribuir as solicitações de entrada.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Fargate** permite executar contêineres sem a necessidade de gerenciar servidores subjacentes, reduzindo significativamente o esforço operacional.  
  - O **Service Auto Scaling** no Amazon ECS ajusta automaticamente o número de tarefas do contêiner com base na carga, garantindo alta disponibilidade e escalabilidade.  
  - O **Application Load Balancer (ALB)** distribui as solicitações de entrada de maneira eficiente entre os contêineres em execução, garantindo melhor desempenho.  
  - Essa abordagem requer o mínimo de alterações no código existente, pois o aplicativo já está conteinerizado.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Usar instâncias Amazon EC2 para hospedar os contêineres aumenta a carga operacional, pois a empresa precisará gerenciar o provisionamento, escalabilidade e manutenção dos servidores manualmente.  
  - **C:** Embora o AWS Lambda ofereça uma solução sem servidor, essa opção exigiria alterações significativas no código para adaptar o aplicativo ao modelo de execução baseado em eventos. Isso contradiz o requisito de "mínimo de alterações no código".  
  - **D:** O AWS ParallelCluster é projetado para cargas de trabalho de computação de alto desempenho (HPC) e não é adequado para hospedar aplicativos web com contêineres. Ele adiciona complexidade desnecessária para este caso de uso.  

</details>
---

### Questão 113
Uma empresa utiliza 50 TB de dados para relatórios. A empresa deseja mover esses dados do local para a AWS. Um aplicativo personalizado no data center da empresa executa um trabalho semanal de transformação de dados. A empresa planeja pausar o aplicativo até que a transferência de dados seja concluída e precisa iniciar o processo de transferência o mais rápido possível.  
O data center não tem largura de banda de rede disponível para cargas de trabalho adicionais. Um arquiteto de soluções deve transferir os dados e configurar o trabalho de transformação para continuar a ser executado na nuvem AWS.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?  

A. Use o AWS DataSync para mover os dados. Crie um trabalho de transformação personalizado usando o AWS Glue.  

B. Solicite um dispositivo AWS Snowcone para mover os dados. Implante o aplicativo de transformação no dispositivo.  

C. Solicite um dispositivo AWS Snowball Edge Storage Optimized. Copie os dados para o dispositivo. Crie um trabalho de transformação personalizado usando o AWS Glue.  

D. Solicite um dispositivo AWS Snowball Edge Storage Optimized que inclua computação Amazon EC2. Copie os dados para o dispositivo. Crie uma nova instância EC2 na AWS para executar o aplicativo de transformação.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>C</resposta>

**C.** Solicite um dispositivo AWS Snowball Edge Storage Optimized. Copie os dados para o dispositivo. Crie um trabalho de transformação personalizado usando o AWS Glue.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Snowball Edge Storage Optimized** é ideal para transferir grandes volumes de dados (50 TB) do local para a AWS sem depender da largura de banda de rede disponível.  
  - Após a transferência, os dados podem ser carregados no S3, onde o **AWS Glue** pode ser usado para criar e gerenciar o trabalho de transformação de dados com esforço operacional mínimo.  
  - Essa solução oferece escalabilidade e integra o processo de transformação diretamente com o ecossistema AWS, minimizando a necessidade de gerenciar infraestrutura adicional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O AWS DataSync depende de conectividade de rede para transferir dados. Como o data center não possui largura de banda de rede disponível, esta opção não é viável.  
  - **B:** O AWS Snowcone é projetado para volumes menores de dados e não é adequado para transferir 50 TB de forma eficiente.  
  - **D:** Embora o AWS Snowball Edge com computação EC2 seja uma opção viável, o uso de uma instância EC2 adicional para executar o trabalho de transformação aumenta a complexidade operacional em comparação com o uso do AWS Glue, que é gerenciado pela AWS.  

</details>

---

### Questão 114
Uma empresa criou um aplicativo de análise de imagens no qual os usuários podem fazer upload de fotos e adicionar molduras às suas imagens. Os usuários enviam imagens e metadados para indicar quais molduras de fotos desejam adicionar às suas imagens. O aplicativo usa uma única instância Amazon EC2 e o Amazon DynamoDB para armazenar os metadados.  
O aplicativo está se tornando mais popular, e o número de usuários está aumentando. A empresa espera que o número de usuários simultâneos varie significativamente dependendo do horário do dia e do dia da semana. A empresa deve garantir que o aplicativo possa escalar para atender às necessidades da crescente base de usuários.  
Qual solução atende a esses requisitos?  

A. Use o AWS Lambda para processar as fotos. Armazene as fotos e os metadados no DynamoDB.  

B. Use o Amazon Kinesis Data Firehose para processar as fotos e armazenar as fotos e os metadados.  

C. Use o AWS Lambda para processar as fotos. Armazene as fotos no Amazon S3. Retenha o DynamoDB para armazenar os metadados.

D. Aumente o número de instâncias EC2 para três. Use volumes Provisioned IOPS SSD (io2) do Amazon Elastic Block Store (Amazon EBS) para armazenar as fotos e os metadados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>C</resposta>

**C.** Use o AWS Lambda para processar as fotos. Armazene as fotos no Amazon S3. Retenha o DynamoDB para armazenar os metadados.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS Lambda:** Usar o AWS Lambda elimina a necessidade de gerenciar servidores, permitindo que o processamento de fotos seja escalado automaticamente com base no volume de solicitações.  
  - **Amazon S3:** O S3 é um serviço altamente escalável, durável e econômico para armazenar fotos, especialmente em cenários com variação significativa no número de usuários.  
  - **Amazon DynamoDB:** O DynamoDB é uma solução altamente escalável e gerenciada para armazenar metadados. Ele pode lidar facilmente com variações no número de usuários e cargas de trabalho.  
  - Essa combinação oferece escalabilidade automática e baixa complexidade operacional para lidar com o aumento do número de usuários e suas variações.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora o AWS Lambda seja uma boa escolha para o processamento, armazenar fotos no DynamoDB não é eficiente nem econômico. O DynamoDB é otimizado para metadados e não para grandes objetos como imagens.  
  - **B:** O Amazon Kinesis Data Firehose é usado para ingestão e entrega de dados de streaming, mas não é ideal para processamento de imagens individuais ou armazenamento de fotos.  
  - **D:** Escalar instâncias EC2 manualmente e usar volumes io2 do Amazon EBS aumenta a complexidade operacional e não oferece escalabilidade automática, o que contradiz o requisito de suportar variações significativas no número de usuários.  

</details>

---

### Questão 115
Uma empresa de registros médicos está hospedando um aplicativo em instâncias Amazon EC2. O aplicativo processa arquivos de dados de clientes armazenados no Amazon S3. As instâncias EC2 estão hospedadas em sub-redes públicas. As instâncias EC2 acessam o Amazon S3 pela internet, mas não precisam de nenhum outro acesso à rede.  
Um novo requisito determina que o tráfego de rede para transferências de arquivos siga uma rota privada e não seja enviado pela internet.  
Qual alteração na arquitetura de rede um arquiteto de soluções deve recomendar para atender a esse requisito?  

A. Crie um gateway NAT. Configure a tabela de rotas para as sub-redes públicas para enviar o tráfego para o Amazon S3 por meio do gateway NAT.  

B. Configure o grupo de segurança das instâncias EC2 para restringir o tráfego de saída, permitindo apenas o tráfego para a lista de prefixos do S3.  

C. Mova as instâncias EC2 para sub-redes privadas. Crie um endpoint de VPC para o Amazon S3 e vincule o endpoint à tabela de rotas das sub-redes privadas.

D. Remova o gateway da internet da VPC. Configure uma conexão AWS Direct Connect e roteie o tráfego para o Amazon S3 por meio da conexão Direct Connect.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>C</resposta>

**C.** Mova as instâncias EC2 para sub-redes privadas. Crie um endpoint de VPC para o Amazon S3 e vincule o endpoint à tabela de rotas das sub-redes privadas.

**Justificativa:**  
- **Por que essa opção?**  
  - Um **endpoint de VPC para o Amazon S3** permite que o tráfego entre a VPC e o Amazon S3 seja roteado internamente pela rede da AWS, sem passar pela internet.  
  - Mover as instâncias EC2 para sub-redes privadas elimina a necessidade de um IP público ou de uma conexão direta à internet, atendendo ao requisito de manter o tráfego privado.  
  - Vincular o endpoint à tabela de rotas das sub-redes privadas garante que todo o tráfego destinado ao Amazon S3 use o endpoint privado, mantendo a conformidade com o requisito.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Usar um gateway NAT ainda resultaria em tráfego passando pela internet, mesmo que seja roteado de forma segura. Isso não atende ao requisito de manter o tráfego totalmente privado.  
  - **B:** Restringir o tráfego com um grupo de segurança não altera a rota do tráfego, que ainda passaria pela internet.  
  - **D:** Configurar uma conexão Direct Connect é uma solução mais complexa e cara, além de não ser necessária para transferências dentro da rede da AWS.  

</details>
---

### Questão 116
Uma empresa utiliza um sistema de gerenciamento de conteúdo (CMS) popular para o site corporativo. No entanto, os patches e a manutenção necessários são onerosos. A empresa está redesenhando seu site e quer uma nova solução. O site será atualizado quatro vezes por ano e não precisa ter nenhum conteúdo dinâmico disponível. A solução deve oferecer alta escalabilidade e segurança aprimorada.  
Quais combinações de mudanças atenderão a esses requisitos com o MENOR esforço operacional? (Escolha duas.)  

A. Configure o Amazon CloudFront na frente do site para usar funcionalidade HTTPS.  

B. Implemente uma ACL da Web do AWS WAF na frente do site para fornecer funcionalidade HTTPS.  

C. Crie e implemente uma função AWS Lambda para gerenciar e servir o conteúdo do site.  

D. Crie o novo site e um bucket Amazon S3. Implemente o site no bucket S3 com o hosting de site estático ativado. 

E. Crie o novo site. Implemente o site usando um grupo de Auto Scaling de instâncias Amazon EC2 atrás de um Application Load Balancer.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<responsta>A,D</responsta>

**A.** Configure o Amazon CloudFront na frente do site para usar funcionalidade HTTPS.  
**D.** Crie o novo site e um bucket Amazon S3. Implemente o site no bucket S3 com o hosting de site estático ativado.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** O **Amazon CloudFront** é uma rede de distribuição de conteúdo (CDN) que melhora a segurança, fornecendo suporte para HTTPS, além de aumentar a escalabilidade ao armazenar em cache o conteúdo estático em locais de borda.  
  - **D:** Hospedar o site em um **bucket S3** com hosting de site estático ativado é uma solução altamente escalável e com baixa manutenção para conteúdo estático. O S3 oferece uma maneira econômica e simples de servir páginas web estáticas.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **AWS WAF** é usado para proteger aplicativos web contra ataques comuns, mas ele não fornece funcionalidade HTTPS por conta própria. O WAF pode ser usado em conjunto com o CloudFront, mas não substitui o uso do HTTPS do CloudFront para este caso.  
  - **C:** Usar uma função **AWS Lambda** para servir o conteúdo do site adicionaria complexidade desnecessária e não é ideal para um site com conteúdo estático que não exige processamento dinâmico.  
  - **E:** Implementar o site em instâncias EC2 com um Application Load Balancer aumenta significativamente o esforço operacional e os custos em comparação com o uso de S3 e CloudFront para conteúdo estático.  

</details>

---

### Questão 117
Uma empresa armazena os logs de sua aplicação em um grupo de logs do Amazon CloudWatch Logs. Uma nova política exige que a empresa armazene todos os logs da aplicação no Amazon OpenSearch Service (anteriormente Amazon Elasticsearch Service) em tempo quase real.  
Qual solução atenderá a este requisito com o MENOR esforço operacional?  

A. Configure uma assinatura do CloudWatch Logs para transmitir os logs para o Amazon OpenSearch Service.  

B. Crie uma função AWS Lambda. Use o grupo de logs para invocar a função e gravar os logs no Amazon OpenSearch Service. 

C. Crie um fluxo de entrega do Amazon Kinesis Data Firehose. Configure o grupo de logs como a origem do fluxo de entrega. Configure o Amazon OpenSearch Service como o destino do fluxo de entrega.  

D. Instale e configure o Amazon Kinesis Agent em cada servidor da aplicação para enviar os logs para o Amazon Kinesis Data Streams. Configure o Kinesis Data Streams para enviar os logs ao Amazon OpenSearch Service.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Configure uma assinatura do CloudWatch Logs para transmitir os logs para o Amazon OpenSearch Service.

**Justificativa:**  
- **Por que essa opção?**  
  - Configurar uma assinatura do **CloudWatch Logs** é a solução mais simples e com menor esforço operacional. As assinaturas permitem que você transmita os logs diretamente de um grupo de logs do CloudWatch para o **Amazon OpenSearch Service**, fornecendo integração nativa e em tempo quase real.  
  - Isso elimina a necessidade de configurar ou gerenciar serviços intermediários, como Lambda ou Kinesis, tornando-o altamente eficiente.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Usar uma função AWS Lambda para processar e transmitir os logs aumenta a complexidade operacional, pois seria necessário gerenciar a função Lambda, incluindo a escalabilidade e a integração com o OpenSearch.  
  - **C:** O **Kinesis Data Firehose** pode ser usado para transmitir os logs ao OpenSearch Service, mas introduz um serviço intermediário desnecessário, aumentando o esforço operacional em comparação com a transmissão direta do CloudWatch Logs.  
  - **D:** Configurar o Kinesis Agent em cada servidor adiciona complexidade significativa, especialmente em ambientes com muitos servidores. Essa abordagem também não utiliza a integração nativa do CloudWatch Logs com o OpenSearch Service.  

</details>
---

### Questão 118
Uma empresa está desenvolvendo um aplicativo web baseado em instâncias Amazon EC2 em várias zonas de disponibilidade. O aplicativo web fornecerá acesso a um repositório de documentos de texto totalizando cerca de 900 TB. A empresa prevê que o aplicativo enfrentará períodos de alta demanda. Um arquiteto de soluções deve garantir que o componente de armazenamento para os documentos de texto possa escalar para atender à demanda do aplicativo a qualquer momento. A empresa está preocupada com o custo total da solução.  
Qual solução de armazenamento atende a esses requisitos de forma MAIS econômica?  

A. Amazon Elastic Block Store (Amazon EBS)  

B. Amazon Elastic File System (Amazon EFS)  

C. Amazon OpenSearch Service (Amazon Elasticsearch Service)  

D. Amazon S3  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Amazon S3

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon S3** é uma solução altamente escalável, durável e econômica para armazenar grandes volumes de dados, como os 900 TB mencionados na questão.  
  - Ele suporta alta demanda sem necessidade de configuração manual de escalabilidade e é otimizado para acesso a objetos armazenados.  
  - Comparado a outras opções, o custo do S3 é significativamente menor, especialmente considerando o volume de armazenamento necessário.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O **Amazon EBS** é projetado para armazenamento conectado a instâncias individuais e não é otimizado para compartilhamento entre múltiplas instâncias. Além disso, o gerenciamento de 900 TB em volumes EBS seria caro e operacionalmente complexo.  
  - **B:** O **Amazon EFS** é ideal para sistemas de arquivos compartilhados e dinâmicos, mas é mais caro que o S3 para armazenamento em larga escala, como 900 TB.  
  - **C:** O **Amazon OpenSearch Service** (anteriormente Elasticsearch) é projetado para análise e pesquisa, não para armazenamento de documentos em larga escala. Usá-lo apenas como solução de armazenamento seria ineficiente e caro.  

</details>

---

### Questão 119
Uma empresa global está usando o Amazon API Gateway para projetar APIs REST para os usuários do seu clube de fidelidade nas regiões **us-east-1** e **ap-southeast-2**. Um arquiteto de soluções deve projetar uma solução para proteger essas APIs REST gerenciadas pelo API Gateway em várias contas contra ataques de **injeção de SQL** e **cross-site scripting** (XSS).  
Qual solução atenderá a esses requisitos com o MENOR esforço administrativo?  

A. Configure o AWS WAF em ambas as regiões. Associe web ACLs regionais a um estágio da API.  

B. Configure o AWS Firewall Manager em ambas as regiões. Configure centralmente as regras do AWS WAF.  

C. Configure o AWS Shield em ambas as regiões. Associe web ACLs regionais a um estágio da API.  

D. Configure o AWS Shield em uma das regiões. Associe web ACLs regionais a um estágio da API.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Configure o AWS WAF em ambas as regiões. Associe web ACLs regionais a um estágio da API.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS WAF** é projetado especificamente para proteger aplicativos web contra ataques comuns, como injeção de SQL e cross-site scripting (XSS).  
  - Associar web ACLs regionais diretamente aos estágios das APIs no API Gateway é simples e eficiente, garantindo proteção em ambas as regiões.  
  - Essa abordagem atende ao requisito com o menor esforço administrativo, pois o WAF é gerenciado pela AWS e pode ser configurado diretamente para o API Gateway.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O **AWS Firewall Manager** é usado para gerenciar centralmente políticas de segurança em várias contas e regiões, mas ele adiciona complexidade desnecessária neste caso, já que o objetivo é proteger apenas APIs específicas em duas regiões.  
  - **C:** O **AWS Shield** é projetado para proteção contra ataques DDoS. Ele não oferece proteção contra injeção de SQL ou cross-site scripting, tornando-o inadequado para os requisitos da questão.  
  - **D:** Configurar o AWS Shield em apenas uma região não protegerá a API na outra região. Além disso, como mencionado anteriormente, o Shield não oferece proteção contra ataques de injeção de SQL ou XSS.  

</details>

---

### Questão 120
Uma empresa implementou uma solução de DNS autogerenciada em três instâncias Amazon EC2 atrás de um Network Load Balancer (NLB) na região **us-west-2**. A maioria dos usuários da empresa está localizada nos Estados Unidos e na Europa. A empresa deseja melhorar o desempenho e a disponibilidade da solução. A empresa lança e configura três instâncias EC2 na região **eu-west-1** e as adiciona como alvos para um novo NLB.  
Qual solução a empresa pode usar para rotear o tráfego para todas as instâncias EC2?  

A. Crie uma política de roteamento de geolocalização no Amazon Route 53 para rotear as solicitações para um dos dois NLBs. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

B. Crie um acelerador padrão no AWS Global Accelerator. Crie grupos de endpoints em **us-west-2** e **eu-west-1**. Adicione os dois NLBs como endpoints para os grupos de endpoints.  

C. Anexe Elastic IPs às seis instâncias EC2. Crie uma política de roteamento de geolocalização no Amazon Route 53 para rotear as solicitações para uma das seis instâncias EC2. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

D. Substitua os dois NLBs por dois Application Load Balancers (ALBs). Crie uma política de roteamento de latência no Amazon Route 53 para rotear as solicitações para um dos dois ALBs. Crie uma distribuição Amazon CloudFront. Use o registro do Route 53 como a origem da distribuição.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Crie um acelerador padrão no AWS Global Accelerator. Crie grupos de endpoints em **us-west-2** e **eu-west-1**. Adicione os dois NLBs como endpoints para os grupos de endpoints.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Global Accelerator** fornece endereços IP fixos e roteia o tráfego de forma otimizada para os endpoints mais próximos, melhorando o desempenho e a disponibilidade para os usuários.  
  - A configuração de grupos de endpoints em ambas as regiões (**us-west-2** e **eu-west-1**) permite que o tráfego seja roteado automaticamente para o NLB mais próximo com base na proximidade do usuário.  
  - Global Accelerator é projetado para aplicativos globais e oferece alta resiliência e baixa latência, além de ser fácil de configurar e gerenciar.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Uma política de roteamento de geolocalização no Route 53 e o uso do CloudFront como origem adicionam complexidade desnecessária e não oferecem os benefícios de desempenho e latência reduzida que o Global Accelerator oferece.  
  - **C:** Usar Elastic IPs diretamente com instâncias EC2 aumenta a complexidade operacional, pois requer o gerenciamento individual de instâncias e não oferece balanceamento de carga ou failover eficiente.  
  - **D:** Substituir os NLBs por ALBs pode melhorar o suporte a aplicativos baseados em HTTP/HTTPS, mas essa solução depende apenas de uma política de latência no Route 53, que não fornece a otimização global e resiliência que o Global Accelerator oferece.  

</details>

---

### Questão 121
Uma empresa está executando uma carga de trabalho de processamento de transações online (OLTP) na AWS. Essa carga de trabalho utiliza uma instância Amazon RDS DB não criptografada em uma implantação Multi-AZ. Snapshots diários do banco de dados são criados a partir dessa instância.  
O que um arquiteto de soluções deve fazer para garantir que o banco de dados e os snapshots estejam sempre criptografados daqui em diante?  

A. Criptografe uma cópia do snapshot mais recente do banco de dados. Substitua a instância de banco de dados existente restaurando o snapshot criptografado. 

B. Crie um novo volume Amazon Elastic Block Store (Amazon EBS) criptografado e copie os snapshots para ele. Habilite a criptografia na instância do banco de dados.  

C. Copie os snapshots e habilite a criptografia usando o AWS Key Management Service (AWS KMS). Restaure o snapshot criptografado para uma instância de banco de dados existente.  

D. Copie os snapshots para um bucket Amazon S3 que esteja criptografado usando criptografia no lado do servidor com chaves gerenciadas pelo AWS Key Management Service (SSE-KMS).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Criptografe uma cópia do snapshot mais recente do banco de dados. Substitua a instância de banco de dados existente restaurando o snapshot criptografado.

**Justificativa:**  
- **Por que essa opção?**  
  - O Amazon RDS não permite habilitar a criptografia diretamente em uma instância de banco de dados existente. No entanto, você pode criptografar um snapshot existente ao fazer uma cópia criptografada dele.  
  - Uma vez que o snapshot esteja criptografado, você pode restaurá-lo para criar uma nova instância do RDS com criptografia habilitada. A partir de então, todos os novos snapshots dessa instância também estarão criptografados.  
  - Este é o método recomendado pela AWS para adicionar criptografia a uma instância de banco de dados não criptografada.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Não é possível habilitar criptografia diretamente em uma instância RDS existente ou copiar snapshots para volumes EBS para criptografá-los.  
  - **C:** Embora seja possível copiar snapshots e criptografá-los, você não pode restaurar um snapshot criptografado para uma instância existente. Deve-se criar uma nova instância a partir do snapshot criptografado.  
  - **D:** Copiar os snapshots para um bucket S3 criptografado protege apenas os snapshots no S3, mas não criptografa a instância RDS subjacente nem os futuros snapshots criados diretamente do banco de dados.  

</details>

---

### Questão 122
Uma empresa deseja construir uma infraestrutura escalável de gerenciamento de chaves para dar suporte a desenvolvedores que precisam criptografar dados em seus aplicativos.  
O que um arquiteto de soluções deve fazer para reduzir a carga operacional?  

A. Use autenticação multifator (MFA) para proteger as chaves de criptografia.  

B. Use o AWS Key Management Service (AWS KMS) para proteger as chaves de criptografia. 

C. Use o AWS Certificate Manager (ACM) para criar, armazenar e atribuir as chaves de criptografia.

D. Use uma política IAM para limitar o escopo de usuários que têm permissões de acesso para proteger as chaves de criptografia.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Use o AWS Key Management Service (AWS KMS) para proteger as chaves de criptografia.

**Justificativa:**  
- **Por que essa opção?**  
  - O **AWS Key Management Service (AWS KMS)** é um serviço gerenciado que permite criar, gerenciar e usar chaves de criptografia com esforço operacional mínimo. Ele oferece integração nativa com outros serviços da AWS e SDKs para desenvolvedores usarem criptografia facilmente em seus aplicativos.  
  - O KMS reduz a carga operacional ao lidar automaticamente com tarefas como rotação de chaves, gerenciamento de permissões granulares e auditoria do uso das chaves no AWS CloudTrail.  
  - Ele é altamente escalável e projetado para suportar aplicativos em grande escala.  

- **Por que as outras opções não são adequadas?**  
  - **A:** A autenticação multifator (MFA) melhora a segurança do acesso às chaves, mas não resolve o problema de gerenciamento de chaves em grande escala, nem reduz significativamente a carga operacional.  
  - **C:** O **AWS Certificate Manager (ACM)** é projetado para gerenciar certificados SSL/TLS, não chaves de criptografia gerais. Ele não atende à necessidade de suportar a criptografia de dados em aplicativos.  
  - **D:** Limitar o escopo de usuários com uma política IAM é uma prática recomendada para segurança, mas não aborda diretamente a questão de gerenciamento escalável de chaves. Essa abordagem seria complementar ao uso do AWS KMS.  

</details>

---

### Questão 123
Uma empresa tem um aplicativo web dinâmico hospedado em duas instâncias Amazon EC2. A empresa possui seu próprio certificado SSL, que está instalado em cada instância para realizar a terminação SSL.  
Recentemente, houve um aumento no tráfego, e a equipe de operações determinou que a criptografia e descriptografia SSL está fazendo com que a capacidade de computação dos servidores web atinja o limite máximo.  
O que um arquiteto de soluções deve fazer para aumentar o desempenho do aplicativo?  

A. Crie um novo certificado SSL usando o AWS Certificate Manager (ACM). Instale o certificado ACM em cada instância.  

B. Crie um bucket Amazon S3. Migre o certificado SSL para o bucket S3. Configure as instâncias EC2 para referenciar o bucket para terminação SSL.  

C. Crie outra instância EC2 como um servidor proxy. Migre o certificado SSL para a nova instância e configure-a para direcionar conexões para as instâncias EC2 existentes.  

D. Importe o certificado SSL para o AWS Certificate Manager (ACM). Crie um Application Load Balancer com um listener HTTPS que use o certificado SSL do ACM.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Importe o certificado SSL para o AWS Certificate Manager (ACM). Crie um Application Load Balancer com um listener HTTPS que use o certificado SSL do ACM.

**Justificativa:**  
- **Por que essa opção?**  
  - Ao usar um **Application Load Balancer (ALB)** com terminação SSL, o tráfego HTTPS é processado pelo ALB, eliminando a carga de criptografia/descriptografia das instâncias EC2. Isso reduz a utilização da capacidade computacional dos servidores web, melhorando o desempenho.  
  - O **AWS Certificate Manager (ACM)** permite importar e gerenciar certificados SSL/TLS com facilidade, sem necessidade de gerenciar manualmente os certificados em cada instância EC2.  
  - Essa abordagem fornece uma solução escalável e gerenciada para lidar com o aumento no tráfego.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Criar um novo certificado ACM e instalá-lo em cada instância EC2 não resolverá o problema de carga computacional causada pela terminação SSL. O problema de desempenho persistirá.  
  - **B:** Usar um bucket S3 para armazenar certificados SSL e configurá-los para referência pelas instâncias EC2 não é uma abordagem suportada ou apropriada para terminação SSL.  
  - **C:** Adicionar uma instância proxy com terminação SSL desloca o problema de carga computacional para a nova instância proxy, o que não resolve o problema de forma eficiente e escalável.  

</details>
---

### Questão 124
Uma empresa tem um trabalho de processamento em lote altamente dinâmico que utiliza muitas instâncias Amazon EC2 para completá-lo. O trabalho é **sem estado**, pode ser iniciado e interrompido a qualquer momento sem impacto negativo e geralmente leva mais de 60 minutos para ser concluído. A empresa pediu a um arquiteto de soluções para projetar uma solução escalável e econômica que atenda aos requisitos do trabalho.  
O que o arquiteto de soluções deve recomendar?  

A. Implementar instâncias Spot do EC2.  

B. Comprar instâncias reservadas do EC2.  

C. Implementar instâncias sob demanda do EC2.  

D. Implementar o processamento no AWS Lambda.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Implementar instâncias Spot do EC2.

**Justificativa:**  
- **Por que essa opção?**  
  - As **instâncias Spot do EC2** são altamente econômicas e ideais para cargas de trabalho **sem estado** que podem ser interrompidas e retomadas sem impacto significativo, como o processamento em lote descrito.  
  - As instâncias Spot permitem economias de custo de até 90% em comparação com instâncias sob demanda.  
  - Como o trabalho é dinâmico e sem estado, ele pode lidar com a interrupção de instâncias Spot, tornando essa opção escalável e econômica.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Instâncias reservadas são mais adequadas para cargas de trabalho previsíveis e de longo prazo. Elas não oferecem flexibilidade para lidar com a natureza dinâmica do trabalho descrito e são mais caras que instâncias Spot.  
  - **C:** Instâncias sob demanda fornecem flexibilidade, mas são significativamente mais caras que instâncias Spot para uma carga de trabalho como essa.  
  - **D:** O AWS Lambda é mais adequado para tarefas de curta duração e baseadas em eventos, não para trabalhos em lote que levam mais de 60 minutos para serem concluídos.  

</details>

---


### Questão 125
Uma empresa opera seu site de comércio eletrônico de duas camadas na AWS. A camada web consiste em um balanceador de carga que envia tráfego para instâncias Amazon EC2. A camada de banco de dados usa uma instância Amazon RDS DB. As instâncias EC2 e a instância RDS DB não devem ser expostas à internet pública. As instâncias EC2 precisam de acesso à internet para concluir o processamento de pagamentos por meio de um serviço web de terceiros. A aplicação deve ser altamente disponível.  
Quais combinações de opções de configuração atenderão a esses requisitos? (Escolha duas.)  

A. Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes privadas. Implemente uma instância RDS Multi-AZ em sub-redes privadas. 

B. Configure uma VPC com duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes privadas.  

C. Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes públicas em duas zonas de disponibilidade. Implemente uma instância RDS Multi-AZ em sub-redes privadas.  

D. Configure uma VPC com uma sub-rede pública, uma sub-rede privada e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer na sub-rede pública.  

E. Configure uma VPC com duas sub-redes públicas, duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes públicas.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>A,E</resposta>

**A.** Use um grupo de Auto Scaling para iniciar as instâncias EC2 em sub-redes privadas. Implemente uma instância RDS Multi-AZ em sub-redes privadas.  
**E.** Configure uma VPC com duas sub-redes públicas, duas sub-redes privadas e dois NAT gateways em duas zonas de disponibilidade. Implemente um Application Load Balancer nas sub-redes públicas.

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** As instâncias EC2 na camada web e a instância RDS na camada de banco de dados devem ser colocadas em sub-redes privadas para garantir que não sejam expostas à internet pública. Isso melhora a segurança. A implementação de RDS em uma configuração Multi-AZ garante alta disponibilidade.  
  - **E:** Configurar sub-redes públicas para o Application Load Balancer permite que ele receba tráfego público da internet e o redirecione para as instâncias EC2 em sub-redes privadas. Os NAT gateways permitem que as instâncias EC2 em sub-redes privadas acessem a internet para comunicações de saída (como o processamento de pagamentos).  

- **Por que as outras opções não são adequadas?**  
  - **B:** Implementar um Application Load Balancer em sub-redes privadas o tornaria inacessível à internet pública, o que não atende aos requisitos de receber tráfego público.  
  - **C:** Lançar instâncias EC2 em sub-redes públicas exporia essas instâncias diretamente à internet, o que viola o requisito de segurança de não expor os servidores públicos.  
  - **D:** Usar apenas uma sub-rede pública e uma sub-rede privada em uma VPC não é suficiente para garantir alta disponibilidade, pois o design depende de múltiplas zonas de disponibilidade.  

</details>

---

### Questão 126
Um arquiteto de soluções precisa implementar uma solução para reduzir os custos de armazenamento de uma empresa. Todos os dados da empresa estão atualmente na classe de armazenamento **Amazon S3 Standard**. A empresa deve manter todos os dados por pelo menos 25 anos. Os dados dos últimos 2 anos devem ser altamente disponíveis e imediatamente recuperáveis.  
Qual solução atenderá a esses requisitos?  

A. Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive imediatamente.  

B. Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive após 2 anos.  

C. Use o S3 Intelligent-Tiering. Ative a opção de arquivamento para garantir que os dados sejam arquivados no S3 Glacier Deep Archive.

D. Configure uma política do S3 Lifecycle para transferir objetos para o S3 One Zone-Infrequent Access (S3 One Zone-IA) imediatamente e para o S3 Glacier Deep Archive após 2 anos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Configure uma política do S3 Lifecycle para transferir objetos para o S3 Glacier Deep Archive após 2 anos.

**Justificativa:**  
- **Por que essa opção?**  
  - A classe de armazenamento **S3 Glacier Deep Archive** é projetada para retenção de longo prazo de dados que são acessados raramente, sendo a opção mais econômica para armazenamento de 25 anos.  
  - A política do **S3 Lifecycle** permite que os dados permaneçam na classe **S3 Standard** (altamente disponível e imediatamente recuperável) pelos primeiros 2 anos, atendendo ao requisito de acesso imediato. Após esse período, os dados podem ser movidos para o **S3 Glacier Deep Archive** para reduzir os custos.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Mover objetos para o S3 Glacier Deep Archive imediatamente viola o requisito de que os dados dos últimos 2 anos devem ser altamente disponíveis e imediatamente recuperáveis.  
  - **C:** O **S3 Intelligent-Tiering** é útil para dados com padrões de acesso imprevisíveis. No entanto, ele não garante a retenção de dados em uma classe específica por 2 anos antes de movê-los para o **S3 Glacier Deep Archive**, tornando-o inadequado para este caso de uso.  
  - **D:** O **S3 One Zone-IA** oferece uma opção de menor custo para dados acessados raramente, mas não é apropriado para dados críticos, pois depende de uma única zona de disponibilidade. Além disso, o requisito de alta disponibilidade para os últimos 2 anos não é atendido com esta abordagem.  

</details>

---

### Questão 127
Uma empresa de mídia está avaliando a possibilidade de mover seus sistemas para a AWS Cloud. A empresa precisa de pelo menos 10 TB de armazenamento com o máximo de desempenho de I/O para processamento de vídeo, 300 TB de armazenamento altamente durável para armazenar conteúdo de mídia, e 900 TB de armazenamento para arquivamento de mídia que não está mais em uso.  
Qual conjunto de serviços um arquiteto de soluções deve recomendar para atender a esses requisitos?  

A. Amazon EBS para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.

B. Amazon EBS para desempenho máximo, Amazon EFS para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.  

C. Amazon EC2 instance store para desempenho máximo, Amazon EFS para armazenamento durável de dados e Amazon S3 para armazenamento de arquivos.  

D. Amazon EC2 instance store para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Amazon EBS para desempenho máximo, Amazon S3 para armazenamento durável de dados e Amazon S3 Glacier para armazenamento de arquivos.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon EBS (Elastic Block Store):** É a melhor escolha para o processamento de vídeo que requer desempenho máximo de I/O e armazenamento de bloco persistente. Ele suporta volumes otimizados para altas taxas de transferência de dados, sendo ideal para cargas de trabalho intensivas como processamento de vídeo.  
  - **Amazon S3:** É uma solução altamente durável e escalável para armazenamento de conteúdo de mídia, com integração nativa com outros serviços AWS e suporte a altas taxas de armazenamento de dados (300 TB neste caso).  
  - **Amazon S3 Glacier:** É ideal para arquivamento de longo prazo de dados raramente acessados, com custos muito baixos, atendendo ao requisito de armazenamento de 900 TB para mídias não utilizadas.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora o EFS seja adequado para sistemas de arquivos compartilhados, ele não é tão econômico quanto o S3 para armazenar grandes volumes de dados (300 TB).  
  - **C:** O **EC2 instance store** oferece desempenho alto, mas não é persistente, o que significa que os dados podem ser perdidos se a instância for interrompida. Isso o torna inadequado para cargas de trabalho que exigem armazenamento confiável. Além disso, o S3 não é otimizado para arquivamento em comparação com o S3 Glacier.  
  - **D:** Semelhante à opção anterior, o **EC2 instance store** não oferece persistência de dados e não é confiável para armazenamento de longo prazo.  

</details>

---

### Questão 128
Uma empresa deseja executar aplicativos em contêineres na AWS Cloud. Esses aplicativos são sem estado e podem tolerar interrupções na infraestrutura subjacente. A empresa precisa de uma solução que minimize os custos e o esforço operacional.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Use instâncias Spot em um grupo de Auto Scaling do Amazon EC2 para executar os contêineres de aplicativos.  

B. Use instâncias Spot em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).  

C. Use instâncias sob demanda em um grupo de Auto Scaling do Amazon EC2 para executar os contêineres de aplicativos.  

D. Use instâncias sob demanda em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Use instâncias Spot em um grupo de nós gerenciados do Amazon Elastic Kubernetes Service (Amazon EKS).

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon EKS com instâncias Spot:** O Amazon EKS é uma solução gerenciada para executar contêineres em Kubernetes, reduzindo significativamente o esforço operacional. Ele fornece uma infraestrutura escalável e de baixo custo.  
  - **Instâncias Spot:** Instâncias Spot são altamente econômicas e ideais para cargas de trabalho que podem tolerar interrupções, como aplicativos sem estado. Elas reduzem significativamente os custos em comparação com instâncias sob demanda.  
  - Combinar o Amazon EKS com instâncias Spot oferece uma solução que minimiza tanto os custos quanto o esforço operacional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora instâncias Spot em um Auto Scaling group do EC2 sejam econômicas, essa solução não aproveita a automação e os benefícios de gerenciamento que o EKS oferece, aumentando o esforço operacional.  
  - **C:** Usar instâncias sob demanda em um Auto Scaling group do EC2 é mais caro do que usar instâncias Spot, e não tira proveito da abstração e do gerenciamento que o EKS fornece.  
  - **D:** Instâncias sob demanda em um grupo de nós gerenciados do EKS fornecem automação e gerenciamento, mas a escolha de instâncias sob demanda aumenta significativamente os custos em comparação com instâncias Spot.  

</details>

---

### Questão 129
**Tradução:**  
Uma empresa está executando um aplicativo web de várias camadas localmente. O aplicativo web é conteinerizado e executado em vários hosts Linux conectados a um banco de dados PostgreSQL que contém registros de usuários. O esforço operacional de manter a infraestrutura e planejar a capacidade está limitando o crescimento da empresa. Um arquiteto de soluções deve melhorar a infraestrutura do aplicativo.  
Quais combinações de ações o arquiteto de soluções deve realizar para alcançar isso? (Escolha duas.)  

A. Migre o banco de dados PostgreSQL para o Amazon Aurora.

B. Migre o aplicativo web para ser hospedado em instâncias Amazon EC2.  

C. Configure uma distribuição Amazon CloudFront para o conteúdo do aplicativo web.  

D. Configure o Amazon ElastiCache entre o aplicativo web e o banco de dados PostgreSQL. 

E. Migre o aplicativo web para ser hospedado no AWS Fargate com Amazon Elastic Container Service (Amazon ECS).  

<details>
<summary>Resposta</summary>
<resposta>A,E</resposta>

**Respostas corretas:**  
**A.** Migre o banco de dados PostgreSQL para o Amazon Aurora.  
**E.** Migre o aplicativo web para ser hospedado no AWS Fargate com Amazon Elastic Container Service (Amazon ECS).

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** Migrar o banco de dados PostgreSQL para o **Amazon Aurora** reduz o esforço operacional, pois o Aurora é um serviço gerenciado, altamente escalável e otimizado para desempenho. Ele elimina a necessidade de manutenção de hardware e planejamento de capacidade para o banco de dados.  
  - **E:** Hospedar o aplicativo web no **AWS Fargate** com o **Amazon ECS** elimina a necessidade de gerenciar servidores subjacentes, reduzindo a sobrecarga operacional. O Fargate é ideal para aplicativos conteinerizados, permitindo escalabilidade automática e integração com outros serviços AWS.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Migrar o aplicativo web para instâncias Amazon EC2 ainda exigiria gerenciamento e manutenção de servidores, o que não resolve o problema de sobrecarga operacional.  
  - **C:** Configurar o **Amazon CloudFront** para distribuição de conteúdo pode melhorar o desempenho para usuários finais, mas não resolve os problemas principais de sobrecarga operacional e planejamento de capacidade.  
  - **D:** Usar o **Amazon ElastiCache** pode melhorar o desempenho ao reduzir a carga no banco de dados PostgreSQL, mas não aborda diretamente a sobrecarga operacional associada à infraestrutura subjacente.  

</details>

---

### Questão 130
Um aplicativo é executado em instâncias Amazon EC2 distribuídas por várias zonas de disponibilidade. As instâncias estão em um grupo de Auto Scaling do Amazon EC2 atrás de um Application Load Balancer. O aplicativo funciona melhor quando a utilização de CPU das instâncias EC2 está em ou próximo de 40%.  
O que um arquiteto de soluções deve fazer para manter o desempenho desejado em todas as instâncias do grupo?  

A. Use uma política de escalabilidade simples para escalar dinamicamente o grupo de Auto Scaling.  

B. Use uma política de rastreamento de destino para escalar dinamicamente o grupo de Auto Scaling.  

C. Use uma função AWS Lambda para atualizar a capacidade desejada do grupo de Auto Scaling.  

D. Use ações de escalabilidade agendadas para aumentar e reduzir o grupo de Auto Scaling.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Use uma política de rastreamento de destino para escalar dinamicamente o grupo de Auto Scaling.

**Justificativa:**  
- **Por que essa opção?**  
  - Uma **política de rastreamento de destino** ajusta automaticamente o tamanho do grupo de Auto Scaling para atingir um valor de métrica-alvo específico, como a utilização da CPU. Nesse caso, configurar o rastreamento para manter a utilização de CPU em torno de 40% garante o desempenho ideal do aplicativo.  
  - Essa abordagem é eficiente e reduz o esforço operacional, pois o Auto Scaling ajusta automaticamente o número de instâncias com base na métrica-alvo configurada.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Uma política de escalabilidade simples baseia-se em alarmes que acionam ações específicas, mas não garante que a utilização da CPU será mantida em 40%.  
  - **C:** Usar uma função AWS Lambda para ajustar manualmente a capacidade desejada adiciona complexidade operacional desnecessária e não é uma solução automatizada como as políticas do Auto Scaling.  
  - **D:** Ações de escalabilidade agendadas funcionam bem para cargas de trabalho previsíveis, mas não são adequadas para ajustes dinâmicos e métricas variáveis, como a utilização da CPU.  

</details>

---

### Questão 131
Uma empresa está desenvolvendo um aplicativo de compartilhamento de arquivos que usará um bucket do Amazon S3 para armazenamento. A empresa deseja servir todos os arquivos por meio de uma distribuição do Amazon CloudFront. A empresa não quer que os arquivos sejam acessíveis por navegação direta para o URL do S3.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Escreva políticas individuais para cada bucket S3 para conceder permissão de leitura apenas para o acesso do CloudFront.  

B. Crie um usuário IAM. Conceda permissão de leitura para objetos no bucket S3. Atribua o usuário ao CloudFront.  

C. Escreva uma política de bucket S3 que atribua o ID da distribuição do CloudFront como o Principal e atribua o bucket S3 como o Amazon Resource Name (ARN). 

D. Crie uma identidade de acesso de origem (OAI). Atribua a OAI à distribuição do CloudFront. Configure as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D.** Crie uma identidade de acesso de origem (OAI). Atribua a OAI à distribuição do CloudFront. Configure as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura.

**Justificativa:**  
- **Por que essa opção?**  
  - Uma **Origin Access Identity (OAI)** é usada para garantir que o acesso aos objetos em um bucket S3 seja permitido apenas por meio de uma distribuição do **CloudFront**. Isso impede o acesso direto aos URLs do S3.  
  - Configurar as permissões do bucket S3 para que apenas a OAI tenha permissão de leitura garante que os arquivos só possam ser acessados por meio do CloudFront.  
  - Essa abordagem é uma prática recomendada para proteger arquivos servidos pelo CloudFront.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Escrever políticas individuais para cada bucket S3 é desnecessário e não garante que o acesso direto ao S3 será bloqueado.  
  - **B:** Criar um usuário IAM para gerenciar o acesso do CloudFront não é o método correto, pois o IAM não controla diretamente o acesso entre o CloudFront e o S3.  
  - **C:** Especificar o ID da distribuição
**CloudFront** como principal na política do bucket S3 não é suportado. O CloudFront usa a OAI para gerenciar permissões de acesso ao S3 de forma segura.

</details>

---

### Questão 132
Uma empresa disponibiliza em seu site relatórios de desempenho histórico para download pelos usuários. O site precisa de uma solução que escale para atender às demandas globais da empresa. A solução deve ser econômica, limitar o provisionamento de recursos de infraestrutura e oferecer o menor tempo de resposta possível.  
Qual combinação um arquiteto de soluções deve recomendar para atender a esses requisitos?

**Alternativas:**
A. Amazon CloudFront e Amazon S3  

B. AWS Lambda e Amazon DynamoDB  

C. Application Load Balancer com Amazon EC2 Auto Scaling  

D. Amazon Route 53 com Application Load Balancers internos  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Amazon CloudFront e Amazon S3

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon S3** é um serviço de armazenamento altamente escalável e econômico, ideal para hospedar arquivos estáticos, como relatórios para download. Ele reduz os custos e elimina a necessidade de provisionar e gerenciar servidores de infraestrutura.
  - O **Amazon CloudFront** é uma rede de entrega de conteúdo (CDN) que garante a distribuição global eficiente e com baixa latência dos arquivos armazenados no S3, atendendo ao requisito de menor tempo de resposta para usuários em diferentes partes do mundo.  
  - Essa combinação é econômica, escalável e não exige provisionamento manual de recursos de infraestrutura.

**Por que as outras opções não são adequadas?**  
- **B:** AWS Lambda e Amazon DynamoDB  
  - AWS Lambda é ideal para execução de código sem provisionamento de servidores, e DynamoDB é usado para armazenamento de dados em tabelas NoSQL. No entanto, essa combinação não é apropriada para distribuir arquivos grandes e estáticos, como relatórios para download, e não oferece a melhor latência para entrega global.  
- **C:** Application Load Balancer com Amazon EC2 Auto Scaling  
  - Essa abordagem requer o provisionamento e a manutenção de instâncias EC2. Embora escalável, não é a solução mais econômica nem oferece a melhor latência global quando comparada ao CloudFront.  
- **D:** Amazon Route 53 com Application Load Balancers internos  
  - O Route 53 pode ser usado para rotear tráfego globalmente, mas, ao utilizar apenas balanceadores de carga internos, a solução não é otimizada para entrega de conteúdo estático globalmente e não atende ao requisito de menor tempo de resposta.  

</details>

---

### Questão 133
Uma empresa executa um banco de dados Oracle localmente. Como parte da migração para a AWS, a empresa deseja atualizar o banco de dados para a versão mais recente disponível. A empresa também quer configurar recuperação de desastres (DR) para o banco de dados. É necessário minimizar a sobrecarga operacional para operações normais e configuração de DR. Além disso, a empresa precisa manter acesso ao sistema operacional subjacente do banco de dados.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Migrar o banco de dados Oracle para uma instância Amazon EC2. Configurar replicação do banco de dados para uma Região diferente da AWS.  

B. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Ativar backups automatizados entre Regiões para replicar os snapshots para outra Região AWS.  

C. Migrar o banco de dados Oracle para Amazon RDS Custom para Oracle. Criar uma réplica de leitura do banco de dados em outra Região AWS.  

D. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Criar um banco de dados standby em outra Zona de Disponibilidade (AZ).  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Migrar o banco de dados Oracle para Amazon RDS Custom para Oracle. Criar uma réplica de leitura do banco de dados em outra Região AWS.

**Justificativa:**  
- **Por que essa opção?**  
  - O **Amazon RDS Custom para Oracle** permite que os usuários mantenham acesso ao sistema operacional subjacente, atendendo ao requisito de manter esse nível de controle.
  - A réplica de leitura em outra região fornece uma configuração eficiente de recuperação de desastres (DR) com replicação contínua e facilita a escalabilidade para leitura em múltiplas regiões.  
  - Além disso, o RDS Custom reduz a sobrecarga operacional, já que automatiza várias tarefas de gerenciamento de banco de dados enquanto mantém flexibilidade para personalizações.

**Por que as outras opções não são adequadas?**  
- A. Migrar o banco de dados Oracle para uma instância Amazon EC2. Configurar replicação do banco de dados para uma Região diferente da AWS.  
  - Embora permita acesso ao sistema operacional, essa solução exige alta sobrecarga operacional para gerenciar a infraestrutura e configurar manualmente a replicação, o que não atende ao requisito de minimizar a sobrecarga.  
- B. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Ativar backups automatizados entre Regiões para replicar os snapshots para outra Região AWS.  
  - Essa abordagem reduz a sobrecarga operacional, mas o RDS padrão não oferece acesso ao sistema operacional subjacente, o que não atende a um requisito importante.  
- D. Migrar o banco de dados Oracle para Amazon RDS para Oracle. Criar um banco de dados standby em outra Zona de Disponibilidade (AZ).  
  - Essa configuração oferece alta disponibilidade (HA) em vez de recuperação de desastres (DR) entre Regiões. Além disso, o RDS padrão não permite acesso ao sistema operacional.  

</details>

---

### Questão 134
Uma empresa deseja migrar sua aplicação para uma solução serverless. A solução serverless precisa analisar dados existentes e novos usando SQL. A empresa armazena os dados em um bucket do Amazon S3. Os dados exigem criptografia e devem ser replicados para outra Região AWS.  
Qual solução atenderá a esses requisitos com o MENOR esforço operacional?

**Alternativas:**
A. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon Athena para consultar os dados.  

B. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon RDS para consultar os dados.  

C. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon Athena para consultar os dados.  

D. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon RDS para consultar os dados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon Athena para consultar os dados.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon S3 Cross-Region Replication (CRR):** Configura a replicação automática de objetos para outro bucket em uma Região diferente, atendendo ao requisito de replicação.  
  - **Criptografia SSE-KMS com chaves multi-Região:** Garante que os dados sejam criptografados com um nível mais avançado de controle usando chaves gerenciadas pelo AWS KMS. Isso é mais seguro do que as chaves gerenciadas pelo S3 (SSE-S3).  
  - **Amazon Athena:** É uma solução serverless que permite consultas SQL diretamente nos dados armazenados no S3, eliminando a necessidade de provisionar e gerenciar um banco de dados relacional.  
  - Essa configuração minimiza o esforço operacional, utiliza uma arquitetura serverless e atende aos requisitos de criptografia e replicação.  

**Por que as outras opções não são adequadas?**  
- B. Criar um novo bucket S3. Carregar os dados no novo bucket S3. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves multi-Região do AWS KMS (SSE-KMS). Usar Amazon RDS para consultar os dados.  
  - Embora atenda aos requisitos de criptografia e replicação, o uso do Amazon RDS exige a configuração de uma instância de banco de dados, o que aumenta o esforço operacional e não é uma solução totalmente serverless.  
- C. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon Athena para consultar os dados.  
  - Apesar de ser uma solução serverless, a criptografia SSE-S3 oferece menos controle e segurança do que o SSE-KMS, tornando-a menos apropriada para dados sensíveis que exigem gerenciamento de chaves avançado.  
- D. Carregar os dados no bucket S3 existente. Usar S3 Cross-Region Replication (CRR) para replicar objetos criptografados para um bucket S3 em outra Região. Usar criptografia do lado do servidor com chaves gerenciadas pelo Amazon S3 (SSE-S3). Usar Amazon RDS para consultar os dados.  
  - Assim como a opção C, a criptografia SSE-S3 não é a ideal. Além disso, o uso do Amazon RDS adiciona esforço operacional, contrariando o requisito de uma solução com baixo overhead.  

</details>

---

### Questão 135
Uma empresa executa cargas de trabalho na AWS. A empresa precisa se conectar a um serviço de um provedor externo. O serviço está hospedado na VPC do provedor. De acordo com a equipe de segurança da empresa, a conectividade deve ser privada e restrita ao serviço de destino. A conexão deve ser iniciada somente a partir da VPC da empresa.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Criar uma conexão de peering entre a VPC da empresa e a VPC do provedor. Atualizar a tabela de rotas para se conectar ao serviço de destino.  

B. Pedir ao provedor para criar um gateway privado virtual em sua VPC. Usar AWS PrivateLink para se conectar ao serviço de destino.  

C. Criar um gateway NAT em uma sub-rede pública da VPC da empresa. Atualizar a tabela de rotas para se conectar ao serviço de destino.  

D. Pedir ao provedor para criar um endpoint de VPC para o serviço de destino. Usar AWS PrivateLink para se conectar ao serviço de destino.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

**D.** Pedir ao provedor para criar um endpoint de VPC para o serviço de destino. Usar AWS PrivateLink para se conectar ao serviço de destino.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS PrivateLink** permite conexões privadas para serviços hospedados em outra VPC, garantindo que o tráfego nunca saia da rede da AWS. Essa abordagem atende aos requisitos de conectividade privada e restrita.  
  - O provedor cria um **endpoint de VPC**, que funciona como um ponto de entrada para o serviço. A VPC da empresa pode então usar o PrivateLink para acessar exclusivamente o serviço de destino.  
  - Essa solução também garante que a conexão seja iniciada somente da VPC da empresa, atendendo aos requisitos de segurança.

**Por que as outras opções não são adequadas?**  
- A. Criar uma conexão de peering entre a VPC da empresa e a VPC do provedor. Atualizar a tabela de rotas para se conectar ao serviço de destino.  
  - Uma conexão de peering permitiria conectividade entre as VPCs, mas não restringe o acesso apenas ao serviço de destino, o que não atende aos requisitos de segurança.  
- B. Pedir ao provedor para criar um gateway privado virtual em sua VPC. Usar AWS PrivateLink para se conectar ao serviço de destino.  
  - O gateway privado virtual (VPN) conecta VPCs ou redes locais, mas não é necessário neste caso, já que o PrivateLink é suficiente e mais direto para conectar ao serviço.  
- C. Criar um gateway NAT em uma sub-rede pública da VPC da empresa. Atualizar a tabela de rotas para se conectar ao serviço de destino.  
  - O gateway NAT permite conexões de saída para a internet, mas não oferece conectividade privada. Isso contraria o requisito de manter a conexão exclusivamente privada.  

</details>

---

### Questão 136
Uma empresa está migrando seu banco de dados PostgreSQL local para o Amazon Aurora PostgreSQL. O banco de dados local deve permanecer online e acessível durante a migração. O banco de dados Aurora deve permanecer sincronizado com o banco de dados local.  
Quais ações combinadas um arquiteto de soluções deve realizar para atender a esses requisitos? (Escolha duas.)

**Alternativas:**
A. Criar uma tarefa de replicação contínua.  

B. Criar um backup do banco de dados local.  

C. Criar um servidor de replicação do AWS Database Migration Service (AWS DMS).  

D. Converter o esquema do banco de dados usando o AWS Schema Conversion Tool (AWS SCT).  

E. Criar uma regra do Amazon EventBridge (Amazon CloudWatch Events) para monitorar a sincronização do banco de dados.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>C,A</resposta>

**A.** Criar uma tarefa de replicação contínua.  
**C.** Criar um servidor de replicação do AWS Database Migration Service (AWS DMS).

**Justificativa:**  
- **Por que essas opções?**  
  - **A. Criar uma tarefa de replicação contínua:** Permite que o banco de dados Aurora seja continuamente sincronizado com o banco de dados local, atendendo ao requisito de manter os dados atualizados em tempo real durante a migração.  
  - **C. Criar um servidor de replicação do AWS DMS:** O AWS DMS é o serviço recomendado para migração de bancos de dados, permitindo configurar a replicação contínua entre o banco de dados local e o Aurora PostgreSQL. O servidor de replicação gerencia o processo de migração e sincronização.  

**Por que as outras opções não são adequadas?**  
- **B. Criar um backup do banco de dados local:** Embora útil para migração inicial de dados, essa abordagem não suporta sincronização contínua e não atende ao requisito de manter o banco de dados online durante a migração.  
- **D. Converter o esquema do banco de dados usando o AWS Schema Conversion Tool (AWS SCT):** Essa ferramenta é útil para converter esquemas ao migrar entre diferentes mecanismos de banco de dados, mas, neste caso, ambos os bancos de dados usam PostgreSQL. Não é necessário para essa migração.  
- **E. Criar uma regra do Amazon EventBridge (Amazon CloudWatch Events) para monitorar a sincronização do banco de dados:** Monitoramento não é um requisito explícito para manter a sincronização ou realizar a migração. Isso pode ser uma etapa complementar, mas não atende diretamente aos requisitos descritos.  

</details>

---

### Questão 137
Uma empresa usa o AWS Organizations para criar contas AWS dedicadas para cada unidade de negócios, permitindo que cada unidade gerencie sua conta de forma independente sob demanda. O destinatário do e-mail principal perdeu uma notificação enviada ao endereço de e-mail do usuário raiz de uma conta. A empresa deseja garantir que todas as notificações futuras não sejam perdidas. As notificações futuras devem ser limitadas aos administradores das contas.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Configurar o servidor de e-mail da empresa para encaminhar mensagens enviadas ao endereço de e-mail do usuário raiz da conta AWS para todos os usuários da organização.  

B. Configurar todos os endereços de e-mail do usuário raiz das contas AWS como listas de distribuição que enviem para alguns administradores capazes de responder aos alertas. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.  

C. Configurar todas as mensagens enviadas ao endereço de e-mail do usuário raiz das contas AWS para serem encaminhadas a um único administrador responsável por monitorar alertas e redirecionar esses alertas aos grupos apropriados.  

D. Configurar todas as contas AWS existentes e todas as novas contas criadas para usarem o mesmo endereço de e-mail do usuário raiz. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Configurar todos os endereços de e-mail do usuário raiz das contas AWS como listas de distribuição que enviem para alguns administradores capazes de responder aos alertas. Configurar contatos alternativos para as contas AWS no console do AWS Organizations ou programaticamente.

**Justificativa:**  
- **Por que essa opção?**  
  - Configurar os endereços de e-mail do usuário raiz como listas de distribuição garante que múltiplos administradores recebam as notificações críticas enviadas para as contas raiz, reduzindo o risco de alertas serem ignorados.  
  - A configuração de contatos alternativos para as contas AWS permite que notificações importantes sejam enviadas diretamente aos administradores apropriados, eliminando a dependência exclusiva do usuário raiz para esse tipo de comunicação.  
  - Essa abordagem é escalável e evita o problema de notificações críticas serem perdidas.  

**Por que as outras opções não são adequadas?**  
- **A. Configurar o servidor de e-mail da empresa para encaminhar mensagens para todos os usuários da organização:**  
  - Encaminhar notificações para todos os usuários da organização pode inundar os destinatários com mensagens irrelevantes, não limitando as notificações apenas aos administradores.  
- **C. Configurar mensagens para serem enviadas a um único administrador:**  
  - Confiar em um único administrador não é uma prática recomendada, pois introduz um ponto único de falha. Isso também pode levar à perda de notificações se o administrador estiver indisponível.  
- **D. Configurar todas as contas para usarem o mesmo endereço de e-mail do usuário raiz:**  
  - Usar o mesmo endereço de e-mail para todas as contas não é recomendado, pois compromete a separação e a independência das contas, tornando mais difícil identificar de qual conta a notificação se originou.  

</details>

---

### Questão 138
Uma empresa executa sua aplicação de comércio eletrônico na AWS. Cada novo pedido é publicado como uma mensagem em uma fila RabbitMQ que roda em uma instância EC2 em uma única Zona de Disponibilidade. Essas mensagens são processadas por uma aplicação diferente que roda em outra instância EC2. Esta aplicação armazena os detalhes em um banco de dados PostgreSQL em outra instância EC2. Todas as instâncias EC2 estão na mesma Zona de Disponibilidade.  
A empresa precisa redesenhar sua arquitetura para proporcionar a maior disponibilidade com o menor esforço operacional.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam o banco de dados PostgreSQL. 

B. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.  

C. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a fila RabbitMQ. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.  

D. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a fila RabbitMQ. Criar outro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Criar um terceiro grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam o banco de dados PostgreSQL.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Migrar a fila para um par redundante (ativo/standby) de instâncias RabbitMQ no Amazon MQ. Criar um grupo de Auto Scaling Multi-AZ para instâncias EC2 que hospedam a aplicação. Migrar o banco de dados para uma implantação Multi-AZ do Amazon RDS para PostgreSQL.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon MQ com RabbitMQ:** Substituir a instância EC2 que roda RabbitMQ pelo Amazon MQ reduz a sobrecarga operacional, pois o Amazon MQ é um serviço gerenciado que oferece alta disponibilidade com pares redundantes em configuração ativa/standby.  
  - **Auto Scaling Multi-AZ para a aplicação:** A criação de um grupo Multi-AZ com Auto Scaling para as instâncias que hospedam a aplicação garante maior disponibilidade e recuperação automática em caso de falha.  
  - **Amazon RDS para PostgreSQL:** Migrar o banco de dados para o Amazon RDS com implantação Multi-AZ elimina a necessidade de gerenciar manualmente a alta disponibilidade do PostgreSQL, ao mesmo tempo em que garante replicação automática e failover.  
  - Essa solução combina alta disponibilidade e baixo esforço operacional em todos os componentes da arquitetura.  

**Por que as outras opções não são adequadas?**  
- **A. Criar grupos de Auto Scaling para instâncias EC2 que hospedam o banco de dados:**  
  - Gerenciar manualmente um cluster PostgreSQL em EC2 com Auto Scaling exige maior esforço operacional comparado ao uso do Amazon RDS Multi-AZ, o que contraria o requisito de menor esforço operacional.  
- **C. Criar grupos de Auto Scaling Multi-AZ para o RabbitMQ em EC2:**  
  - Embora forneça escalabilidade, gerenciar RabbitMQ manualmente em EC2 requer mais esforço operacional. O Amazon MQ é uma solução gerenciada mais apropriada para o caso.  
- **D. Criar três grupos de Auto Scaling Multi-AZ em EC2 para todos os componentes:**  
  - Gerenciar RabbitMQ e PostgreSQL manualmente em EC2 aumenta significativamente a complexidade operacional. Essa abordagem não atende ao requisito de menor esforço operacional.  

</details>

---

### Questão 139
Uma equipe de relatórios recebe arquivos diariamente em um bucket Amazon S3. A equipe revisa e copia manualmente os arquivos desse bucket inicial para um bucket de análise no S3 todos os dias, no mesmo horário, para uso com o Amazon QuickSight. Outras equipes começaram a enviar mais arquivos e em tamanhos maiores para o bucket inicial do S3.  
A equipe de relatórios deseja mover os arquivos automaticamente para o bucket de análise assim que eles forem enviados ao bucket inicial. Além disso, deseja usar funções AWS Lambda para executar código de correspondência de padrões nos dados copiados. Por fim, a equipe deseja enviar os arquivos de dados para um pipeline no Amazon SageMaker Pipelines.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos com o MENOR esforço operacional?

**Alternativas:**
A. Criar uma função Lambda para copiar os arquivos para o bucket de análise. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.  

B. Criar uma função Lambda para copiar os arquivos para o bucket de análise. Configurar o bucket de análise para enviar notificações de eventos para o Amazon EventBridge (Amazon CloudWatch Events). Configurar uma regra ObjectCreated no EventBridge. Configurar Lambda e SageMaker Pipelines como destinos da regra.  

C. Configurar replicação no S3 entre os buckets. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.  

D. Configurar replicação no S3 entre os buckets. Configurar o bucket de análise para enviar notificações de eventos para o Amazon EventBridge (Amazon CloudWatch Events). Configurar uma regra ObjectCreated no EventBridge. Configurar Lambda e SageMaker Pipelines como destinos da regra.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Configurar replicação no S3 entre os buckets. Criar uma notificação de evento do S3 para o bucket de análise. Configurar Lambda e SageMaker Pipelines como destinos da notificação de evento. Configurar o tipo de evento como s3:ObjectCreated:Put.

**Justificativa:**  
- **Por que essa opção?**  
  - **Replicação no S3:** Configurar replicação automática entre os buckets do S3 garante que os arquivos sejam copiados para o bucket de análise assim que forem enviados para o bucket inicial, eliminando a necessidade de criar e gerenciar uma função Lambda para esta tarefa.  
  - **Notificação de evento S3:** Configurar uma notificação no bucket de análise permite invocar uma função Lambda e enviar dados para o Amazon SageMaker Pipelines automaticamente sempre que um novo objeto é criado no bucket de análise.  
  - **Menor esforço operacional:** A replicação S3 gerenciada reduz significativamente a carga operacional, e o uso de notificações do S3 elimina a necessidade de configurar EventBridge adicionalmente.  

**Por que as outras opções não são adequadas?**  
- **A. Criar uma função Lambda para copiar os arquivos para o bucket de análise:**  
  - Usar Lambda para copiar arquivos manualmente adiciona mais complexidade e aumenta o esforço operacional, uma vez que a replicação do S3 pode realizar essa tarefa automaticamente.  
- **B. Configurar notificações EventBridge no bucket de análise:**  
  - Usar EventBridge para notificar eventos no bucket de análise adiciona uma etapa extra que não é necessária, já que as notificações do S3 podem acionar diretamente a Lambda e o SageMaker Pipelines.  
- **D. Configurar replicação no S3 e notificações EventBridge no bucket de análise:**  
  - Embora a replicação seja correta, adicionar EventBridge como um intermediário aumenta a complexidade desnecessariamente, já que notificações do S3 são suficientes para atender aos requisitos.  

</details>

---

### Questão 140
Um arquiteto de soluções precisa ajudar uma empresa a otimizar os custos de execução de uma aplicação na AWS. A aplicação usará instâncias Amazon EC2, AWS Fargate e AWS Lambda para computação dentro da arquitetura.  
As instâncias EC2 executarão a camada de ingestão de dados da aplicação. O uso de EC2 será esporádico e imprevisível. As cargas de trabalho que rodam nas instâncias EC2 podem ser interrompidas a qualquer momento. A interface da aplicação será executada no Fargate, e o Lambda atenderá a camada de API. A utilização da interface e da camada de API será previsível ao longo do próximo ano.  
Qual combinação de opções de compra fornecerá a solução mais econômica para hospedar essa aplicação? (Escolha duas.)

**Alternativas:**
A. Usar Spot Instances para a camada de ingestão de dados. 

B. Usar instâncias On-Demand para a camada de ingestão de dados.  

C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API. 

D. Comprar instâncias reservadas All Upfront de 1 ano para a camada de ingestão de dados.  

E. Comprar um Savings Plan de instâncias EC2 de 1 ano para a interface e camada de API.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>A,C</resposta>

A. Usar Spot Instances para a camada de ingestão de dados.  
C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API.

**Justificativa:**  
- **A. Usar Spot Instances para a camada de ingestão de dados:**  
  - Spot Instances são a opção mais econômica para cargas de trabalho esporádicas e tolerantes a interrupções, como a ingestão de dados. Elas oferecem descontos significativos em relação às instâncias On-Demand, reduzindo os custos para a camada de ingestão de dados.  
- **C. Comprar um Compute Savings Plan de 1 ano para a interface e camada de API:**  
  - Um Compute Savings Plan cobre qualquer tipo de computação na AWS (EC2, Fargate, Lambda) e fornece flexibilidade com descontos em contratos de longo prazo. Como o uso da interface e da camada de API será previsível ao longo de um ano, essa é a opção mais econômica.  

**Por que as outras opções não são adequadas?**  
- **B. Usar instâncias On-Demand para a camada de ingestão de dados:**  
  - Instâncias On-Demand são mais caras do que Spot Instances. Para uma carga de trabalho esporádica e tolerante a interrupções, Spot Instances são mais apropriadas.  
- **D. Comprar instâncias reservadas All Upfront de 1 ano para a camada de ingestão de dados:**  
  - As instâncias reservadas exigem um compromisso fixo, o que não é ideal para cargas de trabalho imprevisíveis e esporádicas como a ingestão de dados.  
- **E. Comprar um Savings Plan de instâncias EC2 de 1 ano para a interface e camada de API:**  
  - Um Savings Plan específico para instâncias EC2 limita-se a instâncias EC2 e não cobre Fargate e Lambda. O Compute Savings Plan é mais flexível e cobre todos os tipos de computação necessários.  

</details>

---


### Questão 141
Uma empresa opera um portal baseado na web que fornece aos usuários notícias globais de última hora, alertas locais e atualizações meteorológicas. O portal entrega uma visão personalizada para cada usuário, usando uma mistura de conteúdo estático e dinâmico. O conteúdo é servido por HTTPS através de um servidor de API que roda em uma instância Amazon EC2 atrás de um Application Load Balancer (ALB). A empresa quer que o portal forneça esse conteúdo aos usuários em todo o mundo o mais rápido possível.  
Como um arquiteto de soluções deve projetar a aplicação para garantir a MENOR latência para todos os usuários?

**Alternativas:**
A. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir todo o conteúdo estático e dinâmico, especificando o ALB como uma origem.  

B. Implantar o stack da aplicação em duas regiões AWS. Usar uma política de roteamento por latência do Amazon Route 53 para servir todo o conteúdo do ALB na região mais próxima.  

C. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir o conteúdo estático. Servir o conteúdo dinâmico diretamente do ALB.  

D. Implantar o stack da aplicação em duas regiões AWS. Usar uma política de roteamento por geolocalização do Amazon Route 53 para servir todo o conteúdo do ALB na região mais próxima.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Implantar o stack da aplicação em uma única região AWS. Usar o Amazon CloudFront para servir todo o conteúdo estático e dinâmico, especificando o ALB como uma origem.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon CloudFront:** É uma rede de entrega de conteúdo (CDN) global que reduz a latência ao armazenar conteúdo em caches próximos aos usuários. Ele suporta a entrega tanto de conteúdo estático quanto dinâmico.  
  - **ALB como origem:** O CloudFront pode ser configurado para usar o ALB como uma origem para conteúdo dinâmico, garantindo que todos os usuários recebam respostas com baixa latência.  
  - **Simples e eficaz:** Manter o stack em uma única região reduz a complexidade operacional, e o uso do CloudFront garante a menor latência para usuários globais.  

**Por que as outras opções não são adequadas?**  
- **B. Implantar em duas regiões com política de roteamento por latência no Route 53:**  
  - Ter duas regiões aumenta a complexidade e os custos operacionais. O Route 53 por si só não reduz significativamente a latência global, pois os dados ainda precisam ser servidos diretamente do ALB sem um cache distribuído.  
- **C. Usar o CloudFront para conteúdo estático e o ALB para conteúdo dinâmico:**  
  - Embora funcione, essa abordagem introduz latência adicional para conteúdo dinâmico, já que ele não se beneficia do cache distribuído do CloudFront.  
- **D. Implantar em duas regiões com política de roteamento por geolocalização no Route 53:**  
  - Similar à opção B, adicionar outra região aumenta a complexidade e os custos operacionais. Além disso, o roteamento por geolocalização não melhora a latência de forma tão eficaz quanto o uso de uma CDN como o CloudFront.  

</details>

---

### Questão 142
Uma empresa de jogos está projetando uma arquitetura altamente disponível. A aplicação roda em um kernel Linux modificado e suporta apenas tráfego baseado em UDP. A empresa precisa que a camada front-end forneça a melhor experiência possível para o usuário. Essa camada deve ter baixa latência, rotear o tráfego para a localização de borda mais próxima e fornecer endereços IP estáticos para entrada nos endpoints da aplicação.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Configurar o Amazon Route 53 para encaminhar solicitações para um Application Load Balancer. Usar AWS Lambda para a aplicação em um grupo de escalabilidade automática do AWS Application Auto Scaling.  

B. Configurar o Amazon CloudFront para encaminhar solicitações para um Network Load Balancer. Usar AWS Lambda para a aplicação em um grupo de escalabilidade automática do AWS Application Auto Scaling.  

C. Configurar o AWS Global Accelerator para encaminhar solicitações para um Network Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.  

D. Configurar o Amazon API Gateway para encaminhar solicitações para um Application Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Configurar o AWS Global Accelerator para encaminhar solicitações para um Network Load Balancer. Usar instâncias Amazon EC2 para a aplicação em um grupo de Auto Scaling do EC2.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS Global Accelerator:** Fornece endereços IP estáticos globais e roteia o tráfego para a localização de borda mais próxima, garantindo baixa latência e a melhor experiência do usuário.  
  - **Network Load Balancer (NLB):** Suporta tráfego baseado em UDP, atendendo ao requisito específico da aplicação.  
  - **Amazon EC2 com Auto Scaling:** Permite a execução do kernel Linux modificado com alta disponibilidade e escalabilidade automática para lidar com mudanças na demanda.  
  - Essa combinação atende a todos os requisitos de baixa latência, suporte a UDP, endereços IP estáticos e roteamento para a localização de borda mais próxima.  

**Por que as outras opções não são adequadas?**  
- **A. Route 53 com Application Load Balancer (ALB) e AWS Lambda:**  
  - O ALB não suporta tráfego UDP, apenas TCP e HTTP/HTTPS, tornando essa configuração incompatível. Além disso, o Lambda não permite kernels modificados.  
- **B. CloudFront com Network Load Balancer e AWS Lambda:**  
  - O Amazon CloudFront não suporta UDP, apenas HTTP/HTTPS. O uso de Lambda também não atende ao requisito de um kernel Linux modificado.  
- **D. API Gateway com Application Load Balancer e EC2:**  
  - O API Gateway é projetado para tráfego HTTP/HTTPS, não para UDP. Além disso, o ALB não suporta UDP, tornando essa configuração inviável.  

</details>

---
### Questão 143
Uma empresa deseja migrar sua aplicação monolítica on-premises existente para a AWS. A empresa quer manter o máximo possível do código do front-end e do back-end. No entanto, a empresa deseja dividir a aplicação em partes menores, com cada parte gerenciada por uma equipe diferente. A solução precisa ser altamente escalável e minimizar a sobrecarga operacional.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Hospedar a aplicação no AWS Lambda. Integrar a aplicação com o Amazon API Gateway.  

B. Hospedar a aplicação com AWS Amplify. Conectar a aplicação a uma API do Amazon API Gateway integrada ao AWS Lambda.  

C. Hospedar a aplicação em instâncias Amazon EC2. Configurar um Application Load Balancer com instâncias EC2 em um grupo de Auto Scaling como destinos.  

D. Hospedar a aplicação no Amazon Elastic Container Service (Amazon ECS). Configurar um Application Load Balancer com o Amazon ECS como o destino.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Hospedar a aplicação no Amazon Elastic Container Service (Amazon ECS). Configurar um Application Load Balancer com o Amazon ECS como o destino.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon ECS:** Permite executar partes da aplicação como contêineres, o que facilita a divisão do monólito em serviços menores. Cada serviço pode ser gerenciado independentemente por equipes diferentes.  
  - **Application Load Balancer (ALB):** Permite a roteação de tráfego entre os diferentes contêineres com base em regras, fornecendo alta escalabilidade e suporte a arquiteturas baseadas em microsserviços.  
  - **Baixa sobrecarga operacional:** O ECS, especialmente quando usado com o AWS Fargate, reduz a necessidade de gerenciar a infraestrutura subjacente, cumprindo o requisito de minimizar a sobrecarga operacional.  

**Por que as outras opções não são adequadas?**  
- **A. AWS Lambda com Amazon API Gateway:**  
  - Embora o Lambda seja altamente escalável e de baixa sobrecarga operacional, ele é mais adequado para aplicações nativas de serverless e não é ideal para aplicações monolíticas existentes que precisam ser divididas. Além disso, o Lambda requer uma reescrita significativa do código para atender à arquitetura baseada em funções.  
- **B. AWS Amplify com Amazon API Gateway e Lambda:**  
  - O AWS Amplify é focado em aplicações web e móveis, e não é uma solução prática para migrações de aplicações monolíticas com back-ends complexos. Ele não atende bem aos requisitos de dividir a aplicação e manter boa parte do código existente.  
- **C. EC2 com Application Load Balancer:**  
  - Embora o EC2 seja altamente flexível, ele exige maior esforço operacional para gerenciar instâncias e a infraestrutura. Isso não cumpre o requisito de minimizar a sobrecarga operacional.  

</details>

---

### Questão 144
Uma empresa recentemente começou a usar o Amazon Aurora como repositório de dados para sua aplicação global de comércio eletrônico. Quando relatórios grandes são executados, os desenvolvedores relatam que a aplicação de comércio eletrônico apresenta baixo desempenho. Após revisar as métricas no Amazon CloudWatch, um arquiteto de soluções percebe que as métricas de **ReadIOPS** e **CPUUtilization** aumentam significativamente durante a execução dos relatórios mensais.  
Qual é a solução MAIS econômica?

**Alternativas:**
A. Migrar os relatórios mensais para o Amazon Redshift.  

B. Migrar os relatórios mensais para um Aurora Replica.  

C. Migrar o banco de dados Aurora para uma classe de instância maior.  

D. Aumentar o IOPS provisionado na instância do Aurora.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Migrar os relatórios mensais para um Aurora Replica.

**Justificativa:**  
- **Por que essa opção?**  
  - **Aurora Replica:** Criar uma réplica de leitura no Aurora permite distribuir a carga de trabalho entre a réplica e o banco de dados principal. Os relatórios podem ser executados na réplica, reduzindo a carga no banco principal e melhorando o desempenho da aplicação de comércio eletrônico.  
  - **Custo-benefício:** As réplicas Aurora são uma solução econômica, pois evitam a necessidade de redimensionar a instância principal ou migrar para outra tecnologia como o Redshift.  
  - **Escalabilidade:** Réplicas podem ser adicionadas conforme necessário, permitindo escalar horizontalmente para lidar com cargas de leitura pesadas.  

**Por que as outras opções não são adequadas?**  
- **A. Migrar os relatórios mensais para o Amazon Redshift:**  
  - Embora o Redshift seja adequado para cargas de trabalho analíticas, essa solução requer migração de dados e reescrita de consultas, aumentando a complexidade e os custos. Além disso, o Redshift pode ser excessivo para relatórios mensais ocasionais.  
- **C. Migrar o banco de dados Aurora para uma classe de instância maior:**  
  - Redimensionar a instância Aurora aumenta os custos significativamente e resolve apenas temporariamente o problema de desempenho, sem separar adequadamente as cargas de trabalho de leitura e escrita.  
- **D. Aumentar o IOPS provisionado na instância do Aurora:**  
  - Aumentar o IOPS pode melhorar a capacidade de leitura e escrita, mas não aborda o problema da alta utilização da CPU causada pelos relatórios. Isso também pode ser uma solução mais cara do que usar uma réplica Aurora.  

</details>

---

### Questão 145
Uma empresa hospeda uma aplicação de análise de websites em uma única instância Amazon EC2 On-Demand. O software de análise é escrito em PHP e usa um banco de dados MySQL. O software de análise, o servidor web que fornece PHP e o servidor do banco de dados estão todos hospedados na instância EC2. A aplicação está apresentando sinais de degradação de desempenho durante horários de pico e exibindo erros 5xx. A empresa precisa fazer a aplicação escalar de forma transparente.  
Qual solução atenderá a esses requisitos de maneira MAIS econômica?

**Alternativas:**
A. Migrar o banco de dados para uma instância Amazon RDS for MySQL. Criar uma AMI da aplicação web. Usar a AMI para iniciar uma segunda instância EC2 On-Demand. Usar um Application Load Balancer para distribuir a carga entre as instâncias EC2.  

B. Migrar o banco de dados para uma instância Amazon RDS for MySQL. Criar uma AMI da aplicação web. Usar a AMI para iniciar uma segunda instância EC2 On-Demand. Usar o Amazon Route 53 com roteamento ponderado para distribuir a carga entre as duas instâncias EC2.

C. Migrar o banco de dados para uma instância Amazon Aurora MySQL. Criar uma função AWS Lambda para parar a instância EC2 e alterar o tipo de instância. Criar um alarme do Amazon CloudWatch para invocar a função Lambda quando a utilização de CPU ultrapassar 75%.  

D. Migrar o banco de dados para uma instância Amazon Aurora MySQL. Criar uma AMI da aplicação web. Aplicar a AMI a um template de inicialização. Criar um Auto Scaling group com o template de inicialização. Configurar o template para usar uma Spot Fleet. Anexar um Application Load Balancer ao Auto Scaling group.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Migrar o banco de dados para uma instância Amazon RDS for MySQL. Criar uma AMI da aplicação web. Usar a AMI para iniciar uma segunda instância EC2 On-Demand. Usar um Application Load Balancer para distribuir a carga entre as instâncias EC2.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon RDS for MySQL:** Separar o banco de dados do servidor web reduz a carga na instância EC2 e melhora o desempenho. RDS é uma solução gerenciada que reduz a sobrecarga operacional e aumenta a escalabilidade.  
  - **AMI e segunda instância EC2:** Criar uma segunda instância usando uma AMI permite distribuir a carga entre as duas instâncias, reduzindo os erros 5xx causados por sobrecarga.  
  - **Application Load Balancer:** Distribui a carga de tráfego de forma eficiente e escalável, garantindo alta disponibilidade.  
  - **Custo-benefício:** Usar instâncias On-Demand para o tráfego inicial é mais econômico do que implementar uma solução mais complexa, como Spot Fleets ou Aurora MySQL.  

**Por que as outras opções não são adequadas?**  
- **B. Route 53 com roteamento ponderado:**  
  - Embora o roteamento ponderado distribua o tráfego, ele não verifica o estado das instâncias. Isso pode causar problemas caso uma instância falhe, enquanto um ALB fornece balanceamento e verificação de integridade automáticos.  
- **C. Aurora MySQL com Lambda e alteração de tipo de instância:**  
  - Alterar o tipo de instância EC2 com Lambda e CloudWatch não resolve o problema de escalabilidade horizontal e ainda resulta em downtime durante a alteração do tipo de instância. Essa abordagem não é ideal para alta disponibilidade.  
- **D. Aurora MySQL com Auto Scaling e Spot Fleet:**  
  - Embora seja uma solução escalável, usar Spot Fleets pode introduzir indisponibilidade devido à natureza das instâncias Spot. Essa abordagem é mais complexa e cara do que o necessário para o cenário apresentado.  

</details>

---

### Questão 146
Uma empresa executa uma aplicação web sem estado em produção em um grupo de instâncias Amazon EC2 On-Demand atrás de um Application Load Balancer. A aplicação experimenta uso intenso durante um período de 8 horas em cada dia útil. O uso da aplicação é moderado e estável durante a noite. Nos finais de semana, o uso é baixo.  
A empresa deseja minimizar os custos das instâncias EC2 sem afetar a disponibilidade da aplicação.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Usar Spot Instances para toda a carga de trabalho.  

B. Usar Reserved Instances para o nível básico de uso. Usar Spot Instances para qualquer capacidade adicional necessária pela aplicação.  

C. Usar On-Demand Instances para o nível básico de uso. Usar Spot Instances para qualquer capacidade adicional necessária pela aplicação.  

D. Usar Dedicated Instances para o nível básico de uso. Usar On-Demand Instances para qualquer capacidade adicional necessária pela aplicação.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Usar Reserved Instances para o nível básico de uso. Usar Spot Instances para qualquer capacidade adicional necessária pela aplicação.

**Justificativa:**  
- **Por que essa opção?**  
  - **Reserved Instances:** Para uso moderado e previsível, como o período noturno e de finais de semana, as Reserved Instances oferecem um custo menor em relação às On-Demand Instances, sendo ideais para a carga de trabalho estável e de longo prazo.  
  - **Spot Instances:** Para as cargas de trabalho adicionais durante o período de uso intenso, as Spot Instances são uma solução econômica e escalável. Como a aplicação é sem estado, ela pode tolerar interrupções ocasionais, tornando as Spot Instances apropriadas.  
  - **Custo-benefício:** Essa combinação otimiza os custos ao aproveitar os preços baixos das Spot Instances e a previsibilidade das Reserved Instances.  

**Por que as outras opções não são adequadas?**  
- **A. Usar Spot Instances para toda a carga de trabalho:**  
  - As Spot Instances podem ser interrompidas pela AWS com pouca ou nenhuma notificação, o que pode afetar a disponibilidade da aplicação, especialmente durante os períodos de uso intenso.  
- **C. Usar On-Demand Instances para o nível básico de uso e Spot Instances para capacidade adicional:**  
  - Embora funcione, as On-Demand Instances têm um custo mais alto em comparação às Reserved Instances, o que não atende ao objetivo de minimizar os custos.  
- **D. Usar Dedicated Instances para o nível básico de uso e On-Demand Instances para capacidade adicional:**  
  - Dedicated Instances são significativamente mais caras e são destinadas a casos específicos que exigem isolamento físico, o que não é necessário para esta aplicação.  

</details>

---

### Questão 147
Uma empresa precisa reter arquivos de log de uma aplicação crítica por 10 anos. A equipe de aplicação acessa regularmente os logs do último mês para solução de problemas, mas logs mais antigos raramente são acessados. A aplicação gera mais de 10 TB de logs por mês.  
Qual opção de armazenamento atende a esses requisitos de forma MAIS econômica?

**Alternativas:**
A. Armazenar os logs no Amazon S3. Usar o AWS Backup para mover logs com mais de 1 mês para o S3 Glacier Deep Archive.  

B. Armazenar os logs no Amazon S3. Usar políticas de ciclo de vida (Lifecycle) do S3 para mover logs com mais de 1 mês para o S3 Glacier Deep Archive.  

C. Armazenar os logs no Amazon CloudWatch Logs. Usar o AWS Backup para mover logs com mais de 1 mês para o S3 Glacier Deep Archive.  

D. Armazenar os logs no Amazon CloudWatch Logs. Usar políticas de ciclo de vida do Amazon S3 para mover logs com mais de 1 mês para o S3 Glacier Deep Archive.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Armazenar os logs no Amazon S3. Usar políticas de ciclo de vida (Lifecycle) do S3 para mover logs com mais de 1 mês para o S3 Glacier Deep Archive.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon S3:** O S3 é uma solução econômica e escalável para armazenar grandes volumes de dados como logs.  
  - **S3 Glacier Deep Archive:** Este armazenamento é altamente econômico para dados raramente acessados e ideal para retenção de longo prazo, como logs que precisam ser mantidos por 10 anos.  
  - **Políticas de ciclo de vida do S3:** Automatizam a movimentação dos dados com base em critérios de idade, movendo logs antigos de forma eficiente e sem intervenção manual para economizar custos.  
  - **Custo-benefício:** Essa abordagem elimina a necessidade de serviços adicionais como o AWS Backup, reduzindo a sobrecarga operacional e os custos.  

**Por que as outras opções não são adequadas?**  
- **A. Usar AWS Backup para mover os logs do S3 para o S3 Glacier Deep Archive:**  
  - O AWS Backup adiciona custos e complexidade desnecessários, uma vez que as políticas de ciclo de vida do S3 oferecem funcionalidade equivalente de forma mais econômica.  
- **C. Usar CloudWatch Logs e AWS Backup para mover logs para o S3 Glacier Deep Archive:**  
  - O CloudWatch Logs é mais caro para armazenar grandes volumes de dados como logs gerados em massa. Além disso, mover os logs para o S3 Glacier Deep Archive usando AWS Backup adiciona custos extras.  
- **D. Usar CloudWatch Logs com políticas de ciclo de vida do S3:**  
  - CloudWatch Logs não suporta diretamente as políticas de ciclo de vida do S3. Além disso, o CloudWatch Logs é menos econômico para armazenar volumes massivos de dados comparado ao S3.
</details>

---

### Questão 148
Uma empresa possui um fluxo de ingestão de dados que inclui os seguintes componentes:  
- Um tópico do Amazon Simple Notification Service (Amazon SNS) que recebe notificações sobre novas entregas de dados.  
- Uma função AWS Lambda que processa e armazena os dados.  

O fluxo de ingestão falha ocasionalmente devido a problemas de conectividade de rede. Quando ocorre uma falha, os dados correspondentes não são ingeridos, a menos que a empresa execute manualmente o trabalho novamente.  
O que um arquiteto de soluções deve fazer para garantir que todas as notificações sejam processadas eventualmente?

**Alternativas:**
A. Configurar a função Lambda para implantação em várias Zonas de Disponibilidade.  

B. Modificar a configuração da função Lambda para aumentar as alocações de CPU e memória da função.  

C. Configurar a estratégia de repetição do tópico SNS para aumentar tanto o número de tentativas quanto o tempo de espera entre as tentativas.  

D. Configurar uma fila do Amazon Simple Queue Service (Amazon SQS) como o destino de falha. Modificar a função Lambda para processar mensagens na fila.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Configurar uma fila do Amazon Simple Queue Service (Amazon SQS) como o destino de falha. Modificar a função Lambda para processar mensagens na fila.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon SQS como destino de falha:** Configurar uma fila SQS garante que as mensagens que não puderem ser processadas inicialmente sejam armazenadas de forma confiável para processamento posterior.  
  - **Garantia de entrega:** O SQS funciona como um buffer, garantindo que nenhuma mensagem seja perdida devido a falhas temporárias na conectividade ou outros problemas.  
  - **Resiliência:** A função Lambda pode ser configurada para consumir mensagens diretamente da fila SQS, garantindo o reprocessamento automático de mensagens sem intervenção manual.  

**Por que as outras opções não são adequadas?**  
- **A. Configurar a função Lambda para implantação em várias Zonas de Disponibilidade:**  
  - As funções Lambda já são implantadas de forma automática em várias Zonas de Disponibilidade, portanto, isso não resolve o problema de falha causado por conectividade de rede.  
- **B. Modificar a configuração da função Lambda para aumentar CPU e memória:**  
  - Aumentar recursos de CPU e memória não resolve problemas relacionados à conectividade de rede ou falhas temporárias no fluxo de mensagens.  
- **C. Configurar a estratégia de repetição do tópico SNS:**  
  - Embora o aumento do número de tentativas e o tempo de espera possam reduzir falhas temporárias, isso não garante que todas as mensagens sejam processadas eventualmente, pois não há armazenamento persistente para mensagens que falharam após várias tentativas.  
</details>

---

### Questão 149
Uma empresa possui um serviço que produz dados de eventos. A empresa deseja usar a AWS para processar os dados de eventos à medida que são recebidos. Os dados são escritos em uma ordem específica que deve ser mantida durante o processamento. A empresa quer implementar uma solução que minimize a sobrecarga operacional.  
Como um arquiteto de soluções deve atender a esse requisito?

**Alternativas:**
A. Criar uma fila FIFO do Amazon Simple Queue Service (Amazon SQS) para armazenar mensagens. Configurar uma função AWS Lambda para processar mensagens da fila.  

B. Criar um tópico do Amazon Simple Notification Service (Amazon SNS) para entregar notificações contendo os dados a serem processados. Configurar uma função AWS Lambda como assinante.  

C. Criar uma fila padrão do Amazon Simple Queue Service (Amazon SQS) para armazenar mensagens. Configurar uma função AWS Lambda para processar mensagens da fila de forma independente.  

D. Criar um tópico do Amazon Simple Notification Service (Amazon SNS) para entregar notificações contendo os dados a serem processados. Configurar uma fila do Amazon Simple Queue Service (Amazon SQS) como assinante.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Criar uma fila FIFO do Amazon Simple Queue Service (Amazon SQS) para armazenar mensagens. Configurar uma função AWS Lambda para processar mensagens da fila.

**Justificativa:**  
- **Por que essa opção?**  
  - **Fila FIFO do SQS:** Garante a entrega em ordem exata (First-In-First-Out), mantendo a sequência de mensagens durante o processamento, atendendo ao requisito de preservação da ordem.  
  - **AWS Lambda:** Automatiza o processamento de mensagens, reduzindo a sobrecarga operacional e eliminando a necessidade de gerenciar servidores ou infraestrutura.  
  - **Baixa sobrecarga operacional:** Essa configuração utiliza serviços gerenciados da AWS e minimiza a necessidade de manutenção.  

**Por que as outras opções não são adequadas?**  
- **B. Criar um tópico SNS com uma função Lambda como assinante:**  
  - O SNS não preserva a ordem das mensagens, o que o torna inadequado para cenários em que a ordem dos dados é crítica.  
- **C. Criar uma fila padrão do SQS:**  
  - As filas padrão do SQS não garantem a ordem das mensagens, o que pode levar a problemas de processamento fora de sequência.  
- **D. Criar um tópico SNS com uma fila SQS como assinante:**  
  - Embora adicionar uma fila SQS como assinante possa ajudar no gerenciamento de mensagens, o SNS ainda não garante a ordem das mensagens, tornando essa abordagem inadequada.  

</details>

---

### Questão 150
Uma empresa está migrando uma aplicação de servidores on-premises para instâncias Amazon EC2. Como parte dos requisitos de design da migração, um arquiteto de soluções deve implementar alarmes de métricas de infraestrutura.  
A empresa não precisa tomar ação se a utilização de CPU aumentar para mais de 50% por um curto período. No entanto, se a utilização de CPU aumentar para mais de 50% **e** os IOPS de leitura no disco estiverem altos ao mesmo tempo, a empresa precisa agir o mais rápido possível. O arquiteto de soluções também deve reduzir alarmes falsos.  
O que o arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Criar alarmes compostos do Amazon CloudWatch sempre que possível.  

B. Criar painéis do Amazon CloudWatch para visualizar as métricas e reagir rapidamente aos problemas.

C. Criar canários do Amazon CloudWatch Synthetics para monitorar a aplicação e gerar alarmes.  

D. Criar alarmes de métrica única no Amazon CloudWatch com múltiplos limiares de métricas, sempre que possível.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Criar alarmes compostos do Amazon CloudWatch sempre que possível.

**Justificativa:**  
- **Por que essa opção?**  
  - **Alarme composto do CloudWatch:** Permite combinar condições de vários alarmes usando operadores lógicos (por exemplo, AND, OR). Isso é ideal para cenários em que múltiplas condições precisam ser atendidas simultaneamente antes de acionar um alarme, como CPU acima de 50% **e** IOPS de leitura altos.  
  - **Redução de alarmes falsos:** Os alarmes compostos garantem que apenas as situações que atendam a todas as condições disparem um alarme, minimizando alarmes desnecessários.  
  - **Reação rápida:** Atende à necessidade de agir imediatamente quando ambas as condições críticas forem atendidas.  

**Por que as outras opções não são adequadas?**  
- **B. Criar painéis do Amazon CloudWatch:**  
  - Painéis ajudam na visualização, mas não geram alarmes ou notificações automáticas. Isso não atende ao requisito de alertar rapidamente quando ambas as condições forem atendidas.  
- **C. Criar canários do Amazon CloudWatch Synthetics:**  
  - Synthetics monitora endpoints ou aplicativos simulando interações, mas não é adequado para monitorar métricas de infraestrutura como CPU e IOPS.  
- **D. Criar alarmes de métrica única com múltiplos limiares:**  
  - Os alarmes de métrica única avaliam apenas uma métrica por vez. Embora suportem múltiplos limiares para essa métrica, não podem combinar condições de várias métricas (como CPU e IOPS), tornando-os inadequados para este caso.  

</details>

---

### Questão 151
Uma empresa deseja migrar seu data center on-premises para a AWS. De acordo com os requisitos de conformidade da empresa, ela pode usar apenas a região **ap-northeast-3**. Os administradores da empresa não têm permissão para conectar VPCs à internet.  
Quais soluções atenderão a esses requisitos? (Escolha duas.)

**Alternativas:**
A. Usar o AWS Control Tower para implementar guardrails de residência de dados para negar acesso à internet e negar acesso a todas as regiões da AWS, exceto **ap-northeast-3**.  

B. Usar regras no AWS WAF para impedir acesso à internet. Negar acesso a todas as regiões da AWS, exceto **ap-northeast-3**, nas configurações da conta AWS. 

C. Usar o AWS Organizations para configurar políticas de controle de serviço (SCPs) que impeçam as VPCs de obter acesso à internet. Negar acesso a todas as regiões da AWS, exceto **ap-northeast-3**.  

D. Criar uma regra de saída para a ACL de rede em cada VPC para negar todo o tráfego de 0.0.0.0/0. Criar uma política do IAM para cada usuário para impedir o uso de qualquer região da AWS que não seja **ap-northeast-3**.  

E. Usar o AWS Config para ativar regras gerenciadas para detectar e alertar sobre gateways de internet e para detectar e alertar sobre novos recursos implantados fora de **ap-northeast-3**.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**
<resposta>C,E</resposta>

C. Usar o AWS Organizations para configurar políticas de controle de serviço (SCPs) que impeçam as VPCs de obter acesso à internet. Negar acesso a todas as regiões da AWS, exceto **ap-northeast-3**.  
E. Usar o AWS Config para ativar regras gerenciadas para detectar e alertar sobre gateways de internet e para detectar e alertar sobre novos recursos implantados fora de **ap-northeast-3**.

**Justificativa:**  
- **Por que essas opções?**  
  - **C. AWS Organizations com SCPs:**  
    - SCPs podem ser usadas para aplicar restrições em contas membros dentro da organização, incluindo impedir o uso de regiões não permitidas e proibir a criação de gateways de internet ou outras formas de acesso à internet. Isso atende diretamente aos requisitos de conformidade.  
  - **E. AWS Config:**  
    - Regras gerenciadas no AWS Config permitem detectar recursos indesejados, como gateways de internet, e identificar novos recursos implantados fora da região permitida. Isso ajuda a monitorar e manter a conformidade.  

**Por que as outras opções não são adequadas?**  
- **A. AWS Control Tower:**  
  - Embora o Control Tower seja útil para gerenciar ambientes multi-conta, ele não fornece suporte direto para negar o uso de regiões ou bloquear o acesso à internet por meio de VPCs. Além disso, sua funcionalidade de guardrails depende de outros serviços, como o AWS Config e SCPs, para implementação.  
- **B. AWS WAF:**  
  - O AWS WAF é projetado para proteger aplicações web contra tráfego malicioso. Ele não impede diretamente o acesso à internet de VPCs nem restringe o uso de regiões da AWS.  
- **D. ACLs de rede e políticas do IAM:**  
  - Bloquear tráfego com ACLs de rede é uma abordagem limitada e não impede totalmente o uso de gateways de internet. Além disso, o uso de políticas do IAM para restringir regiões não é eficiente, pois elas não foram projetadas para esse propósito.  

</details>

---

### Questão 152
Uma empresa utiliza uma aplicação web de três camadas para fornecer treinamento a novos funcionários. A aplicação é acessada apenas durante 12 horas por dia. A empresa está usando uma instância Amazon RDS for MySQL para armazenar informações e deseja minimizar os custos.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?

**Alternativas:**
A. Configurar uma política do IAM para o AWS Systems Manager Session Manager. Criar uma função IAM para a política. Atualizar a relação de confiança da função. Configurar início e parada automáticos para a instância de banco de dados. 

B. Criar um cluster Amazon ElastiCache for Redis que permita aos usuários acessar os dados do cache quando a instância de banco de dados estiver parada. Invalidar o cache após a instância de banco de dados ser iniciada.  

C. Lançar uma instância Amazon EC2. Criar uma função IAM que conceda acesso ao Amazon RDS. Anexar a função à instância EC2. Configurar um cron job para iniciar e parar a instância EC2 no horário desejado.  

D. Criar funções AWS Lambda para iniciar e parar a instância de banco de dados. Criar regras agendadas do Amazon EventBridge (Amazon CloudWatch Events) para invocar as funções Lambda. Configurar as funções Lambda como destinos dos eventos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Criar funções AWS Lambda para iniciar e parar a instância de banco de dados. Criar regras agendadas do Amazon EventBridge (Amazon CloudWatch Events) para invocar as funções Lambda. Configurar as funções Lambda como destinos dos eventos.

**Justificativa:**  
- **Por que essa opção?**  
  - **Lambda Functions:** Permite a execução de scripts personalizados para iniciar e parar a instância RDS automaticamente, minimizando custos ao manter o banco de dados desligado fora do horário de uso.  
  - **EventBridge (CloudWatch Events):** Fornece um mecanismo confiável e simples para agendar eventos, como ligar e desligar a instância de banco de dados.  
  - **Custo-benefício:** Essa abordagem utiliza serviços gerenciados da AWS, reduzindo a sobrecarga operacional e eliminando a necessidade de gerenciar servidores adicionais.  

**Por que as outras opções não são adequadas?**  
- **A. Configurar Systems Manager Session Manager:**  
  - Systems Manager Session Manager não é projetado para gerenciar a programação de início e parada de instâncias RDS. A solução adiciona complexidade desnecessária sem benefícios claros para este caso.  
- **B. Criar um cluster ElastiCache for Redis:**  
  - Implementar um cache Redis para substituir temporariamente o RDS é uma solução mais complexa e cara. Além disso, invalidar o cache após o reinício do banco de dados não resolve o problema de custos do RDS.  
- **C. Configurar uma instância EC2 para gerenciar cron jobs:**  
  - Usar uma instância EC2 para gerenciar a programação de início e parada do banco de dados é mais caro e adiciona sobrecarga operacional em comparação com uma solução baseada em Lambda e EventBridge.  

</details>

---

### Questão 153
Uma empresa vende toques de celular criados a partir de trechos de músicas populares. Os arquivos contendo os toques são armazenados no Amazon S3 Standard e têm pelo menos 128 KB de tamanho. A empresa possui milhões de arquivos, mas os downloads são infrequentes para toques mais antigos que 90 dias. A empresa precisa economizar nos custos de armazenamento, mantendo os arquivos mais acessados prontamente disponíveis para seus usuários.  
Qual ação a empresa deve realizar para atender a esses requisitos da forma MAIS econômica?

**Alternativas:**
A. Configurar o armazenamento S3 Standard-Infrequent Access (S3 Standard-IA) como o nível inicial de armazenamento dos objetos.  

B. Mover os arquivos para o S3 Intelligent-Tiering e configurá-lo para mover os objetos para um nível de armazenamento menos caro após 90 dias.  

C. Configurar o inventário S3 para gerenciar objetos e movê-los para o S3 Standard-Infrequent Access (S3 Standard-IA) após 90 dias.  

D. Implementar uma política de ciclo de vida no S3 que mova os objetos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) após 90 dias.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Implementar uma política de ciclo de vida no S3 que mova os objetos do S3 Standard para o S3 Standard-Infrequent Access (S3 Standard-IA) após 90 dias.

**Justificativa:**  
- **Por que essa opção?**  
  - **S3 Standard-IA:** É um armazenamento mais econômico para objetos acessados com pouca frequência, mantendo boa latência e throughput. Como os arquivos de toques mais antigos que 90 dias são raramente acessados, movê-los para S3 Standard-IA reduz custos.  
  - **Política de ciclo de vida (Lifecycle Policy):** Automatiza a transição dos objetos entre classes de armazenamento com base no tempo, eliminando a necessidade de gerenciamento manual.  
  - **Custo-benefício:** Essa abordagem é direta e econômica, já que o S3 Standard-IA é mais barato que o S3 Standard e é ideal para dados com padrões de acesso menos frequentes.  

**Por que as outras opções não são adequadas?**  
- **A. Configurar S3 Standard-IA como o nível inicial de armazenamento:**  
  - O S3 Standard-IA tem custos de acesso mais altos. Colocar arquivos frequentemente acessados diretamente no S3 Standard-IA pode aumentar os custos devido às taxas de recuperação.  
- **B. Mover os arquivos para o S3 Intelligent-Tiering:**  
  - O S3 Intelligent-Tiering é ideal para padrões de acesso imprevisíveis, mas tem um custo adicional de monitoramento. Como os padrões de acesso são previsíveis (raros após 90 dias), o Intelligent-Tiering seria mais caro do que necessário.  
- **C. Configurar o inventário S3 para gerenciar objetos:**  
  - O inventário S3 fornece relatórios sobre objetos, mas não automatiza a movimentação de objetos entre classes de armazenamento. Isso adiciona trabalho manual e não é a solução mais eficiente.  

</details>

---

### Questão 154
Uma empresa precisa salvar os resultados de um teste médico em um repositório Amazon S3. O repositório deve permitir que alguns cientistas adicionem novos arquivos e restringir todos os outros usuários apenas para acesso de leitura. Nenhum usuário pode ter a capacidade de modificar ou excluir quaisquer arquivos no repositório. A empresa deve manter todos os arquivos no repositório por pelo menos 1 ano após a data de criação.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Usar o S3 Object Lock no modo de governança com um bloqueio legal de 1 ano.  

B. Usar o S3 Object Lock no modo de conformidade com um período de retenção de 365 dias.  

C. Usar uma função IAM para restringir todos os usuários de excluir ou alterar objetos no bucket S3. Usar uma política de bucket S3 para permitir apenas a função IAM.  

D. Configurar o bucket S3 para invocar uma função AWS Lambda toda vez que um objeto for adicionado. Configurar a função para rastrear o hash do objeto salvo para que objetos modificados possam ser marcados de acordo.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Usar o S3 Object Lock no modo de conformidade com um período de retenção de 365 dias.

**Justificativa:**  
- **Por que essa opção?**  
  - **S3 Object Lock em modo de conformidade:** O modo de conformidade garante que ninguém, nem mesmo os administradores da conta, possa modificar ou excluir os arquivos durante o período de retenção especificado. Isso atende ao requisito de impedir alterações e exclusões.  
  - **Período de retenção de 365 dias:** O período de retenção garante que os arquivos sejam mantidos por pelo menos 1 ano, cumprindo o requisito de retenção mínima.  
  - **Controle refinado:** O S3 Object Lock permite que as permissões de escrita sejam concedidas a determinados usuários (cientistas), enquanto outros usuários podem ser restritos ao acesso somente leitura.  

**Por que as outras opções não são adequadas?**  
- **A. S3 Object Lock no modo de governança com bloqueio legal:**  
  - No modo de governança, os administradores ainda podem modificar ou excluir objetos se tiverem permissões suficientes, o que não atende aos requisitos de impedir alterações ou exclusões.  
- **C. Usar uma função IAM e políticas de bucket S3:**  
  - As políticas do IAM e do bucket não podem garantir a retenção mínima de 1 ano, pois elas podem ser alteradas. Além disso, isso não impede que administradores modifiquem ou excluam arquivos.  
- **D. Configurar o S3 para invocar uma função Lambda:**  
  - Esta abordagem não impede alterações ou exclusões diretamente. Ela também adiciona complexidade desnecessária sem garantir conformidade com o período de retenção de 1 ano.  

</details>

---

### Questão 155
Uma grande empresa de mídia hospeda uma aplicação web na AWS. A empresa deseja começar a armazenar em cache arquivos de mídia confidenciais para que usuários ao redor do mundo tenham acesso confiável aos arquivos. O conteúdo é armazenado em buckets Amazon S3. A empresa precisa entregar o conteúdo rapidamente, independentemente de onde as solicitações se originam geograficamente.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Usar o AWS DataSync para conectar os buckets S3 à aplicação web.  

B. Implantar o AWS Global Accelerator para conectar os buckets S3 à aplicação web.  

C. Implantar o Amazon CloudFront para conectar os buckets S3 aos servidores de borda do CloudFront.  

D. Usar o Amazon Simple Queue Service (Amazon SQS) para conectar os buckets S3 à aplicação web.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Implantar o Amazon CloudFront para conectar os buckets S3 aos servidores de borda do CloudFront.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon CloudFront:** É uma rede de entrega de conteúdo (CDN) global que reduz a latência ao armazenar o conteúdo em cache em servidores de borda próximos aos usuários finais.  
  - **Conexão com buckets S3:** O CloudFront pode ser configurado para usar buckets S3 como origem, garantindo que os arquivos sejam entregues de forma eficiente e segura para usuários ao redor do mundo.  
  - **Confidencialidade e desempenho:** O CloudFront oferece suporte à criptografia e controle de acesso, garantindo a confidencialidade dos arquivos enquanto melhora o desempenho.  

**Por que as outras opções não são adequadas?**  
- **A. Usar AWS DataSync:**  
  - O DataSync é usado para transferências eficientes de dados entre sistemas de armazenamento, mas não é adequado para entrega global de conteúdo em tempo real.  
- **B. Implantar AWS Global Accelerator:**  
  - O Global Accelerator melhora a latência para aplicativos globais, mas não fornece funcionalidade de cache. Ele não é projetado para armazenar em cache e entregar conteúdo de mídia.  
- **D. Usar Amazon SQS:**  
  - O SQS é uma fila de mensagens projetada para comunicação assíncrona entre componentes de aplicativos. Ele não oferece armazenamento em cache ou entrega de conteúdo.  

</details>

---

### Questão 156
Uma empresa produz dados em lote provenientes de diferentes bancos de dados. A empresa também produz dados de streaming ao vivo de sensores de rede e APIs de aplicativos. A empresa precisa consolidar todos os dados em um único local para análises de negócios. Os dados recebidos precisam ser processados e armazenados em buckets diferentes no Amazon S3. As equipes posteriormente executarão consultas únicas e importarão os dados para uma ferramenta de inteligência de negócios para exibir indicadores-chave de desempenho (KPIs).  
Quais combinações de etapas atenderão a esses requisitos com a MENOR sobrecarga operacional? (Escolha duas.)

**Alternativas:**
A. Usar o Amazon Athena para consultas únicas. Usar o Amazon QuickSight para criar painéis de KPIs.  

B. Usar o Amazon Kinesis Data Analytics para consultas únicas. Usar o Amazon QuickSight para criar painéis de KPIs.  

C. Criar funções personalizadas do AWS Lambda para mover os registros individuais dos bancos de dados para um cluster Amazon Redshift.  

D. Usar um trabalho de ETL do AWS Glue para converter os dados em formato JSON. Carregar os dados em vários clusters do Amazon OpenSearch Service (Amazon Elasticsearch Service).  

E. Usar blueprints no AWS Lake Formation para identificar os dados que podem ser ingeridos em um data lake. Usar o AWS Glue para rastrear a fonte, extrair os dados e carregá-los no Amazon S3 no formato Apache Parquet.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>A,E</resposta>

A. Usar o Amazon Athena para consultas únicas. Usar o Amazon QuickSight para criar painéis de KPIs.  
E. Usar blueprints no AWS Lake Formation para identificar os dados que podem ser ingeridos em um data lake. Usar o AWS Glue para rastrear a fonte, extrair os dados e carregá-los no Amazon S3 no formato Apache Parquet.  

**Justificativa:**  
- **Por que essas opções?**  
  - **A. Amazon Athena e Amazon QuickSight:**  
    - O Amazon Athena é uma solução serverless para executar consultas SQL em dados armazenados no S3. Ele é ideal para consultas únicas com baixa sobrecarga operacional.  
    - O Amazon QuickSight permite criar visualizações e painéis interativos para KPIs de forma direta e eficiente.  
  - **E. AWS Lake Formation e AWS Glue:**  
    - O AWS Lake Formation facilita a criação de um data lake, consolidando dados de várias fontes no S3.  
    - O AWS Glue automatiza o processo de rastreamento (crawling), extração e carregamento de dados, transformando-os em formatos otimizados como Apache Parquet, que é mais eficiente para análises.  
    - Essa combinação permite consolidar e organizar dados com baixa sobrecarga operacional.  

**Por que as outras opções não são adequadas?**  
- **B. Kinesis Data Analytics e QuickSight:**  
  - O Kinesis Data Analytics é mais adequado para análise de dados de streaming em tempo real, mas não para consultas únicas em dados consolidados. Isso aumenta a complexidade desnecessariamente.  
- **C. Funções personalizadas do AWS Lambda para Redshift:**  
  - Criar funções Lambda personalizadas para mover dados para o Amazon Redshift aumenta a sobrecarga operacional e é desnecessário quando os dados podem ser processados diretamente no S3 e consultados com o Athena.  
- **D. AWS Glue para OpenSearch:**  
  - O Amazon OpenSearch é mais adequado para buscas e análises em tempo real, mas não é ideal para consultas únicas em dados consolidados. Usar vários clusters aumenta a complexidade e os custos.  

</details>

---

### Questão 157
Uma empresa armazena dados em um cluster Amazon Aurora PostgreSQL. A empresa deve armazenar todos os dados por 5 anos e excluir todos os dados após esse período. Além disso, a empresa deve manter indefinidamente os logs de auditoria das ações realizadas no banco de dados. Atualmente, a empresa tem backups automatizados configurados para o Aurora.  
Quais combinações de etapas um arquiteto de soluções deve realizar para atender a esses requisitos? (Escolha duas.)

**Alternativas:**
A. Fazer um snapshot manual do cluster do banco de dados.  

B. Criar uma política de ciclo de vida para os backups automatizados.  

C. Configurar a retenção de backups automatizados por 5 anos.  

D. Configurar uma exportação de logs para o Amazon CloudWatch Logs no cluster do banco de dados.  

E. Usar o AWS Backup para realizar os backups e mantê-los por 5 anos.  

<details>
<summary>Resposta</summary>

**Respostas corretas:** 
<resposta>D,E</resposta>

D. Configurar uma exportação de logs para o Amazon CloudWatch Logs no cluster do banco de dados.  
E. Usar o AWS Backup para realizar os backups e mantê-los por 5 anos.

**Justificativa:**  
- **Por que essas opções?**  
  - **D. Exportação de logs para o CloudWatch Logs:**  
    - O Amazon CloudWatch Logs pode ser configurado para armazenar logs de auditoria indefinidamente. Isso atende ao requisito de manter os logs de ações realizadas no banco de dados.  
  - **E. AWS Backup:**  
    - O AWS Backup é uma solução gerenciada que permite configurar políticas de retenção específicas, como manter backups por 5 anos e deletá-los automaticamente após esse período. Isso elimina a necessidade de gerenciar backups manualmente.  
    - Essa abordagem é escalável e reduz a sobrecarga operacional.  

**Por que as outras opções não são adequadas?**  
- **A. Fazer um snapshot manual do cluster do banco de dados:**  
  - Snapshots manuais precisam ser gerenciados manualmente, o que aumenta a sobrecarga operacional. Eles não são ideais para atender ao requisito de retenção automatizada de 5 anos.  
- **B. Criar uma política de ciclo de vida para os backups automatizados:**  
  - O Aurora não suporta políticas de ciclo de vida diretamente para backups automatizados. Essas políticas são aplicáveis a objetos no S3, não a backups do banco de dados.  
- **C. Configurar a retenção de backups automatizados por 5 anos:**  
  - O período máximo de retenção de backups automatizados no Aurora é de 35 dias. Isso não atende ao requisito de retenção de 5 anos.  

</details>

---

### Questão 158
Um arquiteto de soluções está otimizando um site para um próximo evento musical. Vídeos das apresentações serão transmitidos em tempo real e, posteriormente, estarão disponíveis sob demanda. O evento deve atrair um público global online.  
Qual serviço melhorará o desempenho tanto do streaming em tempo real quanto do streaming sob demanda?

**Alternativas:**
A. Amazon CloudFront  

B. AWS Global Accelerator  

C. Amazon Route 53  

D. Amazon S3 Transfer Acceleration  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Amazon CloudFront

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon CloudFront:** É uma rede de entrega de conteúdo (CDN) projetada para acelerar a distribuição de conteúdo estático e dinâmico para usuários globais. Ele oferece servidores de borda distribuídos geograficamente, reduzindo a latência e garantindo um streaming eficiente, tanto em tempo real quanto sob demanda.  
  - **Transmissão global:** O CloudFront suporta baixa latência para streaming de vídeo em tempo real e pode armazenar em cache conteúdo sob demanda, melhorando o desempenho geral.  
  - **Escalabilidade:** Ideal para eventos com alta demanda global, o CloudFront pode lidar com picos de tráfego sem impacto no desempenho.  

**Por que as outras opções não são adequadas?**  
- **B. AWS Global Accelerator:**  
  - O Global Accelerator é usado para otimizar a latência de aplicativos globais, mas não fornece funcionalidades específicas para streaming de vídeo ou armazenamento em cache de conteúdo sob demanda.  
- **C. Amazon Route 53:**  
  - O Route 53 é um serviço de DNS que resolve nomes de domínio para endereços IP. Ele não melhora diretamente o desempenho do streaming em tempo real ou sob demanda.  
- **D. Amazon S3 Transfer Acceleration:**  
  - O S3 Transfer Acceleration é projetado para uploads rápidos para buckets do S3, mas não otimiza o desempenho de streaming de vídeo.  

</details>

---

### Questão 159
Uma empresa está executando uma aplicação serverless acessível publicamente que usa o Amazon API Gateway e o AWS Lambda. O tráfego da aplicação recentemente aumentou devido a solicitações fraudulentas de botnets.  
Quais etapas um arquiteto de soluções deve realizar para bloquear solicitações de usuários não autorizados? (Escolha duas.)

**Alternativas:**
A. Criar um plano de uso com uma chave de API que será compartilhada apenas com usuários genuínos.  

B. Integrar lógica dentro da função Lambda para ignorar as solicitações de endereços IP fraudulentos.  

C. Implementar uma regra do AWS WAF para direcionar solicitações maliciosas e acionar ações para filtrá-las.  

D. Converter a API pública existente em uma API privada. Atualizar os registros DNS para redirecionar os usuários para o novo endpoint da API.  

E. Criar uma função IAM para cada usuário que tenta acessar a API. O usuário assumirá a função ao fazer a chamada para a API.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**
<resposta>A,C</resposta>

A. Criar um plano de uso com uma chave de API que será compartilhada apenas com usuários genuínos.  
C. Implementar uma regra do AWS WAF para direcionar solicitações maliciosas e acionar ações para filtrá-las.

**Justificativa:**  
- **A. Plano de uso com chave de API:**  
  - Um plano de uso permite limitar o acesso à API a usuários genuínos. A chave de API adiciona uma camada de autenticação, dificultando que bots ou usuários não autorizados acessem a API.  
  - Isso ajuda a proteger a API contra solicitações fraudulentas.  
- **C. AWS WAF:**  
  - O AWS WAF permite criar regras específicas para bloquear tráfego malicioso, como solicitações de botnets.  
  - Ele pode filtrar com base em padrões de tráfego, endereços IP, cabeçalhos HTTP e muito mais, fornecendo uma solução eficaz para evitar acessos não autorizados.  

**Por que as outras opções não são adequadas?**  
- **B. Integrar lógica na função Lambda:**  
  - Embora seja possível implementar lógica para ignorar solicitações fraudulentas, isso aumenta a carga da função Lambda, reduzindo a eficiência e aumentando custos. Essa não é a melhor prática para lidar com tráfego malicioso.  
- **D. Converter a API pública em uma API privada:**  
  - Uma API privada não é acessível publicamente, o que restringiria os usuários legítimos que acessam a aplicação. Isso não atende ao requisito de manter a API acessível publicamente.  
- **E. Criar funções IAM por usuário:**  
  - Criar funções IAM para cada usuário é impraticável e não é escalável, especialmente em um cenário de API pública acessada por muitos usuários.  

</details>

---

### Questão 160
Uma empresa de comércio eletrônico hospeda sua aplicação de análise na nuvem da AWS. A aplicação gera cerca de 300 MB de dados por mês. Os dados são armazenados no formato JSON. A empresa está avaliando uma solução de recuperação de desastres para fazer backup dos dados. Os dados devem estar acessíveis em milissegundos, caso necessário, e devem ser mantidos por 30 dias.  
Qual solução atende a esses requisitos de forma MAIS econômica?

**Alternativas:**
A. Amazon OpenSearch Service (Amazon Elasticsearch Service) 

B. Amazon S3 Glacier  

C. Amazon S3 Standard  

D. Amazon RDS for PostgreSQL  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Amazon S3 Standard

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon S3 Standard:**  
    - É projetado para armazenamento de dados acessados com frequência e oferece latência de acesso em milissegundos, atendendo ao requisito de recuperação rápida dos dados.  
    - É econômico para volumes de dados relativamente pequenos (como 300 MB por mês) e oferece alta durabilidade e disponibilidade, adequados para recuperação de desastres em curto prazo.  
  - **Manutenção por 30 dias:** O S3 Standard permite configurar políticas de ciclo de vida para excluir automaticamente os dados após 30 dias, ajudando a gerenciar custos.  

**Por que as outras opções não são adequadas?**  
- **A. Amazon OpenSearch Service (Amazon Elasticsearch Service):**  
  - O OpenSearch é projetado para pesquisa e análise de dados, não para armazenamento de backup. Ele é mais caro e não otimizado para retenção simples de dados em JSON.  
- **B. Amazon S3 Glacier:**  
  - O S3 Glacier é mais econômico para dados raramente acessados, mas não atende ao requisito de latência de acesso em milissegundos, já que a recuperação de dados pode levar minutos ou horas.  
- **D. Amazon RDS for PostgreSQL:**  
  - O RDS é mais caro para armazenar 300 MB de dados em comparação ao S3. Ele também exige o gerenciamento de um banco de dados relacional, o que adiciona complexidade desnecessária para este caso de uso.  

</details>

---


### Questão 161
Uma empresa possui uma pequena aplicação Python que processa documentos JSON e envia os resultados para um banco de dados SQL on-premises. A aplicação é executada milhares de vezes por dia. A empresa deseja migrar a aplicação para a AWS Cloud. A solução precisa ser altamente disponível, maximizar a escalabilidade e minimizar a sobrecarga operacional.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Colocar os documentos JSON em um bucket Amazon S3. Executar o código Python em várias instâncias Amazon EC2 para processar os documentos. Armazenar os resultados em um cluster Amazon Aurora DB.  

B. Colocar os documentos JSON em um bucket Amazon S3. Criar uma função AWS Lambda que execute o código Python para processar os documentos à medida que eles chegam no bucket S3. Armazenar os resultados em um cluster Amazon Aurora DB.  

C. Colocar os documentos JSON em um volume Amazon Elastic Block Store (Amazon EBS). Usar o recurso EBS Multi-Attach para anexar o volume a várias instâncias Amazon EC2. Executar o código Python nas instâncias EC2 para processar os documentos. Armazenar os resultados em uma instância Amazon RDS DB.  

D. Colocar os documentos JSON em uma fila do Amazon Simple Queue Service (Amazon SQS) como mensagens. Implantar o código Python como um contêiner em um cluster Amazon Elastic Container Service (Amazon ECS) configurado com o tipo de inicialização Amazon EC2. Usar o contêiner para processar as mensagens do SQS. Armazenar os resultados em uma instância Amazon RDS DB.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Colocar os documentos JSON em um bucket Amazon S3. Criar uma função AWS Lambda que execute o código Python para processar os documentos à medida que eles chegam no bucket S3. Armazenar os resultados em um cluster Amazon Aurora DB.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon S3:** É um serviço de armazenamento altamente disponível e escalável que pode armazenar os documentos JSON de maneira confiável.  
  - **AWS Lambda:** Oferece execução serverless para o código Python, eliminando a necessidade de gerenciar servidores ou infraestrutura, o que minimiza a sobrecarga operacional. Ele também escala automaticamente para processar os documentos à medida que chegam no S3.  
  - **Amazon Aurora DB:** Aurora é um banco de dados altamente disponível e gerenciado, ideal para substituir a solução SQL on-premises, proporcionando escalabilidade e durabilidade.  

**Por que as outras opções não são adequadas?**  
- **A. Várias instâncias EC2 para processar documentos JSON:**  
  - Usar EC2 requer o gerenciamento de servidores, o que aumenta a sobrecarga operacional. Além disso, não escala automaticamente com a carga de trabalho.  
- **C. Volume EBS Multi-Attach com EC2:**  
  - O Multi-Attach do EBS não é ideal para compartilhar documentos entre várias instâncias para processamento independente. Além disso, o gerenciamento de EC2 aumenta a complexidade.  
- **D. Fila SQS com ECS:**  
  - Embora o SQS e o ECS possam ser usados para cenários similares, a solução adiciona mais complexidade operacional em comparação ao Lambda e S3. O ECS exige o gerenciamento do cluster e pode não ser tão simples quanto o serverless.  

</details>

---

### Questão 162
Uma empresa deseja usar infraestrutura de computação de alto desempenho (HPC) na AWS para modelagem de risco financeiro. As cargas de trabalho de HPC da empresa rodam no Linux, cada workflow utiliza centenas de instâncias Amazon EC2 Spot, são de curta duração e geram milhares de arquivos de saída que, no final, são armazenados em armazenamento persistente para análises e uso futuro a longo prazo.  
A empresa procura uma solução de armazenamento em nuvem que permita copiar dados on-premises para armazenamento persistente de longo prazo, tornando os dados disponíveis para processamento por todas as instâncias EC2. A solução também deve ser um sistema de arquivos de alto desempenho integrado com o armazenamento persistente para ler e gravar datasets e arquivos de saída.  
Qual combinação de serviços da AWS atende a esses requisitos?

**Alternativas:**
A. Amazon FSx for Lustre integrado com Amazon S3  

B. Amazon FSx for Windows File Server integrado com Amazon S3  

C. Amazon S3 Glacier integrado com Amazon Elastic Block Store (Amazon EBS)  

D. Bucket Amazon S3 com um endpoint VPC integrado com um volume Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2)  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Amazon FSx for Lustre integrado com Amazon S3

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon FSx for Lustre:** É um sistema de arquivos de alto desempenho projetado para cargas de trabalho intensivas como HPC. Ele permite que instâncias EC2 leiam e gravem datasets com baixa latência e alto throughput.  
  - **Integração com Amazon S3:** O FSx for Lustre permite importar e exportar dados de/para buckets S3, oferecendo armazenamento persistente para dados de longo prazo e facilitando o acesso para todas as instâncias EC2.  
  - **Cenário ideal:** Essa combinação atende às necessidades de alto desempenho durante o processamento de dados e armazenamento persistente para análises futuras.  

**Por que as outras opções não são adequadas?**  
- **B. Amazon FSx for Windows File Server integrado com Amazon S3:**  
  - O FSx for Windows File Server é projetado para cargas de trabalho baseadas em Windows e não é ideal para HPC no Linux. Além disso, não oferece o mesmo desempenho do FSx for Lustre.  
- **C. Amazon S3 Glacier integrado com Amazon EBS:**  
  - O S3 Glacier é projetado para armazenamento de arquivos de longo prazo que raramente são acessados. Ele não atende aos requisitos de alto desempenho durante a leitura e gravação de dados para workflows HPC.  
- **D. Bucket S3 com endpoint VPC integrado com EBS gp2:**  
  - Embora o S3 seja adequado para armazenamento persistente, o EBS não é um sistema de arquivos compartilhado para HPC e não oferece suporte para uso simultâneo por várias instâncias EC2.  

</details>

---

### Questão 163
Uma empresa está desenvolvendo uma aplicação conteinerizada on-premises e decide migrar a aplicação para a AWS. A aplicação terá milhares de usuários logo após ser implantada. A empresa não sabe como gerenciar a implantação de contêineres em grande escala. A aplicação precisa ser implantada em uma arquitetura altamente disponível que minimize a sobrecarga operacional.  
Qual solução atenderá a esses requisitos?

**Alternativas:**
A. Armazenar imagens de contêiner em um repositório Amazon Elastic Container Registry (Amazon ECR). Usar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de inicialização AWS Fargate para executar os contêineres. Usar rastreamento de destino para escalar automaticamente com base na demanda.

B. Armazenar imagens de contêiner em um repositório Amazon Elastic Container Registry (Amazon ECR). Usar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de inicialização Amazon EC2 para executar os contêineres. Usar rastreamento de destino para escalar automaticamente com base na demanda.  

C. Armazenar imagens de contêiner em um repositório executado em uma instância Amazon EC2. Executar os contêineres em instâncias EC2 espalhadas por várias Zonas de Disponibilidade. Monitorar a utilização média de CPU no Amazon CloudWatch. Lançar novas instâncias EC2 conforme necessário.  

D. Criar uma Amazon Machine Image (AMI) que contém a imagem do contêiner. Lançar instâncias EC2 em um grupo de Auto Scaling espalhado por várias Zonas de Disponibilidade. Usar um alarme do Amazon CloudWatch para escalar as instâncias EC2 quando o limite médio de utilização da CPU for ultrapassado.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

A. Armazenar imagens de contêiner em um repositório Amazon Elastic Container Registry (Amazon ECR). Usar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de inicialização AWS Fargate para executar os contêineres. Usar rastreamento de destino para escalar automaticamente com base na demanda.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon ECR:** Fornece um repositório gerenciado para armazenar imagens de contêiner, simplificando a entrega contínua de aplicações.  
  - **Amazon ECS com AWS Fargate:** Oferece um ambiente totalmente gerenciado para execução de contêineres sem necessidade de gerenciar infraestrutura subjacente, minimizando a sobrecarga operacional.  
  - **Escalabilidade automática com rastreamento de destino:** Permite escalar os contêineres automaticamente com base em métricas, como uso de CPU ou solicitações, garantindo alta disponibilidade.  
  - **Baixa sobrecarga operacional:** Fargate elimina a necessidade de gerenciar nós EC2, reduzindo a complexidade de gerenciamento.  

**Por que as outras opções não são adequadas?**  
- **B. Amazon ECS com tipo de inicialização Amazon EC2:**  
  - Embora funcione, usar instâncias EC2 para hospedar contêineres exige o gerenciamento de infraestrutura subjacente, como escalabilidade e patches, aumentando a sobrecarga operacional.  
- **C. Repositório em EC2 e execução de contêineres em EC2:**  
  - Gerenciar o repositório e os contêineres em instâncias EC2 exige maior esforço operacional, especialmente em cenários de alta escala e alta disponibilidade.  
- **D. AMI com contêiner em Auto Scaling:**  
  - Implantar contêineres diretamente como AMIs elimina os benefícios de orquestração de contêineres e aumenta a complexidade de gerenciamento, não sendo a solução ideal para aplicações conteinerizadas.  

</details>

---

### Questão 164
Uma empresa possui duas aplicações: uma aplicação de envio que envia mensagens com payloads a serem processadas e uma aplicação de processamento destinada a receber essas mensagens. A empresa quer implementar um serviço da AWS para lidar com mensagens entre as duas aplicações. A aplicação de envio pode enviar cerca de 1.000 mensagens por hora. As mensagens podem levar até 2 dias para serem processadas. Caso as mensagens falhem no processamento, elas devem ser retidas para não impactar o processamento de mensagens restantes.  
Qual solução atende a esses requisitos e é a MAIS eficiente operacionalmente?

**Alternativas:**
A. Configurar uma instância Amazon EC2 executando um banco de dados Redis. Configurar ambas as aplicações para usar a instância. Armazenar, processar e excluir as mensagens, respectivamente.  

B. Usar um fluxo de dados do Amazon Kinesis para receber as mensagens da aplicação de envio. Integrar a aplicação de processamento com a Kinesis Client Library (KCL).  

C. Integrar as aplicações de envio e processamento com uma fila do Amazon Simple Queue Service (Amazon SQS). Configurar uma fila de dead-letter para coletar mensagens que falharam no processamento.  

D. Inscrever a aplicação de processamento em um tópico do Amazon Simple Notification Service (Amazon SNS) para receber notificações para processamento. Integrar a aplicação de envio para escrever no tópico SNS.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Integrar as aplicações de envio e processamento com uma fila do Amazon Simple Queue Service (Amazon SQS). Configurar uma fila de dead-letter para coletar mensagens que falharam no processamento.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon SQS:** É uma solução gerenciada e altamente escalável para filas de mensagens. Suporta retenção de mensagens por até 14 dias, atendendo ao requisito de mensagens que podem levar até 2 dias para serem processadas.  
  - **Dead-letter queue (DLQ):** As DLQs coletam mensagens que falharam no processamento, evitando impactos no processamento de mensagens restantes e garantindo confiabilidade.  
  - **Eficiência operacional:** O SQS elimina a necessidade de gerenciar infraestrutura, sendo uma solução simples e eficiente.  

**Por que as outras opções não são adequadas?**  
- **A. Redis em instância EC2:**  
  - Embora o Redis possa armazenar mensagens, ele exige gerenciamento da instância EC2 e do banco de dados, aumentando a sobrecarga operacional. Além disso, não possui suporte nativo para DLQs.  
- **B. Kinesis data stream:**  
  - O Kinesis é projetado para processamento em tempo real, mas sua complexidade e custos adicionais tornam-no menos adequado para cargas de trabalho de mensagens que não exigem baixa latência. Ele também não possui suporte nativo para DLQs.  
- **D. Amazon SNS:**  
  - O SNS é uma solução de publicação/assinatura e não possui suporte para retenção de mensagens. Mensagens perdidas não seriam armazenadas, o que não atende ao requisito de reprocessamento em caso de falhas.  

</details>

---

### Questão 165
Um arquiteto de soluções deve projetar uma solução que utilize o Amazon CloudFront com um bucket Amazon S3 como origem para hospedar um site estático. A política de segurança da empresa exige que todo o tráfego do site seja inspecionado pelo AWS WAF.  
Como o arquiteto de soluções deve atender a esses requisitos?

**Alternativas:**
A. Configurar uma política de bucket S3 para aceitar solicitações vindas apenas do Amazon Resource Name (ARN) do AWS WAF.  

B. Configurar o Amazon CloudFront para encaminhar todas as solicitações recebidas para o AWS WAF antes de solicitar o conteúdo da origem S3. 

C. Configurar um grupo de segurança que permita apenas endereços IP do Amazon CloudFront acessarem o Amazon S3. Associar o AWS WAF ao CloudFront.  

D. Configurar o Amazon CloudFront e o Amazon S3 para usar uma identidade de acesso de origem (OAI) para restringir o acesso ao bucket S3. Habilitar o AWS WAF na distribuição do CloudFront.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Configurar o Amazon CloudFront e o Amazon S3 para usar uma identidade de acesso de origem (OAI) para restringir o acesso ao bucket S3. Habilitar o AWS WAF na distribuição do CloudFront.

**Justificativa:**  
- **Por que essa opção?**  
  - **Origin Access Identity (OAI):** Restringe o acesso ao bucket S3 para que apenas o CloudFront possa solicitar conteúdo, protegendo o bucket contra acessos diretos.  
  - **AWS WAF no CloudFront:** O AWS WAF pode ser integrado ao CloudFront para inspecionar todas as solicitações recebidas antes que o conteúdo seja servido. Isso garante que todo o tráfego passe pelas regras de segurança do WAF.  
  - **Conformidade:** Essa solução atende ao requisito de inspeção de todo o tráfego pelo WAF e protege a origem S3 contra acessos não autorizados.  

**Por que as outras opções não são adequadas?**  
- **A. Política de bucket S3 com ARN do AWS WAF:**  
  - O AWS WAF não interage diretamente com o bucket S3. Ele é integrado ao CloudFront ou a outros serviços compatíveis, tornando essa configuração inválida.  
- **B. CloudFront encaminhando solicitações para o AWS WAF:**  
  - O CloudFront não "encaminha" solicitações para o AWS WAF. Em vez disso, o WAF é integrado diretamente ao CloudFront para inspeção de tráfego.  
- **C. Grupo de segurança para IPs do CloudFront:**  
  - Grupos de segurança não podem ser aplicados diretamente ao S3. Além disso, apenas restringir IPs do CloudFront não garante que todo o tráfego passe pelo WAF.  

</details>

---

### Questão 166
Os organizadores de um evento global querem disponibilizar relatórios diários online como páginas HTML estáticas. Espera-se que as páginas gerem milhões de visualizações de usuários ao redor do mundo. Os arquivos estão armazenados em um bucket Amazon S3. Um arquiteto de soluções foi solicitado a projetar uma solução eficiente e eficaz.  
Qual ação o arquiteto de soluções deve realizar para alcançar isso?

**Alternativas:**
A. Gerar URLs assinadas para os arquivos.  

B. Usar replicação entre regiões para todas as regiões.  

C. Usar o recurso de geoproximidade do Amazon Route 53.  

D. Usar o Amazon CloudFront com o bucket S3 como origem.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Usar o Amazon CloudFront com o bucket S3 como origem.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon CloudFront:** É uma rede de entrega de conteúdo (CDN) global que armazena em cache o conteúdo em servidores de borda ao redor do mundo. Isso reduz a latência e melhora o desempenho para os usuários, independentemente de sua localização.  
  - **Integração com Amazon S3:** O CloudFront pode ser configurado para usar o bucket S3 como origem, garantindo que os relatórios sejam entregues de forma rápida e eficiente, mesmo sob alta demanda.  
  - **Escalabilidade:** O CloudFront é projetado para lidar com milhões de visualizações, oferecendo alta disponibilidade e resiliência para o conteúdo estático.  

**Por que as outras opções não são adequadas?**  
- **A. Gerar URLs assinadas para os arquivos:**  
  - URLs assinadas são usadas para controle de acesso, não para melhorar o desempenho ou eficiência de entrega de conteúdo estático.  
- **B. Usar replicação entre regiões para todas as regiões:**  
  - A replicação entre regiões do S3 permite armazenar cópias dos dados em diferentes regiões, mas não oferece otimização de entrega ou cache global. Além disso, aumenta custos e complexidade desnecessariamente.  
- **C. Usar o recurso de geoproximidade do Amazon Route 53:**  
  - O Route 53 é um serviço de DNS que pode direcionar usuários para endpoints específicos com base em geografia, mas não fornece cache nem melhora o desempenho de entrega como o CloudFront.  

</details>

---

### Questão 167
Uma empresa executa uma aplicação de produção em uma frota de instâncias Amazon EC2. A aplicação lê dados de uma fila Amazon SQS e processa as mensagens em paralelo. O volume de mensagens é imprevisível e frequentemente apresenta tráfego intermitente. Esta aplicação deve processar continuamente as mensagens sem qualquer tempo de inatividade.  
Qual solução atende a esses requisitos de forma MAIS econômica?

**Alternativas:**
A. Usar exclusivamente Spot Instances para lidar com a capacidade máxima necessária.  

B. Usar exclusivamente Reserved Instances para lidar com a capacidade máxima necessária.  

C. Usar Reserved Instances para a capacidade base e Spot Instances para lidar com a capacidade adicional.  

D. Usar Reserved Instances para a capacidade base e On-Demand Instances para lidar com a capacidade adicional.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Usar Reserved Instances para a capacidade base e Spot Instances para lidar com a capacidade adicional.

**Justificativa:**  
- **Por que essa opção?**  
  - **Reserved Instances para capacidade base:** As Reserved Instances oferecem economia significativa em comparação às On-Demand Instances e são ideais para cargas de trabalho previsíveis e contínuas, como a capacidade base.  
  - **Spot Instances para capacidade adicional:** As Spot Instances são altamente econômicas e adequadas para lidar com aumentos intermitentes no volume de mensagens. A aplicação é tolerante a interrupções, já que pode reiniciar o processamento de mensagens da fila SQS.  
  - **Custo-benefício:** Essa combinação reduz custos enquanto mantém alta disponibilidade e escalabilidade para a aplicação.  

**Por que as outras opções não são adequadas?**  
- **A. Usar exclusivamente Spot Instances:**  
  - Embora econômicas, as Spot Instances podem ser interrompidas pela AWS sem aviso prévio, o que pode causar downtime caso a capacidade mínima base não seja garantida.  
- **B. Usar exclusivamente Reserved Instances:**  
  - Comprar capacidade máxima como Reserved Instances resulta em custos fixos elevados e não é econômico para lidar com volumes de tráfego imprevisíveis.  
- **D. Usar Reserved Instances e On-Demand Instances:**  
  - On-Demand Instances são mais caras do que Spot Instances. Usar On-Demand para capacidade adicional aumenta os custos sem necessidade.  

</details>

---

### Questão 168
Uma equipe de segurança deseja limitar o acesso a serviços ou ações específicos em todas as contas da equipe na AWS. Todas as contas pertencem a uma organização maior no AWS Organizations. A solução deve ser escalável e deve haver um único ponto onde as permissões possam ser gerenciadas.  
O que um arquiteto de soluções deve fazer para alcançar isso?

**Alternativas:**
A. Criar uma ACL para fornecer acesso aos serviços ou ações.  

B. Criar um grupo de segurança para permitir contas e anexá-lo a grupos de usuários.  

C. Criar funções de acesso entre contas (cross-account roles) em cada conta para negar acesso aos serviços ou ações. 

D. Criar uma política de controle de serviço (SCP) na unidade organizacional raiz para negar acesso aos serviços ou ações.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

D. Criar uma política de controle de serviço (SCP) na unidade organizacional raiz para negar acesso aos serviços ou ações.

**Justificativa:**  
- **Por que essa opção?**  
  - **Service Control Policies (SCPs):** As SCPs permitem definir permissões de serviço e ação em um único ponto central para todas as contas em uma organização do AWS Organizations.  
  - **Gerenciamento centralizado:** Criar a SCP na unidade organizacional raiz garante que todas as contas herdem as restrições, atendendo ao requisito de escalabilidade e gerenciamento centralizado.  
  - **Escalabilidade e controle:** As SCPs são aplicadas a todas as contas subordinadas automaticamente, eliminando a necessidade de configurar permissões individualmente em cada conta.  

**Por que as outras opções não são adequadas?**  
- **A. Criar uma ACL:**  
  - As ACLs são usadas para gerenciar controle de acesso em recursos individuais, como buckets S3, e não fornecem um mecanismo escalável ou centralizado para restringir serviços e ações em toda a organização.  
- **B. Criar um grupo de segurança:**  
  - Os grupos de segurança são usados para controlar tráfego de rede para instâncias EC2 e outros recursos, e não para gerenciar permissões de serviços e ações.  
- **C. Criar cross-account roles:**  
  - Criar funções em cada conta é complexo, difícil de manter e não fornece um ponto centralizado de controle. Isso não é escalável para grandes organizações.  

</details>

---

### Questão 169
Uma empresa está preocupada com a segurança de sua aplicação web pública devido a ataques recentes. A aplicação utiliza um Application Load Balancer (ALB). Um arquiteto de soluções deve reduzir o risco de ataques DDoS contra a aplicação.  
O que o arquiteto de soluções deve fazer para atender a esse requisito?

**Alternativas:**
A. Adicionar um agente do Amazon Inspector ao ALB.  

B. Configurar o Amazon Macie para prevenir ataques.  

C. Habilitar o AWS Shield Advanced para prevenir ataques.  

D. Configurar o Amazon GuardDuty para monitorar o ALB.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

C. Habilitar o AWS Shield Advanced para prevenir ataques.

**Justificativa:**  
- **Por que essa opção?**  
  - **AWS Shield Advanced:** É um serviço gerenciado projetado para proteger aplicativos contra ataques DDoS. Ele oferece proteção avançada para Application Load Balancers, CloudFront, e outros recursos da AWS, ajudando a mitigar ataques volumétricos e direcionados.  
  - **Cobertura adicional:** Inclui detecção de ataques em tempo real, mitigação automatizada e suporte 24/7, reduzindo significativamente os riscos de ataques DDoS.  
  - **Proteção direcionada:** Shield Advanced é a solução ideal para proteger o ALB contra ataques de negação de serviço distribuída (DDoS).  

**Por que as outras opções não são adequadas?**  
- **A. Adicionar um agente do Amazon Inspector:**  
  - O Amazon Inspector é usado para identificar vulnerabilidades de segurança em instâncias EC2 e containers. Ele não oferece proteção contra ataques DDoS.  
- **B. Configurar o Amazon Macie:**  
  - O Amazon Macie é usado para proteger dados confidenciais em buckets S3, não para prevenir ou mitigar ataques DDoS.  
- **D. Configurar o Amazon GuardDuty:**  
  - O Amazon GuardDuty fornece monitoramento de ameaças e detecção de atividades suspeitas, mas não é projetado para mitigar ataques DDoS.  

</details>

---

### Questão 171
Uma empresa fornece uma API aos seus usuários que automatiza consultas para cálculos de impostos com base nos preços dos itens. A empresa experimenta um grande número de consultas apenas durante a temporada de férias, o que causa tempos de resposta mais lentos. Um arquiteto de soluções precisa projetar uma solução que seja escalável e elástica.  
O que o arquiteto de soluções deve fazer para alcançar isso?

**Alternativas:**
A. Fornecer uma API hospedada em uma instância Amazon EC2. A instância EC2 realiza os cálculos necessários quando a solicitação da API é feita.  

B. Projetar uma API REST usando o Amazon API Gateway que aceita os nomes dos itens. O API Gateway passa os nomes dos itens para o AWS Lambda para cálculos de impostos.  

C. Criar um Application Load Balancer com duas instâncias Amazon EC2 atrás dele. As instâncias EC2 calcularão o imposto com base nos nomes dos itens recebidos.  

D. Projetar uma API REST usando o Amazon API Gateway que conecta a uma API hospedada em uma instância Amazon EC2. O API Gateway aceita e passa os nomes dos itens para a instância EC2 para cálculos de impostos.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta> </resposta>

B. Projetar uma API REST usando o Amazon API Gateway que aceita os nomes dos itens. O API Gateway passa os nomes dos itens para o AWS Lambda para cálculos de impostos.

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon API Gateway:** Fornece uma solução gerenciada e escalável para criar APIs REST. Ele pode lidar automaticamente com picos de tráfego, como durante a temporada de férias.  
  - **AWS Lambda:** O Lambda permite executar cálculos de impostos de forma serverless, escalando automaticamente para atender ao aumento de consultas. Essa abordagem reduz a sobrecarga operacional, pois não há necessidade de gerenciar servidores.  
  - **Escalabilidade e elasticidade:** A combinação do API Gateway com o Lambda é ideal para lidar com padrões de tráfego imprevisíveis e de alta variação.  

**Por que as outras opções não são adequadas?**  
- **A. API hospedada em uma instância EC2:**  
  - Uma única instância EC2 não pode escalar automaticamente para lidar com picos de tráfego, o que resulta em tempos de resposta lentos durante a temporada de férias.  
- **C. Application Load Balancer com duas instâncias EC2:**  
  - Embora o ALB permita escalabilidade horizontal, a abordagem com EC2 exige o gerenciamento manual das instâncias e sua escalabilidade. Isso aumenta a sobrecarga operacional e pode não ser tão eficiente quanto o Lambda.  
- **D. API Gateway conectando a uma instância EC2:**  
  - Embora o API Gateway forneça escalabilidade, usar uma única instância EC2 para cálculos não é elástico. A solução não escala automaticamente para lidar com picos de tráfego.  

</details>

---

### Questão 173
Uma empresa de jogos hospeda uma aplicação baseada em navegador na AWS. Os usuários da aplicação consomem um grande número de vídeos e imagens que estão armazenados no Amazon S3. Esse conteúdo é o mesmo para todos os usuários.  
A aplicação tornou-se popular, com milhões de usuários acessando esses arquivos de mídia globalmente. A empresa quer fornecer esses arquivos aos usuários enquanto reduz a carga na origem.  
Qual solução atende a esses requisitos de forma MAIS econômica?  

A. Implantar um acelerador do AWS Global Accelerator na frente dos servidores web.  

B. Implantar uma distribuição web do Amazon CloudFront na frente do bucket S3.  

C. Implantar uma instância do Amazon ElastiCache for Redis na frente dos servidores web.  

D. Implantar uma instância do Amazon ElastiCache for Memcached na frente dos servidores web.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Implantar uma distribuição web do Amazon CloudFront na frente do bucket S3.

**Justificativa:**  
- **Por que essa opção?** O Amazon CloudFront é um serviço de Content Delivery Network (CDN) que armazena em cache o conteúdo estático, como vídeos e imagens, em uma rede global de servidores distribuídos. Isso reduz significativamente a carga no bucket S3 (origem) e melhora o tempo de resposta para os usuários globalmente. Além disso, é uma solução altamente econômica para distribuição de mídia estática em escala global.  

**Por que as outras opções não são adequadas?**  
- **A:** O AWS Global Accelerator é projetado para melhorar a disponibilidade e a performance de aplicações baseadas em IP, mas não é uma solução de cache ou CDN. Ele não reduz diretamente a carga na origem nem oferece economia de custo para servir conteúdo estático.  
- **C:** O Amazon ElastiCache for Redis é uma solução de cache em memória altamente performática para dados dinâmicos e consultas frequentes, mas não é adequado para armazenamento e entrega de conteúdo estático como vídeos e imagens.  
- **D:** O Amazon ElastiCache for Memcached também é uma solução de cache em memória, mas, assim como o Redis, não é projetado para distribuir mídia estática para milhões de usuários globalmente.  

</details>

---

### Questão 174
Uma empresa possui uma aplicação de múltiplas camadas que executa seis servidores web front-end em um grupo de Auto Scaling do Amazon EC2 em uma única Zona de Disponibilidade (Availability Zone) por trás de um Application Load Balancer (ALB).  
Um arquiteto de soluções precisa modificar a infraestrutura para ser altamente disponível sem modificar a aplicação.  
Qual arquitetura o arquiteto de soluções deve escolher para fornecer alta disponibilidade?  

A. Criar um grupo de Auto Scaling que use três instâncias em cada uma de duas Regiões.  

B. Modificar o grupo de Auto Scaling para usar três instâncias em cada uma de duas Zonas de Disponibilidade.  

C. Criar um modelo de Auto Scaling que possa ser usado para criar rapidamente mais instâncias em outra Região.  

D. Alterar o ALB na frente das instâncias do Amazon EC2 para uma configuração de balanceamento de tráfego em round-robin para o nível web.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Modificar o grupo de Auto Scaling para usar três instâncias em cada uma de duas Zonas de Disponibilidade.

**Justificativa:**  
- **Por que essa opção?** Para garantir alta disponibilidade, é essencial distribuir as instâncias em várias Zonas de Disponibilidade dentro da mesma Região. Dessa forma, se uma Zona de Disponibilidade falhar, o tráfego pode ser redirecionado para as instâncias da outra Zona de Disponibilidade. Isso é possível sem modificar a aplicação, e o ALB pode distribuir o tráfego automaticamente entre as instâncias em diferentes Zonas de Disponibilidade.

**Por que as outras opções não são adequadas?**  
- **A:** Usar duas Regiões introduz complexidade desnecessária e não é necessário para alta disponibilidade. A distribuição em várias Zonas de Disponibilidade dentro de uma única Região já oferece resiliência suficiente.  
- **C:** Criar um modelo de Auto Scaling para instâncias em outra Região pode ser útil em cenários de recuperação de desastres, mas não resolve o problema de alta disponibilidade no momento, já que não há failover automático para outra Região sem alterações significativas na arquitetura.  
- **D:** Alterar o ALB para um balanceamento round-robin não adiciona alta disponibilidade, pois todas as instâncias ainda estão em uma única Zona de Disponibilidade. Se essa Zona falhar, todo o serviço será interrompido.  

</details>

---
### Questão 175
Uma empresa de comércio eletrônico possui uma aplicação de processamento de pedidos que utiliza Amazon API Gateway e uma função AWS Lambda. A aplicação armazena dados em um banco de dados Amazon Aurora PostgreSQL. Durante um recente evento de vendas, ocorreu um aumento repentino de pedidos de clientes. Alguns clientes enfrentaram timeouts, e a aplicação não processou os pedidos desses clientes.  
Um arquiteto de soluções determinou que a utilização de CPU e memória estava alta no banco de dados devido a um grande número de conexões abertas. O arquiteto de soluções precisa evitar os erros de timeout, fazendo o menor número possível de alterações na aplicação.  

Qual solução atenderá a esses requisitos?  

A. Configurar concorrência provisionada para a função Lambda. Modificar o banco de dados para ser um banco de dados global em várias Regiões AWS.  

B. Usar o Amazon RDS Proxy para criar um proxy para o banco de dados. Modificar a função Lambda para usar o endpoint do RDS Proxy em vez do endpoint do banco de dados.  

C. Criar uma réplica de leitura para o banco de dados em uma Região AWS diferente. Usar parâmetros de string de consulta no API Gateway para direcionar o tráfego para a réplica de leitura.  

D. Migrar os dados do Aurora PostgreSQL para o Amazon DynamoDB usando o AWS Database Migration Service (AWS DMS). Modificar a função Lambda para usar a tabela DynamoDB.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Usar o Amazon RDS Proxy para criar um proxy para o banco de dados. Modificar a função Lambda para usar o endpoint do RDS Proxy em vez do endpoint do banco de dados.

**Justificativa:**  
- **Por que essa opção?** O Amazon RDS Proxy gerencia conexões de banco de dados de forma eficiente, reduzindo a carga no banco de dados e otimizando o uso de recursos. Ele permite que as funções Lambda reutilizem conexões existentes, evitando a sobrecarga de conexões abertas e, consequentemente, os timeouts. Essa solução requer mudanças mínimas na aplicação, já que basta atualizar a função Lambda para usar o endpoint do RDS Proxy.  

**Por que as outras opções não são adequadas?**  
- **A:** Configurar concorrência provisionada para a função Lambda ajudaria a gerenciar o escalonamento das funções, mas não resolveria diretamente o problema de conexões excessivas ao banco de dados. Transformar o banco de dados em um banco global em várias Regiões é uma solução mais complexa do que o necessário e não é voltada para o problema apresentado.  
- **C:** Criar uma réplica de leitura em outra Região não resolve o problema, já que as réplicas de leitura são destinadas apenas a consultas e não processam transações de gravação como os pedidos dos clientes. Além disso, adicionar roteamento com base em parâmetros do API Gateway exige alterações mais significativas na lógica da aplicação.  
- **D:** Migrar para o Amazon DynamoDB requer mudanças substanciais na aplicação e no esquema de dados, o que vai contra o requisito de realizar o menor número possível de alterações na aplicação.  

</details>

---

### Questão 176
Uma aplicação executa em instâncias Amazon EC2 em sub-redes privadas. A aplicação precisa acessar uma tabela do Amazon DynamoDB.  
Qual é a maneira MAIS segura de acessar a tabela, garantindo que o tráfego não saia da rede da AWS?  

A. Usar um endpoint de VPC para o DynamoDB.  

B. Usar um gateway NAT em uma sub-rede pública.  

C. Usar uma instância NAT em uma sub-rede privada.  

D. Usar o gateway da internet conectado à VPC.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Usar um endpoint de VPC para o DynamoDB.

**Justificativa:**  
- **Por que essa opção?** Um endpoint de VPC para o DynamoDB permite que instâncias EC2 em sub-redes privadas acessem o DynamoDB diretamente por meio da rede da AWS, sem que o tráfego precise passar pela internet. Isso fornece a maneira mais segura de acesso, eliminando a necessidade de NAT ou internet gateway e mantendo todo o tráfego dentro da infraestrutura segura da AWS.  

**Por que as outras opções não são adequadas?**  
- **B:** Um NAT gateway permite que instâncias em sub-redes privadas acessem serviços fora da VPC, mas isso faz com que o tráfego passe pela internet pública antes de atingir o DynamoDB, o que não é ideal em termos de segurança.  
- **C:** Uma instância NAT funciona de forma semelhante a um gateway NAT, mas exige mais gerenciamento e apresenta os mesmos problemas de segurança, pois o tráfego sai da rede da AWS para acessar o DynamoDB.  
- **D:** Usar um internet gateway permite que as instâncias EC2 acessem diretamente a internet, o que não atende ao requisito de manter o tráfego dentro da rede da AWS. Isso também expõe o tráfego a riscos de segurança adicionais.  

</details>

---

### Questão 177
Uma empresa de entretenimento está usando o Amazon DynamoDB para armazenar metadados de mídia. A aplicação é intensiva em leitura e está enfrentando atrasos. A empresa não possui equipe para lidar com tarefas operacionais adicionais e precisa melhorar a eficiência de desempenho do DynamoDB sem reconfigurar a aplicação.  

O que um arquiteto de soluções deve recomendar para atender a esse requisito?  

A. Usar o Amazon ElastiCache for Redis.  

B. Usar o Amazon DynamoDB Accelerator (DAX).  

C. Replicar os dados usando tabelas globais do DynamoDB.  

D. Usar o Amazon ElastiCache for Memcached com Auto Discovery ativado.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B.** Usar o Amazon DynamoDB Accelerator (DAX).

**Justificativa:**  
- **Por que essa opção?** O DynamoDB Accelerator (DAX) é um cache de leitura em memória que melhora significativamente o desempenho de leituras intensivas do DynamoDB, reduzindo a latência de milissegundos para microssegundos. Ele pode ser implementado sem a necessidade de reconfigurar o banco de dados ou a lógica de escrita, exigindo apenas pequenas alterações no cliente da aplicação. É uma solução gerenciada e que minimiza a sobrecarga operacional.  

**Por que as outras opções não são adequadas?**  
- **A:** O Amazon ElastiCache for Redis é uma solução de cache de dados em memória altamente eficiente, mas exigiria mudanças mais significativas na aplicação para integrar o cache com DynamoDB, o que vai contra o requisito de evitar reconfigurações.  
- **C:** As tabelas globais do DynamoDB são usadas para replicar dados entre Regiões, melhorando a disponibilidade global e a latência para acessos de diferentes localizações. No entanto, isso não é necessário no caso apresentado, pois o problema é de desempenho de leitura, e as tabelas globais não oferecem os mesmos benefícios de desempenho que o DAX.  
- **D:** O Amazon ElastiCache for Memcached com Auto Discovery também exigiria mudanças na aplicação para integração e não é específico para melhorar o desempenho de leitura do DynamoDB, como o DAX é.  

</details>

---

### Questão 178
A infraestrutura de uma empresa consiste em instâncias Amazon EC2 e uma instância Amazon RDS DB em uma única Região da AWS. A empresa deseja fazer backup dos seus dados em uma Região separada.  

Qual solução atenderá a esses requisitos com o MENOR esforço operacional?  

A. Usar o AWS Backup para copiar backups do EC2 e RDS para a Região separada.  

B. Usar o Amazon Data Lifecycle Manager (Amazon DLM) para copiar backups do EC2 e RDS para a Região separada.  

C. Criar Amazon Machine Images (AMIs) das instâncias EC2. Copiar as AMIs para a Região separada. Criar uma réplica de leitura para a instância RDS DB na Região separada.  

D. Criar snapshots do Amazon Elastic Block Store (Amazon EBS). Copiar os snapshots do EBS para a Região separada. Criar snapshots do RDS. Exportar os snapshots do RDS para o Amazon S3. Configurar a replicação entre Regiões (CRR) do S3 para a Região separada.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Usar o AWS Backup para copiar backups do EC2 e RDS para a Região separada.

**Justificativa:**  
- **Por que essa opção?** O AWS Backup é uma solução gerenciada que simplifica a criação, o agendamento e a replicação de backups para várias Regiões. Ele reduz o esforço operacional, pois permite configurar políticas centralizadas para backups e cópias entre Regiões tanto para instâncias EC2 (EBS) quanto para RDS. Isso atende aos requisitos de maneira eficiente e com mínima sobrecarga operacional.  

**Por que as outras opções não são adequadas?**  
- **B:** O Amazon Data Lifecycle Manager (DLM) é projetado para gerenciar snapshots do Amazon EBS, mas não oferece suporte direto para backups do RDS, o que significa que não cobre todos os requisitos da questão.  
- **C:** Criar AMIs e copiá-las para outra Região exige mais etapas manuais, especialmente para a configuração da réplica de leitura do RDS, o que aumenta a sobrecarga operacional. Além disso, uma réplica de leitura é projetada para melhorar a disponibilidade e não é uma solução ideal para backups.  
- **D:** Esse processo envolve múltiplas etapas manuais e soluções adicionais (exportar snapshots do RDS para o S3 e configurar replicação entre Regiões), o que aumenta significativamente o esforço operacional, tornando-o mais complexo do que o necessário.  

</details>

---

### Questão 179
Um arquiteto de soluções precisa armazenar com segurança um nome de usuário e uma senha de banco de dados que uma aplicação utiliza para acessar uma instância do Amazon RDS. A aplicação que acessa o banco de dados é executada em uma instância Amazon EC2. O arquiteto deseja criar um parâmetro seguro no AWS Systems Manager Parameter Store.  
O que o arquiteto de soluções deve fazer para atender a esse requisito?  

A. Criar uma função IAM que tenha acesso de leitura ao parâmetro do Parameter Store. Permitir acesso de descriptografia a uma chave do AWS Key Management Service (AWS KMS) usada para criptografar o parâmetro. Atribuir esta função IAM à instância EC2.  

B. Criar uma política IAM que permita acesso de leitura ao parâmetro do Parameter Store. Permitir acesso de descriptografia a uma chave do AWS Key Management Service (AWS KMS) usada para criptografar o parâmetro. Atribuir esta política IAM à instância EC2.  

C. Criar uma relação de confiança IAM entre o parâmetro do Parameter Store e a instância EC2. Especificar o Amazon RDS como um principal na política de confiança.  

D. Criar uma relação de confiança IAM entre a instância do banco de dados e a instância EC2. Especificar o Systems Manager como um principal na política de confiança.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A.** Criar uma função IAM que tenha acesso de leitura ao parâmetro do Parameter Store. Permitir acesso de descriptografia a uma chave do AWS Key Management Service (AWS KMS) usada para criptografar o parâmetro. Atribuir esta função IAM à instância EC2.

**Justificativa:**  
- **Por que essa opção?** O AWS Systems Manager Parameter Store permite armazenar valores sensíveis, como nomes de usuário e senhas, com segurança, utilizando criptografia do AWS KMS. Para acessar um parâmetro seguro, a instância EC2 precisa de uma função IAM que tenha permissões específicas para ler o parâmetro no Parameter Store e também para descriptografá-lo usando a chave KMS associada. Isso é feito atribuindo a função IAM à instância EC2, garantindo acesso seguro e controlado.  

**Por que as outras opções não são adequadas?**  
- **B:** Criar apenas uma política IAM e atribuí-la diretamente à instância EC2 não é uma prática recomendada, pois as permissões devem ser atribuídas a uma função IAM, que pode ser associada à instância EC2 para controle mais granular.  
- **C:** Relações de confiança IAM são usadas para delegar permissões entre entidades, mas o Amazon RDS não está envolvido diretamente no processo de autenticação e não deve ser configurado como um principal para acessar o Parameter Store.  
- **D:** O Systems Manager não precisa de uma relação de confiança entre a instância do banco de dados e a instância EC2. A relação de confiança deve ser entre a instância EC2 e a função IAM que fornece as permissões de acesso.  

</details>

---

### Questão 180
Uma empresa está projetando uma plataforma de comunicações em nuvem acionada por APIs. A aplicação é hospedada em instâncias Amazon EC2 por trás de um Network Load Balancer (NLB). A empresa usa o Amazon API Gateway para fornecer acesso externo à aplicação por meio de APIs.  
A empresa deseja proteger a plataforma contra exploits da web, como injeção de SQL, e também deseja detectar e mitigar grandes e sofisticados ataques DDoS.  
Qual combinação de soluções oferece a MELHOR proteção? (Escolha duas.)  

A. Usar o AWS WAF para proteger o NLB.  

B. Usar o AWS Shield Advanced com o NLB.  

C. Usar o AWS WAF para proteger o Amazon API Gateway.  

D. Usar o Amazon GuardDuty com o AWS Shield Standard.  

E. Usar o AWS Shield Standard com o Amazon API Gateway.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>B,C</resposta>

**B.** Usar o AWS Shield Advanced com o NLB.
**C.** Usar o AWS WAF para proteger o Amazon API Gateway.

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O AWS Shield Advanced fornece proteção aprimorada contra ataques DDoS sofisticados e é recomendado para proteger o NLB, que é um ponto de entrada crítico para a aplicação. Ele também oferece suporte proativo e monitoramento para mitigar ataques direcionados.  
  - **C:** O AWS WAF (Web Application Firewall) é projetado para proteger contra vulnerabilidades de aplicação, como injeções de SQL e ataques XSS. Integrar o WAF ao Amazon API Gateway é a abordagem mais eficaz para proteger as APIs contra exploits da web.  

**Por que as outras opções não são adequadas?**  
- **A:** Proteger o NLB com o AWS WAF não é ideal, pois o WAF é mais eficaz em pontos de entrada voltados para a aplicação, como o Amazon API Gateway ou um Application Load Balancer (ALB). O NLB opera no nível de transporte e não suporta integração direta com o AWS WAF.  
- **D:** O Amazon GuardDuty fornece detecção de ameaças baseada em inteligência e logs, mas não oferece mitigação direta contra ataques DDoS ou exploits da web. Ele é mais uma solução complementar.  
- **E:** O AWS Shield Standard fornece proteção básica contra ataques DDoS, mas para mitigar ataques sofisticados, o Shield Advanced é necessário. Além disso, o Shield Standard não protege contra exploits da web, como injeções de SQL.  
</details>

---

### Questão 181
Uma empresa possui um aplicativo legado de processamento de dados que é executado em instâncias do Amazon EC2. Os dados são processados sequencialmente, mas a ordem dos resultados não importa. O aplicativo usa uma arquitetura monolítica. A única forma que a empresa tem de escalar o aplicativo para atender à maior demanda é aumentar o tamanho das instâncias.  
Os desenvolvedores da empresa decidiram reescrever o aplicativo para usar uma arquitetura de microsserviços no Amazon Elastic Container Service (Amazon ECS).  
O que um arquiteto de soluções deve recomendar para a comunicação entre os microsserviços?  

A. Criar uma fila do Amazon Simple Queue Service (Amazon SQS). Adicionar código aos produtores de dados para enviar dados para a fila. Adicionar código aos consumidores de dados para processar os dados da fila.  

B. Criar um tópico do Amazon Simple Notification Service (Amazon SNS). Adicionar código aos produtores de dados para publicar notificações no tópico. Adicionar código aos consumidores de dados para assinar o tópico.  

C. Criar uma função AWS Lambda para passar mensagens. Adicionar código aos produtores de dados para chamar a função Lambda com um objeto de dados. Adicionar código aos consumidores de dados para receber o objeto de dados passado pela função Lambda.  

D. Criar uma tabela no Amazon DynamoDB. Habilitar DynamoDB Streams. Adicionar código aos produtores de dados para inserir dados na tabela. Adicionar código aos consumidores de dados para usar a API do DynamoDB Streams para detectar novas entradas na tabela e recuperar os dados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Criar uma fila do Amazon Simple Queue Service (Amazon SQS). Adicionar código aos produtores de dados para enviar dados para a fila. Adicionar código aos consumidores de dados para processar os dados da fila.  

**Justificativa:**  
- **Por que essa opção?**  
  O Amazon SQS é ideal para cenários em que os dados são processados de forma assíncrona e a ordem de processamento não é importante. Ele desacopla os produtores e consumidores, permitindo que os microsserviços sejam escalados independentemente. Além disso, SQS garante alta disponibilidade, confiabilidade e tolerância a falhas, o que é essencial para um sistema de microsserviços.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora o Amazon SNS seja útil para transmitir mensagens para múltiplos assinantes, ele não é adequado para o processamento assíncrono que desacopla produtores e consumidores. SNS é mais indicado para notificações em tempo real, onde a ordem e a garantia de entrega para cada consumidor não são críticas.  
  - **C:** Usar uma função AWS Lambda para intermediar mensagens adiciona complexidade desnecessária ao sistema. Lambda não é projetado para atuar como um sistema de filas e pode gerar problemas de escalabilidade e custo em sistemas de alto volume.  
  - **D:** O DynamoDB Streams permite processar alterações em uma tabela DynamoDB, mas isso adiciona uma camada de complexidade e não é tão eficiente quanto uma fila para comunicação direta entre produtores e consumidores. Além disso, ele é mais adequado para cenários de replicação ou rastreamento de mudanças em dados, e não para processamento desacoplado de mensagens.

</details>

---

### Questão 182
Uma empresa deseja migrar seu banco de dados MySQL de um ambiente local para a AWS. Recentemente, a empresa enfrentou uma interrupção no banco de dados que impactou significativamente os negócios. Para garantir que isso não aconteça novamente, a empresa busca uma solução confiável na AWS que minimize a perda de dados e armazene cada transação em pelo menos dois nós.  
Qual solução atende a esses requisitos?  

A. Criar uma instância do Amazon RDS com replicação síncrona para três nós em três Zonas de Disponibilidade.  

B. Criar uma instância do Amazon RDS MySQL com a funcionalidade Multi-AZ ativada para replicar os dados de forma síncrona.  

C. Criar uma instância do Amazon RDS MySQL e, em seguida, criar uma réplica de leitura em uma região da AWS separada que replique os dados de forma síncrona.  

D. Criar uma instância do Amazon EC2 com o MySQL instalado que acione uma função AWS Lambda para replicar os dados de forma síncrona para uma instância do Amazon RDS MySQL.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Criar uma instância do Amazon RDS MySQL com a funcionalidade Multi-AZ ativada para replicar os dados de forma síncrona.  

**Justificativa:**  
- **Por que essa opção?**  
  A funcionalidade Multi-AZ do Amazon RDS replica dados de forma síncrona para uma instância secundária em outra Zona de Disponibilidade. Isso fornece alta disponibilidade e tolerância a falhas, minimizando a perda de dados, já que cada transação é confirmada em ambas as instâncias antes de ser considerada concluída. Esta solução atende perfeitamente ao requisito de confiabilidade e replicação mínima de dois nós.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O Amazon RDS não oferece replicação síncrona para três nós por padrão. A configuração Multi-AZ replica dados para um nó secundário em outra Zona de Disponibilidade, mas não para três nós.  
  - **C:** Réplicas de leitura do RDS são assíncronas, não garantindo a consistência imediata dos dados. Isso significa que existe a possibilidade de perda de dados em caso de falha no nó principal.  
  - **D:** Configurar uma instância EC2 com MySQL e usar Lambda para replicação adiciona uma complexidade desnecessária. Essa solução também não oferece replicação nativa e confiável como o RDS Multi-AZ, além de ser mais difícil de gerenciar e escalar.

</details>

---

### Questão 183
Uma empresa está construindo um novo site de pedidos dinâmico. A empresa deseja minimizar a manutenção e atualização de servidores. O site deve ser altamente disponível e escalar a capacidade de leitura e gravação o mais rápido possível para atender às mudanças na demanda dos usuários.  
Qual solução atenderá a esses requisitos?  

A. Hospedar conteúdo estático no Amazon S3. Hospedar conteúdo dinâmico usando o Amazon API Gateway e AWS Lambda. Usar o Amazon DynamoDB com capacidade sob demanda para o banco de dados. Configurar o Amazon CloudFront para entregar o conteúdo do site.  

B. Hospedar conteúdo estático no Amazon S3. Hospedar conteúdo dinâmico usando o Amazon API Gateway e AWS Lambda. Usar o Amazon Aurora com Aurora Auto Scaling para o banco de dados. Configurar o Amazon CloudFront para entregar o conteúdo do site.  

C. Hospedar todo o conteúdo do site em instâncias do Amazon EC2. Criar um grupo de Auto Scaling para escalar as instâncias EC2. Usar um Application Load Balancer para distribuir o tráfego. Usar o Amazon DynamoDB com capacidade de gravação provisionada para o banco de dados.  

D. Hospedar todo o conteúdo do site em instâncias do Amazon EC2. Criar um grupo de Auto Scaling para escalar as instâncias EC2. Usar um Application Load Balancer para distribuir o tráfego. Usar o Amazon Aurora com Aurora Auto Scaling para o banco de dados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Hospedar conteúdo estático no Amazon S3. Hospedar conteúdo dinâmico usando o Amazon API Gateway e AWS Lambda. Usar o Amazon DynamoDB com capacidade sob demanda para o banco de dados. Configurar o Amazon CloudFront para entregar o conteúdo do site.  

**Justificativa:**  
- **Por que essa opção?**  
  Essa solução atende aos requisitos de escalabilidade, alta disponibilidade e manutenção mínima. O Amazon S3 é ideal para hospedar conteúdo estático, pois é altamente escalável e não requer gerenciamento de servidores. O Amazon API Gateway combinado com AWS Lambda elimina a necessidade de servidores para conteúdo dinâmico, fornecendo escalabilidade automática. O DynamoDB com capacidade sob demanda ajusta automaticamente a capacidade de leitura e gravação para atender às mudanças na demanda, garantindo desempenho consistente. O CloudFront melhora a entrega de conteúdo com caching global e baixa latência.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora o Aurora com Auto Scaling seja escalável, ele exige mais manutenção em comparação ao DynamoDB e não escala tão rapidamente quanto o DynamoDB em modo sob demanda. Para um site dinâmico que precisa escalar rapidamente, o DynamoDB é mais apropriado.  
  - **C:** Usar instâncias EC2 para todo o conteúdo adiciona uma sobrecarga de manutenção, incluindo patching e gerenciamento de servidores. Além disso, o DynamoDB em modo provisionado não ajusta a capacidade automaticamente, o que pode causar gargalos em picos de demanda.  
  - **D:** Assim como na alternativa C, o uso de instâncias EC2 aumenta a complexidade de gerenciamento. Embora o Aurora com Auto Scaling seja uma boa escolha para bancos relacionais, ele não oferece a mesma agilidade de escalabilidade que o DynamoDB em modo sob demanda para casos de uso dinâmicos.

</details>

---

### Questão 184
Uma empresa possui uma conta AWS usada para engenharia de software. A conta AWS tem acesso ao data center local da empresa por meio de duas conexões AWS Direct Connect. Todo o tráfego que não pertence à VPC é roteado para o gateway privado virtual.  
Uma equipe de desenvolvimento criou recentemente uma função AWS Lambda pelo console. A equipe precisa permitir que a função acesse um banco de dados que está em uma sub-rede privada no data center local da empresa.  
Qual solução atenderá a esses requisitos?  

A. Configurar a função Lambda para ser executada na VPC com o grupo de segurança apropriado.  

B. Configurar uma conexão VPN da AWS para o data center. Roteie o tráfego da função Lambda através da VPN.  

C. Atualizar as tabelas de rota na VPC para permitir que a função Lambda acesse o data center local por meio do Direct Connect.  

D. Criar um endereço Elastic IP. Configurar a função Lambda para enviar tráfego através do Elastic IP sem uma interface de rede elástica.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Configurar a função Lambda para ser executada na VPC com o grupo de segurança apropriado.  

**Justificativa:**  
- **Por que essa opção?**  
  Para que a função Lambda acesse recursos em uma sub-rede privada, ela deve ser configurada para rodar dentro da VPC apropriada. Ao associar a função Lambda a uma VPC, você também pode configurar grupos de segurança para permitir o acesso ao banco de dados no data center. Como o tráfego não pertencente à VPC já é roteado através do Direct Connect, isso permite que a função se conecte ao banco de dados sem a necessidade de outras configurações de rede.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Configurar uma conexão VPN não é necessário, pois a conectividade com o data center já está configurada por meio do Direct Connect. Essa abordagem adicionaria complexidade desnecessária.  
  - **C:** Atualizar as tabelas de rota não resolve o problema por si só, porque a função Lambda precisa estar associada à VPC para usar essas rotas. A simples atualização das tabelas de rota não permitirá que uma função Lambda sem VPC acesse recursos na sub-rede privada.  
  - **D:** Elastic IPs não podem ser usados diretamente com funções Lambda. Além disso, essa abordagem não fornece um caminho seguro e gerenciado para acessar sub-redes privadas ou data centers locais.

</details>

---

### Questão 185
Uma empresa executa um aplicativo usando o Amazon ECS. O aplicativo cria versões redimensionadas de uma imagem original e faz chamadas à API do Amazon S3 para armazenar as imagens redimensionadas no Amazon S3.  
Como um arquiteto de soluções pode garantir que o aplicativo tenha permissão para acessar o Amazon S3?  

A. Atualizar a função do S3 no AWS IAM para permitir acesso de leitura/gravação a partir do Amazon ECS e, em seguida, reiniciar o contêiner.  

B. Criar uma função do IAM com permissões para o S3 e especificar essa função como o `taskRoleArn` na definição da tarefa.  

C. Criar um grupo de segurança que permita acesso do Amazon ECS ao Amazon S3 e atualizar a configuração de inicialização usada pelo cluster ECS.  

D. Criar um usuário do IAM com permissões para o S3 e reiniciar as instâncias Amazon EC2 do cluster ECS enquanto estiver logado com essa conta.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Criar uma função do IAM com permissões para o S3 e especificar essa função como o `taskRoleArn` na definição da tarefa.  

**Justificativa:**  
- **Por que essa opção?**  
  A solução mais apropriada é criar uma função do IAM com permissões necessárias para acessar o S3 e associar essa função diretamente à definição da tarefa ECS usando o atributo `taskRoleArn`. Isso garante que as permissões corretas sejam atribuídas diretamente ao nível da tarefa, minimizando o risco de escalonamento de privilégios e garantindo que apenas os recursos necessários tenham acesso ao S3.  

- **Por que as outras opções não são adequadas?**  
  - **A:** As permissões do IAM não são diretamente associadas ao Amazon S3. A configuração correta de permissões para o ECS requer o uso de uma função IAM atribuída à definição de tarefa, e não apenas a atualização de permissões no S3.  
  - **C:** Grupos de segurança controlam o tráfego de rede, não as permissões para acessar os serviços da AWS. Permissões de acesso ao S3 são gerenciadas por políticas do IAM e não por grupos de segurança.  
  - **D:** Criar um usuário do IAM e logar manualmente com essa conta para as instâncias do cluster é uma prática insegura e não escalável. A AWS recomenda o uso de funções do IAM para atribuir permissões a serviços, como o ECS, em vez de usar credenciais de usuário manualmente.

</details>

---

### Questão 186
Uma empresa possui um aplicativo baseado em Windows que deve ser migrado para a AWS. O aplicativo requer o uso de um sistema de arquivos Windows compartilhado, anexado a várias instâncias Amazon EC2 Windows que estão implantadas em várias Zonas de Disponibilidade.  
O que um arquiteto de soluções deve fazer para atender a esse requisito?  

A. Configurar o AWS Storage Gateway no modo de gateway de volumes. Montar o volume em cada instância Windows.  

B. Configurar o Amazon FSx for Windows File Server. Montar o sistema de arquivos Amazon FSx em cada instância Windows.  

C. Configurar um sistema de arquivos usando o Amazon Elastic File System (Amazon EFS). Montar o sistema de arquivos EFS em cada instância Windows.  

D. Configurar um volume Amazon Elastic Block Store (Amazon EBS) com o tamanho necessário. Anexar cada instância EC2 ao volume. Montar o sistema de arquivos dentro do volume em cada instância Windows.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Configurar o Amazon FSx for Windows File Server. Montar o sistema de arquivos Amazon FSx em cada instância Windows.  

**Justificativa:**  
- **Por que essa opção?**  
  O Amazon FSx for Windows File Server é a solução ideal para sistemas de arquivos compartilhados em Windows na AWS. Ele é projetado para aplicativos baseados em Windows e oferece suporte ao protocolo SMB (Server Message Block), além de permitir compartilhamento de arquivos entre instâncias em várias Zonas de Disponibilidade. Isso atende aos requisitos de alta disponibilidade e compatibilidade com o sistema operacional Windows.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O AWS Storage Gateway é usado principalmente para integração entre ambientes locais e a AWS. Ele não é ideal para sistemas de arquivos compartilhados em instâncias EC2 em várias Zonas de Disponibilidade.  
  - **C:** O Amazon EFS é otimizado para sistemas baseados em Linux. Ele não é compatível com Windows nativamente, o que o torna inadequado para essa aplicação.  
  - **D:** Volumes Amazon EBS não podem ser compartilhados entre várias instâncias EC2 ao mesmo tempo. Eles são projetados para serem usados exclusivamente por uma única instância, o que os torna inadequados para um sistema de arquivos compartilhado.  

</details>

---

### Questão 187
Uma empresa está desenvolvendo um aplicativo de comércio eletrônico que consistirá em um front-end com balanceamento de carga, um aplicativo baseado em contêiner e um banco de dados relacional. Um arquiteto de soluções precisa criar uma solução altamente disponível que opere com o mínimo de intervenção manual possível.  

Quais soluções atendem a esses requisitos? (Escolha duas.)  

A. Criar uma instância do Amazon RDS no modo Multi-AZ.  

B. Criar uma instância do Amazon RDS e uma ou mais réplicas em outra Zona de Disponibilidade.  

C. Criar um cluster Docker baseado em instâncias Amazon EC2 para lidar com a carga dinâmica do aplicativo.  

D. Criar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de execução Fargate para lidar com a carga dinâmica do aplicativo.  

E. Criar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de execução Amazon EC2 para lidar com a carga dinâmica do aplicativo.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>A,D</resposta>

**A:** Criar uma instância do Amazon RDS no modo Multi-AZ.  
**D:** Criar um cluster Amazon Elastic Container Service (Amazon ECS) com o tipo de execução Fargate para lidar com a carga dinâmica do aplicativo.  

**Justificativa:**  
- **Por que essas opções?**  
  - **A:** O Amazon RDS no modo Multi-AZ oferece alta disponibilidade e failover automático para bancos de dados relacionais. Ele reduz a necessidade de intervenção manual, garantindo continuidade em caso de falha em uma Zona de Disponibilidade.  
  - **D:** O Amazon ECS com o tipo de execução Fargate elimina a necessidade de gerenciar servidores ou clusters de contêineres manualmente. Ele é ideal para cargas dinâmicas, escalando automaticamente para atender às demandas do aplicativo, o que reduz a necessidade de intervenção manual.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Embora as réplicas de leitura em outra Zona de Disponibilidade aumentem a disponibilidade para leituras, elas não oferecem failover automático para gravações, o que é essencial para alta disponibilidade.  
  - **C:** Gerenciar manualmente um cluster baseado em instâncias Amazon EC2 aumenta a carga operacional, pois seria necessário ajustar e monitorar os recursos manualmente para lidar com a carga dinâmica do aplicativo.  
  - **E:** Usar o tipo de execução Amazon EC2 para ECS requer o gerenciamento manual de instâncias EC2 subjacentes, o que adiciona complexidade e vai contra o requisito de minimizar a intervenção manual.  

</details>

---
### Questão 188
Uma empresa usa o Amazon S3 como seu data lake. A empresa tem um novo parceiro que deve usar SFTP para enviar arquivos de dados. Um arquiteto de soluções precisa implementar uma solução SFTP altamente disponível que minimize a sobrecarga operacional.  
Qual solução atenderá a esses requisitos?  

A. Usar o AWS Transfer Family para configurar um servidor habilitado para SFTP com um endpoint publicamente acessível. Escolher o data lake do S3 como destino.  

B. Usar o Amazon S3 File Gateway como um servidor SFTP. Expor a URL do endpoint do S3 File Gateway para o novo parceiro. Compartilhar o endpoint do S3 File Gateway com o novo parceiro.  

C. Lançar uma instância Amazon EC2 em uma sub-rede privada em uma VPC. Instruir o novo parceiro a enviar arquivos para a instância EC2 usando uma VPN. Executar um script cron na instância EC2 para enviar arquivos ao data lake do S3.  

D. Lançar instâncias Amazon EC2 em uma sub-rede privada em uma VPC. Colocar um Network Load Balancer (NLB) na frente das instâncias EC2. Criar uma porta de escuta SFTP para o NLB. Compartilhar o nome do host do NLB com o novo parceiro. Executar um script cron nas instâncias EC2 para enviar arquivos ao data lake do S3.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Usar o AWS Transfer Family para configurar um servidor habilitado para SFTP com um endpoint publicamente acessível. Escolher o data lake do S3 como destino.  

**Justificativa:**  
- **Por que essa opção?**  
  O AWS Transfer Family é uma solução gerenciada para transferências de arquivos que suporta SFTP, FTPS e FTP. Ele se integra diretamente ao Amazon S3, eliminando a necessidade de gerenciar infraestrutura como instâncias EC2. É altamente disponível por padrão e minimiza a sobrecarga operacional, atendendo perfeitamente aos requisitos da empresa.  

- **Por que as outras opções não são adequadas?**  
  - **B:** O Amazon S3 File Gateway não é projetado para atuar como um servidor SFTP. Ele serve como uma ponte entre armazenamento local e o Amazon S3, mas não oferece suporte direto ao protocolo SFTP.  
  - **C:** Gerenciar manualmente uma instância EC2 para operar como servidor SFTP e configurar uma VPN adiciona complexidade desnecessária. Essa solução também não é intrinsecamente altamente disponível.  
  - **D:** Configurar várias instâncias EC2 com um Network Load Balancer para SFTP adiciona sobrecarga operacional significativa. A necessidade de scripts cron para mover os arquivos para o S3 aumenta ainda mais a complexidade, tornando essa abordagem menos eficiente e confiável em comparação ao AWS Transfer Family.  

</details>

---

### Questão 189
Uma empresa precisa armazenar documentos contratuais. Um contrato tem duração de 5 anos. Durante esse período de 5 anos, a empresa deve garantir que os documentos não possam ser sobrescritos ou excluídos. A empresa precisa criptografar os documentos em repouso e rotacionar as chaves de criptografia automaticamente todos os anos.  

Quais combinações de etapas um arquiteto de soluções deve adotar para atender a esses requisitos com a MENOR sobrecarga operacional? (Escolha duas.)  

A. Armazenar os documentos no Amazon S3. Usar o S3 Object Lock no modo de governança.  

B. Armazenar os documentos no Amazon S3. Usar o S3 Object Lock no modo de conformidade.  

C. Usar criptografia no lado do servidor com chaves de criptografia gerenciadas pelo Amazon S3 (SSE-S3). Configurar a rotação de chaves.  

D. Usar criptografia no lado do servidor com chaves gerenciadas pelo AWS Key Management Service (AWS KMS). Configurar a rotação de chaves.  

E. Usar criptografia no lado do servidor com chaves fornecidas pelo cliente (importadas) no AWS Key Management Service (AWS KMS). Configurar a rotação de chaves.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>B,D</resposta>

**B:** Armazenar os documentos no Amazon S3. Usar o S3 Object Lock no modo de conformidade.  
**D:** Usar criptografia no lado do servidor com chaves gerenciadas pelo AWS Key Management Service (AWS KMS). Configurar a rotação de chaves.  

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O S3 Object Lock no modo de conformidade garante que os objetos não possam ser excluídos ou sobrescritos durante o período de retenção configurado. Esse modo é mais restritivo do que o modo de governança e atende ao requisito de garantir a imutabilidade dos documentos por 5 anos.  
  - **D:** Usar o AWS KMS com chaves gerenciadas permite configurar a rotação automática de chaves anualmente, atendendo ao requisito de segurança com a menor sobrecarga operacional. O AWS KMS gerencia as chaves com integração direta ao S3, simplificando o gerenciamento de criptografia.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O modo de governança do S3 Object Lock permite que usuários com permissões específicas desativem a proteção de objetos, o que pode violar o requisito de imutabilidade durante o período de retenção.  
  - **C:** O SSE-S3 não oferece suporte à rotação de chaves pelo cliente. Embora seja gerenciado pela AWS, ele não fornece a flexibilidade de gerenciamento de chaves necessária para esse caso.  
  - **E:** Usar chaves fornecidas pelo cliente no AWS KMS requer que a empresa gerencie a rotação manualmente, o que aumenta a sobrecarga operacional e vai contra o objetivo de minimizar o esforço de gerenciamento.  

</details>

---

### Questão 190
Uma empresa possui uma aplicação web baseada em Java e PHP. A empresa planeja mover a aplicação de um ambiente local para a AWS. A empresa precisa da capacidade de testar frequentemente novos recursos do site. A solução também deve ser altamente disponível, gerenciada e exigir o mínimo de sobrecarga operacional.  

Qual solução atenderá a esses requisitos?  

A. Criar um bucket Amazon S3. Habilitar hospedagem web estática no bucket S3. Fazer upload do conteúdo estático para o bucket S3. Usar o AWS Lambda para processar todo o conteúdo dinâmico.  

B. Implantar a aplicação web em um ambiente AWS Elastic Beanstalk. Usar a troca de URLs para alternar entre vários ambientes Elastic Beanstalk para testar novos recursos.  

C. Implantar a aplicação web em instâncias Amazon EC2 configuradas com Java e PHP. Usar grupos de Auto Scaling e um Application Load Balancer para gerenciar a disponibilidade do site.  

D. Containerizar a aplicação web. Implantar a aplicação em instâncias Amazon EC2. Usar o AWS Load Balancer Controller para rotear dinamicamente o tráfego entre contêineres que contenham novos recursos do site para teste.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Implantar a aplicação web em um ambiente AWS Elastic Beanstalk. Usar a troca de URLs para alternar entre vários ambientes Elastic Beanstalk para testar novos recursos.  

**Justificativa:**  
- **Por que essa opção?**  
  O AWS Elastic Beanstalk é uma solução gerenciada que suporta Java e PHP, oferecendo alta disponibilidade e escalabilidade automática. Ele reduz significativamente a sobrecarga operacional, já que gerencia automaticamente o provisionamento de recursos e a configuração da infraestrutura. Além disso, o Elastic Beanstalk permite alternar URLs entre ambientes para testar novos recursos de forma segura e eficiente.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora o S3 seja uma solução gerenciada, ele é mais adequado para sites estáticos. Usar AWS Lambda para processar conteúdo dinâmico não é ideal para uma aplicação complexa como essa, pois pode aumentar a complexidade e os custos operacionais.  
  - **C:** Gerenciar manualmente instâncias EC2 com Auto Scaling e Load Balancer adiciona sobrecarga operacional e não oferece os benefícios gerenciados que o Elastic Beanstalk fornece.  
  - **D:** Containerizar a aplicação e usar EC2 para gerenciá-la requer maior esforço operacional em comparação ao Elastic Beanstalk. Embora seja uma abordagem moderna, não atende ao requisito de minimizar a sobrecarga operacional.  

</details>

---

### Questão 191
Uma empresa possui um aplicativo de pedidos que armazena informações de clientes no Amazon RDS for MySQL. Durante o horário comercial, os funcionários executam consultas pontuais para fins de relatórios. Estão ocorrendo timeouts durante o processamento de pedidos porque as consultas de relatório estão demorando muito para serem executadas. A empresa precisa eliminar os timeouts sem impedir que os funcionários realizem consultas.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Criar uma réplica de leitura. Mover as consultas de relatórios para a réplica de leitura.  

B. Criar uma réplica de leitura. Distribuir o aplicativo de pedidos entre a instância de banco de dados primária e a réplica de leitura.  

C. Migrar o aplicativo de pedidos para o Amazon DynamoDB com capacidade sob demanda.  

D. Agendar as consultas de relatório para horários fora de pico.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Criar uma réplica de leitura. Mover as consultas de relatórios para a réplica de leitura.  

**Justificativa:**  
- **Por que essa opção?**  
  Criar uma réplica de leitura no Amazon RDS permite separar as cargas de trabalho de leitura e escrita. As consultas de relatórios podem ser redirecionadas para a réplica de leitura, enquanto a instância primária lida com as transações de gravação do aplicativo de pedidos. Isso elimina os timeouts causados pelas consultas de relatório sem impedir os funcionários de realizar essas consultas.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Distribuir o aplicativo de pedidos entre a instância primária e a réplica de leitura não é uma prática recomendada, pois réplicas de leitura não são projetadas para operações de gravação. Isso pode causar inconsistências e erros.  
  - **C:** Migrar para o DynamoDB não é necessário neste caso, pois o problema está relacionado à separação de carga de leitura e escrita. Além disso, o DynamoDB é um banco de dados NoSQL e pode não atender aos requisitos do aplicativo existente baseado em MySQL.  
  - **D:** Agendar as consultas de relatório para horários fora de pico é uma solução temporária que não resolve o problema subjacente. Os funcionários ainda precisam realizar consultas durante o horário comercial, o que não seria atendido por essa abordagem.  

</details>

---


### Questão 192
Um hospital deseja criar cópias digitais de sua grande coleção de registros históricos escritos. O hospital continuará a adicionar centenas de novos documentos diariamente. A equipe de dados do hospital irá digitalizar os documentos e enviá-los para a AWS Cloud.  
Um arquiteto de soluções deve implementar uma solução para analisar os documentos, extrair informações médicas e armazená-los de forma que um aplicativo possa executar consultas SQL sobre os dados. A solução deve maximizar a escalabilidade e a eficiência operacional.  
Quais combinações de etapas o arquiteto de soluções deve adotar para atender a esses requisitos? (Escolha duas.)  

A. Gravar as informações dos documentos em uma instância Amazon EC2 que executa um banco de dados MySQL.  

B. Gravar as informações dos documentos em um bucket Amazon S3. Usar o Amazon Athena para consultar os dados.  

C. Criar um grupo de Auto Scaling de instâncias Amazon EC2 para executar um aplicativo personalizado que processa os arquivos digitalizados e extrai as informações médicas.  

D. Criar uma função AWS Lambda que é executada quando novos documentos são carregados. Usar o Amazon Rekognition para converter os documentos em texto bruto. Usar o Amazon Transcribe Medical para detectar e extrair informações médicas relevantes do texto.  

E. Criar uma função AWS Lambda que é executada quando novos documentos são carregados. Usar o Amazon Textract para converter os documentos em texto bruto. Usar o Amazon Comprehend Medical para detectar e extrair informações médicas relevantes do texto.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>B,E</resposta>

**B:** Gravar as informações dos documentos em um bucket Amazon S3. Usar o Amazon Athena para consultar os dados.  
**E:** Criar uma função AWS Lambda que é executada quando novos documentos são carregados. Usar o Amazon Textract para converter os documentos em texto bruto. Usar o Amazon Comprehend Medical para detectar e extrair informações médicas relevantes do texto.  

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O Amazon S3 é uma solução escalável e eficiente para armazenar os dados dos documentos. Ele se integra diretamente ao Amazon Athena, permitindo consultas SQL sobre os dados sem a necessidade de configurar e gerenciar um banco de dados relacional. Isso maximiza a escalabilidade e reduz a sobrecarga operacional.  
  - **E:** O AWS Lambda é uma solução sem servidor que processa novos documentos automaticamente. O Amazon Textract é ideal para converter documentos digitalizados em texto bruto, enquanto o Amazon Comprehend Medical pode identificar e extrair informações médicas relevantes. Essa combinação é altamente eficiente e escalável.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Usar uma instância EC2 com um banco de dados MySQL aumenta a sobrecarga operacional e não oferece a escalabilidade necessária para processar grandes volumes de dados continuamente.  
  - **C:** Criar um grupo de Auto Scaling de instâncias EC2 para processar arquivos digitalizados é menos eficiente do que usar uma solução baseada em Lambda e serviços gerenciados da AWS, como Textract e Comprehend Medical.  
  - **D:** O Amazon Rekognition é projetado para análise de imagens e não para extrair texto de documentos digitalizados. O Amazon Transcribe Medical é usado para transcrição de áudio, o que não se aplica a este caso.  

</details>

---

### Questão 193
Uma empresa está executando um aplicativo de processamento em lote em instâncias Amazon EC2. O aplicativo consiste em um backend com múltiplos bancos de dados Amazon RDS. O aplicativo está gerando um alto número de leituras nos bancos de dados. Um arquiteto de soluções deve reduzir o número de leituras nos bancos de dados, garantindo alta disponibilidade.  
O que o arquiteto de soluções deve fazer para atender a esse requisito?  

A. Adicionar réplicas de leitura ao Amazon RDS.  

B. Usar o Amazon ElastiCache para Redis.  

C. Usar o cache DNS do Amazon Route 53.  

D. Usar o Amazon ElastiCache para Memcached.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Usar o Amazon ElastiCache para Redis.  

**Justificativa:**  
- **Por que essa opção?**  
  O Amazon ElastiCache para Redis é uma solução de cache in-memory altamente eficiente que reduz o número de leituras diretamente nos bancos de dados, armazenando em cache os resultados de consultas frequentemente acessadas. Ele oferece suporte a alta disponibilidade com replicação e failover automático, garantindo que o cache continue operacional mesmo em caso de falhas.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Embora réplicas de leitura do Amazon RDS possam ajudar a distribuir a carga de leitura, elas ainda dependem diretamente do banco de dados e não reduzem significativamente a latência como uma solução de cache in-memory. Além disso, a configuração de múltiplas réplicas pode aumentar os custos e a complexidade operacional.  
  - **C:** O cache DNS do Amazon Route 53 melhora a resolução de nomes DNS, mas não tem relação com a redução de leituras no banco de dados. Ele não resolve o problema apresentado.  
  - **D:** O ElastiCache para Memcached é uma solução de cache in-memory semelhante ao Redis, mas não oferece recursos de alta disponibilidade como replicação e failover automático. Isso o torna menos adequado para o requisito de alta disponibilidade.  

</details>

---

### Questão 194
Uma empresa precisa executar uma aplicação crítica na AWS. A empresa precisa usar o Amazon EC2 para o banco de dados da aplicação. O banco de dados deve ser altamente disponível e deve realizar failover automaticamente se ocorrer um evento disruptivo.  

Qual solução atenderá a esses requisitos?  

A. Lançar duas instâncias EC2, cada uma em uma Zona de Disponibilidade diferente na mesma Região AWS. Instalar o banco de dados em ambas as instâncias EC2. Configurar as instâncias EC2 como um cluster. Configurar a replicação do banco de dados.  

B. Lançar uma instância EC2 em uma Zona de Disponibilidade. Instalar o banco de dados na instância EC2. Usar uma Amazon Machine Image (AMI) para fazer backup dos dados. Usar o AWS CloudFormation para automatizar o provisionamento da instância EC2 se ocorrer um evento disruptivo.  

C. Lançar duas instâncias EC2, cada uma em uma Região AWS diferente. Instalar o banco de dados em ambas as instâncias EC2. Configurar a replicação do banco de dados. Fazer failover do banco de dados para uma segunda Região.  

D. Lançar uma instância EC2 em uma Zona de Disponibilidade. Instalar o banco de dados na instância EC2. Usar uma Amazon Machine Image (AMI) para fazer backup dos dados. Usar a recuperação automática do EC2 para recuperar a instância se ocorrer um evento disruptivo.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>A</resposta>

**A:** Lançar duas instâncias EC2, cada uma em uma Zona de Disponibilidade diferente na mesma Região AWS. Instalar o banco de dados em ambas as instâncias EC2. Configurar as instâncias EC2 como um cluster. Configurar a replicação do banco de dados.  

**Justificativa:**  
- **Por que essa opção?**  
  Ao usar duas instâncias EC2 em Zonas de Disponibilidade diferentes dentro da mesma Região e configurar a replicação do banco de dados entre elas, é possível alcançar alta disponibilidade. Em caso de falha de uma instância ou Zona de Disponibilidade, o failover automático será realizado para a instância em funcionamento, garantindo a continuidade do banco de dados.  

- **Por que as outras opções não são adequadas?**  
  - **B:** Fazer backup com uma AMI e usar o CloudFormation para reprovisionar a instância não atende aos requisitos de failover automático. Esse processo é manual e pode causar atrasos.  
  - **C:** Configurar duas instâncias em Regiões diferentes adiciona complexidade desnecessária e latência, especialmente para bancos de dados que precisam de baixa latência para replicação. Além disso, a configuração de failover entre Regiões não é automática sem soluções adicionais, como o uso de Amazon RDS Multi-Region.  
  - **D:** A recuperação automática do EC2 restaura a mesma instância em caso de falha, mas não oferece alta disponibilidade. Durante a recuperação, a aplicação ficará indisponível até que a instância seja restaurada.  

</details>

---

### Questão 195
O sistema de pedidos de uma empresa envia solicitações de clientes para instâncias Amazon EC2. As instâncias EC2 processam os pedidos e os armazenam em um banco de dados no Amazon RDS. Os usuários relatam que precisam reprocessar pedidos quando o sistema falha. A empresa deseja uma solução resiliente que possa processar pedidos automaticamente em caso de falha do sistema.  
O que um arquiteto de soluções deve fazer para atender a esses requisitos?  

A. Mover as instâncias EC2 para um grupo de Auto Scaling. Criar uma regra do Amazon EventBridge (Amazon CloudWatch Events) para direcionar uma tarefa do Amazon Elastic Container Service (Amazon ECS).  

B. Mover as instâncias EC2 para um grupo de Auto Scaling atrás de um Application Load Balancer (ALB). Atualizar o sistema de pedidos para enviar mensagens ao endpoint do ALB.  

C. Mover as instâncias EC2 para um grupo de Auto Scaling. Configurar o sistema de pedidos para enviar mensagens para uma fila do Amazon Simple Queue Service (Amazon SQS). Configurar as instâncias EC2 para consumir mensagens da fila.  

D. Criar um tópico do Amazon Simple Notification Service (Amazon SNS). Criar uma função AWS Lambda e inscrever a função no tópico SNS. Configurar o sistema de pedidos para enviar mensagens ao tópico SNS. Enviar um comando para as instâncias EC2 processarem as mensagens usando o AWS Systems Manager Run Command.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>C</resposta>

**C:** Mover as instâncias EC2 para um grupo de Auto Scaling. Configurar o sistema de pedidos para enviar mensagens para uma fila do Amazon Simple Queue Service (Amazon SQS). Configurar as instâncias EC2 para consumir mensagens da fila.  

**Justificativa:**  
- **Por que essa opção?**  
  O Amazon SQS é uma solução de filas resiliente e escalável que desacopla o sistema de pedidos das instâncias EC2. Isso garante que, mesmo em caso de falha do sistema ou instâncias, os pedidos sejam armazenados na fila e processados quando as instâncias voltarem a estar disponíveis. Usar um grupo de Auto Scaling garante que as instâncias EC2 sejam escaladas automaticamente para lidar com picos de carga ou substituir instâncias com falha.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Configurar o Amazon EventBridge para acionar uma tarefa do Amazon ECS adiciona complexidade desnecessária e não aborda diretamente o problema de armazenamento resiliente de pedidos em caso de falha.  
  - **B:** O Application Load Balancer ajuda na distribuição de tráfego, mas não armazena mensagens ou pedidos em caso de falha. Isso não resolve o problema de reprocessamento relatado pelos usuários.  
  - **D:** Usar o Amazon SNS e AWS Lambda adiciona complexidade desnecessária e não fornece um mecanismo de armazenamento persistente para os pedidos. O SNS é projetado para notificações em tempo real, não para retenção de mensagens como o SQS.  

</details>

---

### Questão 196
Uma empresa executa um aplicativo em uma grande frota de instâncias Amazon EC2. O aplicativo lê e grava entradas em uma tabela do Amazon DynamoDB. O tamanho da tabela do DynamoDB cresce continuamente, mas o aplicativo precisa apenas dos dados dos últimos 30 dias. A empresa precisa de uma solução que minimize custos e esforço de desenvolvimento.  
Qual solução atende a esses requisitos?  

A. Usar um template do AWS CloudFormation para implantar a solução completa. Reimplantar o stack do CloudFormation a cada 30 dias e excluir o stack original.  

B. Usar uma instância EC2 que executa um aplicativo de monitoramento do AWS Marketplace. Configurar o aplicativo de monitoramento para usar Amazon DynamoDB Streams e armazenar o timestamp quando um novo item for criado na tabela. Usar um script que roda na instância EC2 para excluir itens com timestamp superior a 30 dias.  

C. Configurar o Amazon DynamoDB Streams para invocar uma função AWS Lambda quando um novo item for criado na tabela. Configurar a função Lambda para excluir itens na tabela que são mais antigos que 30 dias.  

D. Estender o aplicativo para adicionar um atributo com o valor do timestamp atual mais 30 dias para cada novo item criado na tabela. Configurar o DynamoDB para usar o atributo como o atributo de TTL.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D:** Estender o aplicativo para adicionar um atributo com o valor do timestamp atual mais 30 dias para cada novo item criado na tabela. Configurar o DynamoDB para usar o atributo como o atributo de TTL.  

**Justificativa:**  
- **Por que essa opção?**  
  O recurso Time-to-Live (TTL) do Amazon DynamoDB é uma solução integrada, econômica e eficiente para excluir automaticamente itens que excederem o período de retenção especificado. Isso reduz a complexidade de desenvolvimento e elimina a necessidade de gerenciar scripts ou recursos adicionais, minimizando custos e esforço.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Reimplantar o stack do CloudFormation a cada 30 dias é ineficiente, envolve esforço operacional significativo e pode causar interrupções no serviço.  
  - **B:** Usar uma instância EC2 com um aplicativo de monitoramento adiciona custos desnecessários e complexidade, além de depender de scripts manuais para exclusão de itens.  
  - **C:** Embora o uso de DynamoDB Streams e uma função Lambda seja viável, ele introduz complexidade adicional em comparação com o recurso TTL, que já é otimizado para esse caso de uso.  

</details>

---

### Questão 197
Uma empresa possui um aplicativo Microsoft .NET que é executado em um servidor Windows local. O aplicativo armazena dados usando um servidor Oracle Database Standard Edition. A empresa planeja uma migração para a AWS e deseja minimizar mudanças de desenvolvimento durante a migração. O ambiente de aplicação na AWS deve ser altamente disponível.  
Quais combinações de ações a empresa deve tomar para atender a esses requisitos? (Escolha duas.)  

A. Refatorar o aplicativo como serverless com funções AWS Lambda executando .NET Core.  

B. Realocar o aplicativo no AWS Elastic Beanstalk com a plataforma .NET em uma implantação Multi-AZ.  

C. Replataformar o aplicativo para ser executado no Amazon EC2 com a Amazon Linux Amazon Machine Image (AMI).  

D. Usar o AWS Database Migration Service (AWS DMS) para migrar do banco de dados Oracle para o Amazon DynamoDB em uma implantação Multi-AZ.  

E. Usar o AWS Database Migration Service (AWS DMS) para migrar do banco de dados Oracle para o Oracle no Amazon RDS em uma implantação Multi-AZ.  

<details>
<summary>Resposta</summary>

**Respostas corretas:**  
<resposta>B,E</resposta>

**B:** Realocar o aplicativo no AWS Elastic Beanstalk com a plataforma .NET em uma implantação Multi-AZ.  
**E:** Usar o AWS Database Migration Service (AWS DMS) para migrar do banco de dados Oracle para o Oracle no Amazon RDS em uma implantação Multi-AZ.  

**Justificativa:**  
- **Por que essas opções?**  
  - **B:** O AWS Elastic Beanstalk oferece uma solução gerenciada para implantar e escalar aplicativos .NET com o mínimo de mudanças no código. Ele suporta alta disponibilidade em uma configuração Multi-AZ, alinhando-se aos requisitos do caso.  
  - **E:** O Amazon RDS para Oracle é ideal para migrar o banco de dados Oracle sem a necessidade de alterar o esquema ou as consultas existentes. Ele também oferece alta disponibilidade com suporte Multi-AZ, atendendo aos requisitos de resiliência.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Refatorar o aplicativo como serverless com AWS Lambda requer mudanças significativas no código, o que vai contra o objetivo de minimizar alterações no desenvolvimento.  
  - **C:** Replataformar o aplicativo para o Amazon Linux AMI não é viável, pois o .NET requer um ambiente Windows para executar o aplicativo sem modificações significativas.  
  - **D:** Migrar para o DynamoDB não é adequado porque o banco de dados atual é relacional (Oracle) e migrar para um banco NoSQL exigiria mudanças significativas no aplicativo e no esquema de dados.  

</details>

---

### Questão 198
Uma empresa executa um aplicativo containerizado em um cluster Kubernetes em um data center local. A empresa utiliza um banco de dados MongoDB para armazenamento de dados. A empresa deseja migrar alguns desses ambientes para a AWS, mas não pode realizar alterações no código ou no método de implantação neste momento. A solução deve minimizar a sobrecarga operacional.  
Qual solução atende a esses requisitos?  

A. Usar o Amazon Elastic Container Service (Amazon ECS) com nós de trabalho Amazon EC2 para computação e MongoDB no EC2 para armazenamento de dados.  

B. Usar o Amazon Elastic Container Service (Amazon ECS) com AWS Fargate para computação e Amazon DynamoDB para armazenamento de dados.  

C. Usar o Amazon Elastic Kubernetes Service (Amazon EKS) com nós de trabalho Amazon EC2 para computação e Amazon DynamoDB para armazenamento de dados.  

D. Usar o Amazon Elastic Kubernetes Service (Amazon EKS) com AWS Fargate para computação e Amazon DocumentDB (com compatibilidade com MongoDB) para armazenamento de dados.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D:** Usar o Amazon Elastic Kubernetes Service (Amazon EKS) com AWS Fargate para computação e Amazon DocumentDB (com compatibilidade com MongoDB) para armazenamento de dados.  

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon EKS com AWS Fargate:** Permite a migração do ambiente Kubernetes sem alterações no método de implantação, eliminando a necessidade de gerenciar a infraestrutura subjacente. Fargate reduz a sobrecarga operacional ao gerenciar a infraestrutura de nós automaticamente.  
  - **Amazon DocumentDB:** Oferece compatibilidade com MongoDB, permitindo que a empresa migre os dados sem alterar o código que interage com o banco de dados. Essa solução elimina a necessidade de gerenciar instâncias MongoDB diretamente, reduzindo ainda mais a sobrecarga operacional.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Usar Amazon ECS e MongoDB no EC2 exige gerenciar manualmente a infraestrutura do banco de dados e dos nós de trabalho, aumentando a sobrecarga operacional.  
  - **B:** O Amazon DynamoDB é um banco de dados NoSQL, mas não é compatível com MongoDB. Migrar para DynamoDB exigiria alterações no esquema de dados e no código, o que não é permitido neste caso.  
  - **C:** Embora o Amazon EKS com EC2 permita o uso de Kubernetes, o uso do DynamoDB para armazenamento de dados exigiria alterações no código, além de aumentar a complexidade de gerenciamento dos nós do Kubernetes.  

</details>

---

### Questão 199
Uma empresa de telemarketing está projetando a funcionalidade de seu call center na AWS. A empresa precisa de uma solução que ofereça reconhecimento de múltiplos interlocutores e gere arquivos de transcrição. A empresa também deseja consultar os arquivos de transcrição para analisar padrões de negócios. Os arquivos de transcrição devem ser armazenados por 7 anos para fins de auditoria.  
Qual solução atenderá a esses requisitos?  

A. Usar o Amazon Rekognition para reconhecimento de múltiplos interlocutores. Armazenar os arquivos de transcrição no Amazon S3. Usar modelos de aprendizado de máquina para análise dos arquivos de transcrição.  

B. Usar o Amazon Transcribe para reconhecimento de múltiplos interlocutores. Usar o Amazon Athena para análise dos arquivos de transcrição.  

C. Usar o Amazon Translate para reconhecimento de múltiplos interlocutores. Armazenar os arquivos de transcrição no Amazon Redshift. Usar consultas SQL para análise dos arquivos de transcrição.  

D. Usar o Amazon Rekognition para reconhecimento de múltiplos interlocutores. Armazenar os arquivos de transcrição no Amazon S3. Usar o Amazon Textract para análise dos arquivos de transcrição.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>B</resposta>

**B:** Usar o Amazon Transcribe para reconhecimento de múltiplos interlocutores. Usar o Amazon Athena para análise dos arquivos de transcrição.  

**Justificativa:**  
- **Por que essa opção?**  
  - **Amazon Transcribe:** É a solução ideal para reconhecimento de múltiplos interlocutores em arquivos de áudio, com suporte para geração de transcrições precisas e etiquetagem de diferentes falantes.  
  - **Amazon Athena:** Permite consultar diretamente os arquivos de transcrição armazenados no Amazon S3 usando SQL, simplificando a análise de padrões de negócios.  
  - **Amazon S3:** É altamente escalável e econômico para armazenar os arquivos de transcrição durante o período necessário de 7 anos.  

- **Por que as outras opções não são adequadas?**  
  - **A:** O Amazon Rekognition é projetado para análise de imagens e vídeos, não para reconhecimento de fala ou transcrição de áudio.  
  - **C:** O Amazon Translate é usado para tradução de texto, não para reconhecimento de múltiplos interlocutores ou transcrição de áudio. Além disso, armazenar os dados no Amazon Redshift aumenta os custos e a complexidade desnecessariamente.  
  - **D:** O Amazon Rekognition não é adequado para reconhecimento de fala. O Amazon Textract é usado para extrair texto de documentos digitalizados, e não para análise de arquivos de transcrição.  

</details>

---

### Questão 200
Uma empresa hospeda seu aplicativo na AWS. A empresa usa o Amazon Cognito para gerenciar usuários. Quando os usuários fazem login no aplicativo, o aplicativo busca os dados necessários do Amazon DynamoDB usando uma API REST hospedada no Amazon API Gateway. A empresa deseja uma solução gerenciada pela AWS que controle o acesso à API REST para reduzir os esforços de desenvolvimento.  
Qual solução atenderá a esses requisitos com a MENOR sobrecarga operacional?  

A. Configurar uma função AWS Lambda para ser um autorizador no API Gateway para validar qual usuário fez a solicitação.  

B. Para cada usuário, criar e atribuir uma chave de API que deve ser enviada com cada solicitação. Validar a chave usando uma função AWS Lambda.  

C. Enviar o endereço de e-mail do usuário no cabeçalho com cada solicitação. Invocar uma função AWS Lambda para validar se o usuário com esse endereço de e-mail tem o acesso apropriado.  

D. Configurar um autorizador de pool de usuários do Amazon Cognito no API Gateway para permitir que o Amazon Cognito valide cada solicitação.  

<details>
<summary>Resposta</summary>

**Resposta correta:**  
<resposta>D</resposta>

**D:** Configurar um autorizador de pool de usuários do Amazon Cognito no API Gateway para permitir que o Amazon Cognito valide cada solicitação.  

**Justificativa:**  
- **Por que essa opção?**  
  O autorizador de pool de usuários do Amazon Cognito integrado ao API Gateway é uma solução gerenciada que valida automaticamente as solicitações com tokens gerados pelo Cognito quando os usuários fazem login. Isso reduz significativamente a sobrecarga operacional e elimina a necessidade de criar e manter uma lógica personalizada para autenticação e autorização.  

- **Por que as outras opções não são adequadas?**  
  - **A:** Usar uma função Lambda como autorizador requer a implementação manual da lógica de autenticação, aumentando a complexidade e os custos operacionais.  
  - **B:** Criar e gerenciar chaves de API manualmente para cada usuário adiciona um esforço significativo e não aproveita as funcionalidades nativas de gerenciamento de usuários do Cognito.  
  - **C:** Validar o e-mail do usuário com uma função Lambda depende de lógica personalizada e não é escalável nem seguro, já que os cabeçalhos podem ser facilmente manipulados.  

</details>

---
